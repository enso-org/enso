from Standard.Base import all
import Standard.Base.Errors.Encoding_Error.Encoding_Error
import Standard.Base.Errors.File_Error.File_Error
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

from Standard.Table import Table, Column, Data_Formatter, Quote_Style, Match_Columns, Delimited
from Standard.Table.Errors import all

from Standard.Test_New import all

from project.Util import all

type My_Type
    Value x

    to_text : Text
    to_text self = "[[[My Type :: " + self.x.to_text + "]]]"

default_line_endings_for_new_files = Line_Ending_Style.Unix
join_lines lines trailing_newline=True =
    eol = default_line_endings_for_new_files.to_text
    if trailing_newline then lines.join eol suffix=eol else lines.join eol

add_specs suite_builder =
    line_ending_pairs = [[Line_Ending_Style.Unix, '\n'], [Line_Ending_Style.Windows, '\r\n'], [Line_Ending_Style.Mac_Legacy, '\r']]
    suite_builder.group "Delimited File Writing" group_builder->
        group_builder.specify "should correctly write a simple table and return the written file object on success" <|
            table = Table.new [["A", [1,2,3]], ["B", [1.0,1.5,2.2]], ["C", ["x","y","z"]], ["D", ["a", 2, My_Type.Value 10]]]
            file = (enso_project.data / "transient" / "written.csv")
            file.delete_if_exists
            table.write file on_problems=Report_Error . should_succeed . should_equal file
            expected_text = normalize_lines <| """
                A,B,C,D
                1,1.0,x,a
                2,1.5,y,2
                3,2.2,z,[[[My Type :: 10]]]
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

        group_builder.specify "should allow to specify line ending style" <|
            table = Table.new [["a", ["b", "c"]], ["d", ["e", "f"]]]
            lines = ["a,d", "b,e", "c,f"]
            line_ending_pairs.each setting->
                style=setting.first
                separator=setting.second
                file = (enso_project.data / "transient" / "endings.csv")
                table.write file (Delimited ',' line_endings=style) on_problems=Report_Error . should_succeed
                text = Data.read_text file
                text.should_equal (lines.join separator suffix=separator)
                file.delete

        group_builder.specify 'should quote values that contain the delimiter, newline or quotes, in the [,""] variant' <|
            data_formatter = Data_Formatter.Value decimal_point=","
            table = Table.new [['The Column "Name"', ["foo","'bar'",'"baz"', 'one, two, three', 'a\nb']], ["Hello, Column?", [1.0, 1000000.5, 2.2, -1.5, 0.0]]]
            file = (enso_project.data / "transient" / "quotes1.csv")
            file.delete_if_exists
            table.write file (Delimited "," value_formatter=data_formatter) on_problems=Report_Error . should_succeed
            expected_text = normalize_lines <| """
                "The Column ""Name""","Hello, Column?"
                foo,"1,0"
                'bar',"1000000,5"
                """baz""","2,2"
                "one, two, three","-1,5"
                "a
                b","0,0"
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

        group_builder.specify 'should quote values that contain the delimiter, newline or quotes, in the [;\\\"] variant' <|
            data_formatter = Data_Formatter.Value thousand_separator="'"
            table = Table.new [['"A"', ["foo",'!"baz" ', 'one, two, three', "a;b; c ", "a\b", 'n\nm']], ["B", [1000000.5, 1000.0, 0.0, -1.2, Nothing, 33]]]
            file = (enso_project.data / "transient" / "quotes2.csv")
            file.delete_if_exists
            table.write file (Delimited ";" value_formatter=data_formatter . with_quotes quote='"' quote_escape='\\') on_problems=Report_Error . should_succeed
            expected_text = normalize_lines <| """
                "\"A\"";B
                foo;1'000'000.5
                "!\"baz\" ";1'000.0
                one, two, three;0.0
                "a;b; c ";-1.2
                "a\\b";
                "n
                m";33.0
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

        group_builder.specify "should quote values that contain the delimiter, newline or quotes, in the [\t''] variant" <|
            data_formatter = Data_Formatter.Value thousand_separator="'"
            table = Table.new [['"A"', [Nothing,"The 'thing'.", 'one, "two", three', 'a\tb', 'x\ny', 'w\vz']], ["B\C", [1000000.5, 1000.0, Nothing, -1.2, 2.0, 42.0]]]
            file = (enso_project.data / "transient" / "quotes3.csv")
            file.delete_if_exists
            table.write file (Delimited '\t' value_formatter=data_formatter . with_quotes quote='\'' quote_escape='\'') on_problems=Report_Error . should_succeed
            expected_text = normalize_lines <| '''
                "A"\tB\\C
                \t'1''000''000.5'
                'The ''thing''.'\t'1''000.0'
                one, "two", three\t
                'a\tb'\t-1.2
                'x
                y'\t2.0
                w\vz\t42.0
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

        group_builder.specify "should correctly distinguish empty text from a missing value" <|
            table = Table.new [["A", [1,Nothing,3]], ["B", [Nothing,"","abc"]]]
            file = (enso_project.data / "transient" / "empty_vs_null.csv")
            file.delete_if_exists
            table.write file on_problems=Report_Error . should_succeed
            expected_text = normalize_lines <| """
                A,B
                1,
                ,""
                3,abc
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

        group_builder.specify "should quote values containing the comment symbol if comments are enabled" <|
            table = Table.new [["#", ['b', 'x', '#']], ["B", [Nothing,"#","abc"]]]
            file = (enso_project.data / "transient" / "comments.csv")
            file.delete_if_exists
            table.write file on_problems=Report_Error . should_succeed
            expected_text = join_lines ['#,B','b,', 'x,#', '#,abc']
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

            format = Delimited ',' . with_comments
            table.write file format on_problems=Report_Error . should_succeed
            expected_text_2 = normalize_lines <| """
                "#",B
                b,
                x,"#"
                "#",abc
            text_2 = Data.read_text file
            text_2.should_equal expected_text_2
            file.delete

        group_builder.specify 'should not quote values if quoting is disabled' <|
            format = Delimited "," value_formatter=(Data_Formatter.Value decimal_point=",") . without_quotes
            table = Table.new [['The Column "Name"', ["foo","'bar'",'"baz"', 'one, two, three']], ["Hello, Column?", [1.0, 1000000.5, 2.2, -1.5]]]
            file = (enso_project.data / "transient" / "quote_disabled.csv")
            file.delete_if_exists
            r = table.write file format on_problems=Report_Error
            r.should_equal file
            warnings = Problems.get_attached_warnings r
            ## Only the 3rd row of the first column warns. Since quoting is
               disabled we cannot check what could be the quote character to be
               escaped.
            ew1 = Unquoted_Characters_In_Output.Warning 'The Column "Name"' [3]
            ew2 = Unquoted_Characters_In_Output.Warning "Hello, Column?" [-1, 0, 1, 2, 3]
            warnings.should_contain_the_same_elements_as [ew1, ew2]
            w1 = warnings.find w-> w.column == 'Hello, Column?'
            w1.to_display_text . should_equal "The Hello, Column? at rows [the header, 0, 1, 2, 3] contains characters that need quoting, but quoting is disabled. The generated file may be corrupted."
            expected_text = normalize_lines <| """
                The Column "Name",Hello, Column?
                foo,1,0
                'bar',1000000,5
                "baz",2,2
                one, two, three,-1,5
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

        group_builder.specify 'should allow to always quote text and custom values, but for non-text primitives only if absolutely necessary' <|
            format = Delimited "," value_formatter=(Data_Formatter.Value thousand_separator='"' . with_datetime_formats date_formats=["dddd, d MMM y"]) . with_quotes always_quote=True quote_escape='\\'
            table = Table.new [['The Column "Name"', ["foo","'bar'",'"baz"', 'one, two, three']], ["B", [1.0, 1000000.5, 2.2, -1.5]], ["C", ["foo", My_Type.Value 44, (Date.new 2022 06 21), 42]], ["D", [1,2,3,4000]], ["E", [Nothing, (Time_Of_Day.new 13 55), Nothing, Nothing]]]
            file = (enso_project.data / "transient" / "quote_always.csv")
            file.delete_if_exists
            table.write file format on_problems=Report_Error . should_succeed
            expected_text1 = normalize_lines <| """
                "The Column \"Name\"","B","C","D","E"
                "foo",1.0,"foo",1,
                "'bar'","1\"000\"000.5","[[[My Type :: 44]]]",2,13:55:00
                "\"baz\"",2.2,"Tuesday, 21 Jun 2022",3,
            expected_text = expected_text1 + '"one, two, three",-1.5,42,"4\\"000",\n'
            text = Data.read_text file
            text.should_equal expected_text
            file.delete

        group_builder.specify "should correctly handle alternative encodings" <|
            table = Table.new [["Ä…Ä™Ä‡Å›", [0]], ["ÃŸ", ["Å¼Ã³Å‚w ðŸ¢"]]]
            file = (enso_project.data / "transient" / "utf16.csv")
            file.delete_if_exists
            table.write file (Delimited "," encoding=Encoding.utf_16_be) on_problems=Report_Error . should_succeed
            expected_text = normalize_lines <| """
                Ä…Ä™Ä‡Å›,ÃŸ
                0,Å¼Ã³Å‚w ðŸ¢
            text = Data.read_text file encoding=Encoding.utf_16_be
            text.should_equal expected_text
            file.delete

        group_builder.specify "should correctly handle encoding errors" <|
            table = Table.new [["A", [0, 1]], ["B", ["sÅ‚Ã³wka", "ðŸ¢"]]]
            file = (enso_project.data / "transient" / "ascii.csv")
            file.delete_if_exists
            result = table.write file (Delimited "," encoding=Encoding.ascii)
            expected_text = normalize_lines <| """
                A,B
                0,s??wka
                1,?
            text = Data.read_text file encoding=Encoding.ascii
            text.should_equal expected_text
            result . should_equal file
            positions = [7, 8, 15]
            msg = "Encoding issues at codepoints " +
                positions.map .to_text . join separator=", " suffix="."
            Problems.get_attached_warnings result . should_equal [Encoding_Error.Error msg]
            file.delete

        group_builder.specify "should allow only text columns if no formatter is specified" <|
            format = Delimited "," value_formatter=Nothing
            table_1 = Table.new [["A", ["x", "y"]], ["B", ["z", "w"]]]
            file_1 = (enso_project.data / "transient" / "textonly.csv")
            file_1.delete_if_exists
            result_1 = table_1.write file_1 format on_problems=Report_Error . should_succeed
            expected_text = normalize_lines <| """
                A,B
                x,z
                y,w
            text_1 = Data.read_text file_1
            text_1.should_equal expected_text
            result_1 . should_equal file_1

            table_2 = Table.new [["A", [1, 2]], ["B", ["z", "w"]]]
            file_2 = (enso_project.data / "transient" / "non-text_but_no_formatter.csv")
            file_2.delete_if_exists
            result_2 = table_2.write file_2 format
            result_2 . should_fail_with Illegal_Argument
            text_2 = Data.read_text file_2
            text_2.should_equal ""

            file_1.delete
            file_2.delete

        group_builder.specify "should create a new file in append mode if it didn't exist" <|
            table = Table.new [["A", [1,2,3]], ["B", [1.0,1.5,2.2]], ["C", ["x","y","z"]]]
            file = (enso_project.data / "transient" / "append_nonexistent.csv")
            file.delete_if_exists
            table.write file on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
            got_table = file.read
            got_table.should_equal table
            file.delete

        group_builder.specify "should correctly append to an empty file" <|
            table = Table.new [["A", [1,2,3]], ["B", [1.0,1.5,2.2]], ["C", ["x","y","z"]]]
            file = (enso_project.data / "transient" / "append_empty.csv")
            file.delete_if_exists
            "".write file
            table.write file on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
            got_table = file.read
            got_table.should_equal table
            file.delete

        group_builder.specify "should correctly append to a file with a missing newline at EOF" <|
            table = Table.new [["A", [1,2,3]], ["B", [1.0,1.5,2.2]], ["C", ["x","y","z"]]]
            file = (enso_project.data / "transient" / "append_missing_newline.csv")
            file.delete_if_exists
            'A,B,C\r0,0,0'.write file
            table.write file on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
            text = Data.read_text file
            expected_lines = ["A,B,C", "0,0,0", "1,1.0,x", "2,1.5,y", "3,2.2,z"]
            text.should_equal (expected_lines.join '\r' suffix='\r')
            file.delete

        group_builder.specify "should append to a file, matching columns by name (headers=Infer)" <|
            existing_table = Table.new [["A", [1,2]], ["B", [1.0,1.5]], ["C", ["x","y"]]]
            appending_table = Table.new [["B", [33,44]], ["A", [Nothing, 0]], ["C", ["a","BB"]]]
            file = (enso_project.data / "transient" / "append_by_name.csv")
            file.delete_if_exists
            existing_table.write file on_existing_file=Existing_File_Behavior.Overwrite on_problems=Report_Error . should_succeed
            appending_table.write file on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
            got_table = file.read
            expected_table = Table.new [["A", [1,2,Nothing,0]], ["B", [1.0,1.5,33,44]], ["C", ["x","y","a","BB"]]]
            got_table.should_equal expected_table
            file.delete

        group_builder.specify "should append to a file, matching columns by name (headers=True)" <|
            existing_table = Table.new [["0", [1,2]], ["B1", [1.0,1.5]], ["C", ["x","y"]]]
            appending_table = Table.new [["B1", [33,44]], ["0", [Nothing, 0]], ["C", ["a","BB"]]]
            file = (enso_project.data / "transient" / "append_by_name_2.csv")
            file.delete_if_exists
            existing_table.write file on_existing_file=Existing_File_Behavior.Overwrite on_problems=Report_Error . should_succeed
            format = Delimited "," . with_headers
            appending_table.write file format on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
            got_table = file.read format
            expected_table = Table.new [["0", [1,2,Nothing,0]], ["B1", [1.0,1.5,33,44]], ["C", ["x","y","a","BB"]]]
            got_table.should_equal expected_table
            file.delete

        group_builder.specify "should fail when appending and matching columns by name but column names are not available in the file (headers=Infer)" <|
            existing_table = Table.new [["A", [1,2]], ["B", [1.0,1.5]], ["C", ["x","y"]]]
            appending_table = Table.new [["B", [33,44]], ["A", [Nothing, 0]], ["C", ["a","BB"]]]
            file = (enso_project.data / "transient" / "append_no_header.csv")
            file.delete_if_exists
            no_header_format = Delimited "," . without_headers
            existing_table.write file no_header_format on_existing_file=Existing_File_Behavior.Overwrite
            appending_table.write file on_existing_file=Existing_File_Behavior.Append . should_fail_with Illegal_Argument
            file.delete

        group_builder.specify "should fail when appending and matching columns by name but headers are disabled (headers=False)" <|
            existing_table = Table.new [["A", [1,2]], ["B", [1.0,1.5]], ["C", ["x","y"]]]
            appending_table = Table.new [["B", [33,44]], ["A", [Nothing, 0]], ["C", ["a","BB"]]]
            file = (enso_project.data / "transient" / "append_no_header.csv")
            file.delete_if_exists
            no_header_format = Delimited "," . without_headers
            existing_table.write file on_existing_file=Existing_File_Behavior.Overwrite
            appending_table.write file no_header_format on_existing_file=Existing_File_Behavior.Append . should_fail_with Illegal_Argument
            file.delete

        group_builder.specify "should fail on column mismatch when appending to a file by name" <|
            existing_table = Table.new [["A", [1,2]], ["B", [1.0,1.5]]]
            appending_table = Table.new [["B", [33,44]], ["X", [Nothing, 0]]]
            file = (enso_project.data / "transient" / "append_no_header.csv")
            file.delete_if_exists
            existing_table.write file on_existing_file=Existing_File_Behavior.Overwrite
            result = appending_table.write file on_existing_file=Existing_File_Behavior.Append
            result . should_fail_with Column_Name_Mismatch
            result.catch.missing . should_equal ["A"]
            result.catch.extras . should_equal ["X"]
            result.catch.to_display_text . should_equal "Columns mismatch. Missing from new data: [A] Extras in new data: [X]"
            file.delete

        group_builder.specify "should append to a file, matching columns by position" <|
            existing_table = Table.new [["A", [1,2]], ["B", [1.0,1.5]], ["C", ["x","y"]]]
            appending_table = Table.new [["AA", [33,44]], ["...", [Nothing, 0]], ["hmmm", ["a","BB"]]]

            test_append initial_file_format append_format expected_table =
                file = (enso_project.data / "transient" / "append_by_position.csv")
                file.delete_if_exists
                existing_table.write file initial_file_format on_existing_file=Existing_File_Behavior.Overwrite on_problems=Report_Error . should_succeed
                appending_table.write file append_format match_columns=Match_Columns.By_Position on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
                read_format = initial_file_format
                got_table = file.read read_format
                got_table.should_equal expected_table
                file.delete

            base_format = Delimited ","
            no_headers = base_format . without_headers
            with_headers = base_format . with_headers

            expected_table_with_headers = Table.new [["A", [1,2,33,44]], ["B", [1.0,1.5,Nothing,0]], ["C", ["x","y","a","BB"]]]
            expected_table_without_headers = expected_table_with_headers.rename_columns ["Column 1", "Column 2", "Column 3"]

            test_append initial_file_format=with_headers append_format=no_headers expected_table_with_headers
            test_append initial_file_format=with_headers append_format=base_format expected_table_with_headers
            test_append initial_file_format=no_headers append_format=base_format expected_table_without_headers
            test_append initial_file_format=no_headers append_format=no_headers expected_table_without_headers

        group_builder.specify "should fail on column count mismatch when appending to a file by position" <|
            existing_table = Table.new [["A", [1,2]], ["B", [1.0,1.5]], ["C", ["x","y"]]]
            appending_table_1 = Table.new [["B", [33,44]], ["X", [Nothing, 0]]]
            appending_table_2 = Table.new [["B", [33,44]], ["X", [Nothing, 0]], ["Y", ["a","BB"]], ["Z", [Nothing, 0]]]
            file = (enso_project.data / "transient" / "append_mismatch.csv")
            file.delete_if_exists
            existing_table.write file on_existing_file=Existing_File_Behavior.Overwrite

            result_1 = appending_table_1.write file match_columns=Match_Columns.By_Position on_existing_file=Existing_File_Behavior.Append
            result_1 . should_fail_with Column_Count_Mismatch
            result_1.catch.expected . should_equal 3
            result_1.catch.actual . should_equal 2
            result_1.catch.to_display_text . should_equal "Expected 3 columns, got 2."

            result_2 = appending_table_2.write file match_columns=Match_Columns.By_Position on_existing_file=Existing_File_Behavior.Append
            result_2 . should_fail_with Column_Count_Mismatch
            result_2.catch.expected . should_equal 3
            result_2.catch.actual . should_equal 4
            result_2.catch.to_display_text . should_equal "Expected 3 columns, got 4."

            file.delete

        group_builder.specify "should use the same line ending style as existing data when appending" <|
            initial_table = Table.new [["a", [1, 2]], ["d", ["e", "f"]]]
            table_to_append = Table.new [["a", ["x", "y"]], ["d", ["z", "w"]]]
            expected_lines = ["a,d", "1,e", "2,f", "x,z", "y,w"]
            line_ending_pairs.each setting->
                style=setting.first
                separator=setting.second
                file = (enso_project.data / "transient" / "endings.csv")
                initial_table.write file (Delimited ',' line_endings=style) on_problems=Report_Error . should_succeed
                table_to_append.write file on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
                text = Data.read_text file
                text.should_equal (expected_lines.join separator suffix=separator)
                file.delete

        group_builder.specify "should use Unix line ending style when appending to an empty or nonexistent file" <|
            empty_file = (enso_project.data / "transient" / "empty.csv")
            "".write empty_file
            nonexistent_file = (enso_project.data / "transient" / "nonexistent.csv")
            nonexistent_file.delete_if_exists

            table_to_append = Table.new [["a", ["x", "y"]], ["d", ["z", "w"]]]
            table_to_append.write nonexistent_file on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
            table_to_append.write empty_file on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed

            expected_lines = ["a,d", "x,z", "y,w"]
            expected_text = join_lines expected_lines
            Data.read_text empty_file . should_equal expected_text
            Data.read_text nonexistent_file . should_equal expected_text

        group_builder.specify "should use the existing line ending style when appending to a file consisting of only comments" <|
            initial_lines = ["# comment 1", "# comment 2"]
            table_to_append = Table.new [["a", ["x", "y"]], ["b", ["z", "w"]]]
            expected_lines = initial_lines + ["a,b", "x,z", "y,w"]
            file = (enso_project.data / "transient" / "endings_comments_only.csv")
            line_ending_pairs.each setting->
                separator=setting.second
                file.delete_if_exists
                (initial_lines.join separator suffix=separator).write file
                format = Delimited ',' . with_comments
                table_to_append.write file format on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
                text = Data.read_text file
                expected_text = expected_lines.join separator suffix=separator
                text.should_equal expected_text
                file.delete

        group_builder.specify "should use the existing line ending style when appending to a file consisting of only comments missing last EOL" <|
            initial_lines = ["# comment 1", "# comment 2 without EOL"]
            table_to_append = Table.new [["a", ["x", "y"]], ["b", ["z", "w"]]]
            expected_lines = initial_lines + ["a,b", "x,z", "y,w"]
            file = (enso_project.data / "transient" / "endings_comments_only.csv")
            line_ending_pairs.each setting->
                separator=setting.second
                file.delete_if_exists
                (initial_lines.join separator).write file
                format = Delimited ',' . with_comments
                table_to_append.write file format on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
                text = Data.read_text file
                expected_text = expected_lines.join separator suffix=separator
                text.should_equal expected_text
                file.delete

        group_builder.specify "should correctly handle append edge cases" <|
            table = Table.new [["a", [1, 2]]]
            file = (enso_project.data / "transient" / "append_edge_cases.csv")
            file.delete_if_exists

            format = Delimited ',' . without_headers

            # A long line but without a trailing newline
            base_line = "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-ABC"
            expected_lines_1 = [base_line, "1", "2"]
            # 1 character with trailing newline
            line_ending_pairs.each setting->
                separator=setting.second
                (base_line+separator).write file
                table.write file format on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=Report_Error . should_succeed
                text = Data.read_text file
                expected_text = expected_lines_1.join separator suffix=separator
                text.should_equal expected_text
                file.delete

            base_line.write file
            table.write file format on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=Report_Error . should_succeed
            Data.read_text file . should_equal <| normalize_lines base_line+'\n1\n2\n'
            file.delete

            # 1 character without trailing newline
            "#".write file
            table.write file format on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=Report_Error . should_succeed
            Data.read_text file . should_equal <| normalize_lines '#\n1\n2\n'
            file.delete

            "#".write file
            table.write file format.with_comments on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=Report_Error . should_succeed
            Data.read_text file . should_equal <| normalize_lines '#\n1\n2\n'
            file.delete

            expected_lines_2 = ["#", "1", "2"]
            # 1 character with trailing newline
            line_ending_pairs.each setting->
                [format.with_comments, format].each format->
                    separator=setting.second
                    ("#"+separator).write file
                    table.write file format on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=Report_Error . should_succeed
                    text = Data.read_text file
                    expected_text = expected_lines_2.join separator suffix=separator
                    text.should_equal expected_text
                    file.delete

            ["B", "#"].each middle_line->
                expected_lines_3 = ["A", middle_line, "1", "2"]
                [format.with_comments, format].each format->
                    # 2 lines without trailing newline
                    line_ending_pairs.each setting->
                        separator=setting.second
                        ("A"+separator+middle_line).write file
                        table.write file format on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=Report_Error . should_succeed
                        text = Data.read_text file
                        expected_text = expected_lines_3.join separator suffix=separator
                        text.should_equal expected_text
                        file.delete

                    # 2 lines with trailing newline
                    line_ending_pairs.each setting->
                        separator=setting.second
                        ("A"+separator+middle_line+separator).write file
                        table.write file format on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=Report_Error . should_succeed
                        text = Data.read_text file
                        expected_text = expected_lines_3.join separator suffix=separator
                        text.should_equal expected_text
                        file.delete

        group_builder.specify "should use the existing line ending style when appending to a file consisting of only one comment with EOL" <|
            initial_line = "# comment 1 with EOL"
            table_to_append = Table.new [["a", ["x", "y"]], ["b", ["z", "w"]]]
            expected_lines = [initial_line] + ["a,b", "x,z", "y,w"]
            file = (enso_project.data / "transient" / "endings_comments_only.csv")
            line_ending_pairs.each setting->
                separator=setting.second
                file.delete_if_exists
                (initial_line+separator).write file
                format = Delimited ',' . with_comments
                table_to_append.write file format on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
                text = Data.read_text file
                expected_text = expected_lines.join separator suffix=separator
                text.should_equal expected_text
                file.delete

        group_builder.specify "should use the Unix line ending style when appending to a file consisting of only one comment and missing the EOL" <|
            initial_lines = ["# comment 1 without EOL"]
            table_to_append = Table.new [["a", ["x", "y"]], ["b", ["z", "w"]]]
            expected_lines = initial_lines + ["a,b", "x,z", "y,w"]
            file = (enso_project.data / "transient" / "endings_comments_only.csv")
            file.delete_if_exists
            (join_lines initial_lines trailing_newline=False).write file
            format = Delimited ',' . with_comments
            table_to_append.write file format on_existing_file=Existing_File_Behavior.Append on_problems=Report_Error . should_succeed
            text = Data.read_text file
            expected_text = join_lines expected_lines
            text.should_equal expected_text
            file.delete

        group_builder.specify "should fail if explicitly provided line endings do not match line endings in the file when appending" <|
            initial_table = Table.new [["a", [1, 2]]]
            table_to_append = Table.new [["a", ["x", "y"]]]
            file = (enso_project.data / "transient" / "endings_mismatch.csv")
            file.delete_if_exists
            initial_table.write file (Delimited ',' line_endings=Line_Ending_Style.Mac_Legacy)
            result = table_to_append.write file (Delimited ',' line_endings=Line_Ending_Style.Unix) on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position
            result . should_fail_with Illegal_Argument
            result.catch.message . should_equal "The explicitly provided line endings ('\n') do not match the line endings in the file ('\r')."
            file.delete

        group_builder.specify "should fail if the target file is read-only" <|
            f = enso_project.data / "transient" / "permission.csv"
            f.delete_if_exists

            initial_data = "MY DATA"
            initial_data.write f
            set_writable f False

            t1 = Table.new [["X", [1, 2, 3]]]
            [Existing_File_Behavior.Backup, Existing_File_Behavior.Overwrite, Existing_File_Behavior.Append].each behavior->
                r1 = t1.write f (Delimited ',') on_existing_file=behavior
                r1.should_fail_with File_Error
                r1.catch.should_be_a File_Error.Access_Denied
                f.read Plain_Text . should_equal initial_data

            set_writable f True
            f.delete

        group_builder.specify "should fail if the parent directory does not exist" <|
            parent = enso_project.data / "transient" / "nonexistent"
            parent.exists.should_be_false

            f = parent / "foo.csv"
            t1 = Table.new [["X", [1, 2, 3]]]
            r1 = t1.write f (Delimited ',')
            r1.should_fail_with File_Error
            r1.catch.should_be_a File_Error.Not_Found

        group_builder.specify "should warn about not-encodable characters according to the problem behaviour" <|
            f = enso_project.data / "transient" / "encoding-errors.csv"

            format = Delimited "," encoding=Encoding.ascii headers=True
            t = Table.new [["X", ["A", "B", "ðŸ˜Š", "D"]]]
            do_write pb =
                f.delete_if_exists
                t.write f format on_problems=pb
            tester write_result =
                write_result . should_equal f
                read_table = write_result.read format
                read_table.column_names . should_equal ["X"]
                read_table.at "X" . to_vector . should_equal ["A", "B", "?", "D"]
            problems = [Encoding_Error.Error "Encoding issues at codepoint 6."]
            Problems.test_problem_handling do_write problems tester

            # And should not overwrite the original contents when working in backup mode.
            f.delete_if_exists
            "Initial Content".write f on_existing_file=Existing_File_Behavior.Overwrite
            big_table = Table.new [["X", 0.up_to 5000 . to_vector + ["ðŸ˜Š"]]]
            r2 = big_table.write f format on_problems=Problem_Behavior.Report_Error
            r2.should_fail_with Encoding_Error
            r2.catch.to_display_text . should_contain "Encoding issues"
            f.read Plain_Text . should_equal "Initial Content"
            f.delete

main =
    suite = Test.build suite_builder->
        add_specs suite_builder
    suite.run_with_filter

