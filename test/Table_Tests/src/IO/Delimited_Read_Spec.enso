from Standard.Base import all
import Standard.Base.Errors.Encoding_Error.Encoding_Error
import Standard.Base.Errors.File_Error.File_Error
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

from Standard.Table import Table, Column, Data_Formatter, Quote_Style, Delimited
from Standard.Table.Extensions.Table_Conversions import all
from Standard.Table.Errors import all

from Standard.Test_New import all

import project.Util

add_specs suite_builder =
    suite_builder.group "Delimited File Parsing" group_builder->
        group_builder.specify "should load a simple table with headers" <|
            c_1 = ["a", ['1', '4', '7', '10']]
            c_2 = ["b", ['2', Nothing, '8', '11']]
            c_3 = ["c", [Nothing, '6', '9', '12']]
            expected_table = Table.new [c_1, c_2, c_3]
            simple_empty = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True value_formatter=Nothing)
            simple_empty.should_equal expected_table

        group_builder.specify "should load a simple table without headers" <|
            c_1 = ["Column 1", ['a', '1', '4', '7', '10']]
            c_2 = ["Column 2", ['b', '2', Nothing, '8', '11']]
            c_3 = ["Column 3", ['c', Nothing, '6', '9', '12']]
            expected_table = Table.new [c_1, c_2, c_3]
            simple_empty = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False value_formatter=Nothing)
            simple_empty.should_equal expected_table

        group_builder.specify "should work in presence of missing headers" <|
            action on_problems = Data.read (enso_project.data / "missing_header.csv") (Delimited "," headers=True value_formatter=Nothing) on_problems
            tester table =
                table.columns.map .name . should_equal ["a", "Column 1", "c", "Column 2", "d"]
                table.at "a" . to_vector . should_equal ["1"]
                table.at "Column 1" . to_vector . should_equal ["2"]
                table.at "c" . to_vector . should_equal ["3"]
                table.at "Column 2" . to_vector . should_equal ["4"]
                table.at "d" . to_vector . should_equal ["5"]
            problems = [Invalid_Column_Names.Error [Nothing, Nothing]]
            Problems.test_problem_handling action problems tester

        group_builder.specify "should infer headers based on the first two rows" <|
            t1 = Data.read (enso_project.data / "data_small.csv") (Delimited ",")
            t1.columns.map .name . should_equal ["Code", "Index", "Flag", "Value", "ValueWithNothing", "TextWithNothing", "Hexadecimal", "Leading0s", "QuotedNumbers", "Mixed Types"]

            t2 = Data.read (enso_project.data / "all_text.csv") (Delimited ",")
            t2.columns.map .name . should_equal ["Column 1", "Column 2"]
            t2.at "Column 1" . to_vector . should_equal ["a", "c", "e", "g"]
            t2.at "Column 2" . to_vector . should_equal ["b", "d", "f", "h"]

            t3 = Data.read (enso_project.data / "two_rows1.csv") (Delimited ",")
            t3.columns.map .name . should_equal ["a", "b", "c"]
            t3.at "a" . to_vector . should_equal ["x"]
            t3.at "b" . to_vector . should_equal [Nothing]
            t3.at "c" . to_vector . should_equal [Nothing]

            t4 = Data.read (enso_project.data / "two_rows2.csv") (Delimited ",")
            t4.columns.map .name . should_equal ["Column 1", "Column 2", "Column 3"]
            t4.at "Column 1" . to_vector . should_equal ["a", "d"]
            t4.at "Column 2" . to_vector . should_equal ["b", "e"]
            t4.at "Column 3" . to_vector . should_equal ["c", "f"]

            t5 = Data.read (enso_project.data / "numbers_in_header.csv") (Delimited ",")
            t5.columns.map .name . should_equal ["Column 1", "Column 2", "Column 3"]
            t5.at "Column 1" . to_vector . should_equal ["a", "1"]
            t5.at "Column 2" . to_vector . should_equal ["b", "2"]
            t5.at "Column 3" . to_vector . should_equal [0, 3]

            t6 = Data.read (enso_project.data / "quoted_numbers_in_header.csv") (Delimited ",")
            t6.columns.map .name . should_equal ["1", "x"]
            t6.at "1" . to_vector . should_equal ["y"]
            t6.at "x" . to_vector . should_equal [2]

        group_builder.specify "should not use the first row as headers if it is the only row, unless specifically asked to" <|
            t1 = Data.read (enso_project.data / "one_row.csv") (Delimited ",")
            t1.columns.map .name . should_equal ["Column 1", "Column 2", "Column 3"]
            t1.at "Column 1" . to_vector . should_equal ["x"]
            t1.at "Column 2" . to_vector . should_equal ["y"]
            t1.at "Column 3" . to_vector . should_equal ["z"]

            t2 = Data.read (enso_project.data / "one_row.csv") (Delimited "," headers=True)
            t2.columns.map .name . should_equal ["x", "y", "z"]
            t2.row_count .  should_equal 0
            t2.at "x" . to_vector . should_equal []

        group_builder.specify "should raise an informative error when loading an empty file" <|
            t = Data.read (enso_project.data / "empty.txt") (Delimited "," headers=True value_formatter=Nothing)
            t.should_fail_with Empty_File_Error

        group_builder.specify "should correctly handle file opening issues" <|
            nonexistent_file = enso_project.data / "a_filename_that_does_not_exist.foobar"
            r1 = Data.read nonexistent_file (Delimited "," headers=True value_formatter=Nothing)
            r1.should_fail_with File_Error
            r1.catch.should_be_a File_Error.Not_Found

            directory = enso_project.data
            r2 = Data.read directory (Delimited "," headers=True value_formatter=Nothing) Problem_Behavior.Report_Error
            r2.should_fail_with File_Error
            r2.catch.should_be_a File_Error.IO_Error

        group_builder.specify "should work with all kinds of line endings" <|
            path name = enso_project.data / 'transient' / name
            create_file name ending_style =
                lines = ['a,b,c', 'd,e,f', '1,2,3']
                text = lines.join ending_style
                text.write (path name)

            test_file name =
                table = Data.read (path name) (Delimited "," headers=True value_formatter=Nothing) Problem_Behavior.Report_Error
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['d', '1']
                table.at 'b' . to_vector . should_equal ['e', '2']
                table.at 'c' . to_vector . should_equal ['f', '3']

            create_file 'crlf.csv' '\r\n'
            test_file 'crlf.csv'
            create_file 'lf.csv' '\n'
            test_file 'lf.csv'
            create_file 'cr.csv' '\r'
            test_file 'cr.csv'

            # Currently mixed line endings are not supported.
            'a,b,c\nd,e,f\r1,2,3'.write (path 'mixed.csv')
            Data.read (path 'mixed.csv') (Delimited "," headers=True value_formatter=Nothing) Problem_Behavior.Report_Error . should_fail_with Invalid_Row

            ['crlf.csv', 'lf.csv', 'cr.csv', 'mixed.csv'].each (path >> .delete)

        group_builder.specify "should allow to override line endings style" <|
            file = enso_project.data / "transient" / "lf.csv"
            lines = ['a,b,c', 'd,e,f', '1,2,3']
            text = lines.join '\n'
            text.write file

            format = Delimited ',' headers=False value_formatter=(Data_Formatter.Value trim_values=False)

            reference_table = Table.new [["Column 1", ["a", "d", "1"]], ["Column 2", ["b", "e", "2"]], ["Column 3", ["c", "f", "3"]]]
            collapsed_table = Table.new <|
                ['a', 'b', 'c\nd', 'e', 'f\n1', 2, 3].map_with_index i-> v->
                    ["Column " + (i+1).to_text, [v]]
            Data.read file format . should_equal reference_table
            Data.read file (format.with_line_endings Line_Ending_Style.Unix) . should_equal reference_table
            Data.read file (format.with_line_endings Line_Ending_Style.Mac_Legacy) . should_equal collapsed_table
            Data.read file (format.with_line_endings Line_Ending_Style.Windows) . should_equal collapsed_table
            file.delete

            file_2 = enso_project.data / "transient" / "crlf.csv"
            lines.join '\r\n' . write file_2
            Data.read file_2 (format.with_line_endings Line_Ending_Style.Windows) . should_equal reference_table

            # For some reason loading the CRLF file in Unix mode trims the CR characters. We may want to revisit this at some point.
            table = Data.read file_2 (format.with_line_endings Line_Ending_Style.Unix)
            table . should_equal reference_table
            file_2.delete

        group_builder.specify "should work with Windows-1252 encoding" <|
            table = Data.read (enso_project.data / "windows.csv") (Delimited "," headers=True encoding=Encoding.windows_1252) Problem_Behavior.Report_Error
            table.columns.map .name . should_equal ['a', 'b', 'c']
            table.at 'a' . to_vector . should_equal ['$Â¢']
            table.at 'b' . to_vector . should_equal ['Â¤']
            table.at 'c' . to_vector . should_equal ['Â¥']

        group_builder.specify "should work with UTF-16 encoding" <|
            table = Data.read (enso_project.data / "utf16.csv") (Delimited "," headers=True encoding=Encoding.utf_16_be) Problem_Behavior.Report_Error
            table.columns.map .name . should_equal ['Ä…', 'ðŸš€b', 'Ä‡ðŸ˜Ž']
            table.at 'Ä…' . to_vector . should_equal ['Ä…']
            table.at 'ðŸš€b' . to_vector . should_equal ['âœ¨ðŸš€ðŸš§ðŸ˜ðŸ˜ƒðŸ˜ðŸ˜ŽðŸ˜™ðŸ˜‰â˜º']
            table.at 'Ä‡ðŸ˜Ž' . to_vector . should_equal ['à¹à¸¡à¸§à¸¡à¸µà¸ªà¸µà¹ˆà¸‚à¸²']

        group_builder.specify "should report errors when encountering malformed characters" <|
            utf8_file = (enso_project.data / "transient" / "utf8_invalid.csv")
            utf8_bytes = [97, 44, 98, 44, 99, 10, -60, -123, 44, -17, -65, -65, 44, -61, 40, -61, 40, 10]
            utf8_bytes.write_bytes utf8_file
            action_1 on_problems =
                utf8_file.read (Delimited "," headers=True) on_problems
            tester_1 table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['Ä…']
                table.at 'b' . to_vector . should_equal ['\uFFFF']
                table.at 'c' . to_vector . should_equal ['\uFFFD(\uFFFD(']
            problems_1 = [Encoding_Error.Error "Encoding issues at bytes 13, 15."]
            Problems.test_problem_handling action_1 problems_1 tester_1
            utf8_file.delete

            action_2 on_problems =
                (enso_project.data / "utf16_invalid.csv").read (Delimited "," headers=True encoding=Encoding.utf_16_be) on_problems
            tester_2 table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                # This column does not raise a problem - the '\uFFFD' is simply present in the input file.
                table.at 'a' . to_vector . should_equal ['\uFFFD']
                table.at 'b' . to_vector . should_equal ['\uFFFF']
                # However, this column will raise a problem as the '\uFFFD' comes from replacing an invalid codepoint.
                table.at 'c' . to_vector . should_equal ['\uFFFD']
            problems_2 = [Encoding_Error.Error "Encoding issues at byte 22."]
            Problems.test_problem_handling action_2 problems_2 tester_2

        group_builder.specify "should handle duplicated columns" <|
            action on_problems = Data.read (enso_project.data / "duplicated_columns.csv") (Delimited "," headers=True value_formatter=Nothing) on_problems
            tester table =
                table.columns.map .name . should_equal ['a', 'b', 'c', 'a 1']
                table.at 'a' . to_vector . should_equal ['1']
                table.at 'a 1' . to_vector . should_equal ['4']
            problems = [Duplicate_Output_Column_Names.Error ['a']]
            Problems.test_problem_handling action problems tester

        group_builder.specify "should handle quotes" <|
            t1 = Data.read (enso_project.data / "double_quoted.csv") (Delimited "," headers=True value_formatter=Nothing)
            t1.at 'a' . to_vector . should_equal ['a, x', '"a']
            t1.at 'c' . to_vector . should_equal ['3', '"']

            t2 = Data.read (enso_project.data / "escape_quoted.csv") (Delimited "," headers=True value_formatter=Nothing . with_quotes quote_escape="\")
            t2.at 'a' . to_vector . should_equal ['a"b', 'a\\\"z']

            t3 = Data.read (enso_project.data / "no_quoting.csv") (Delimited "," headers=True value_formatter=Nothing . without_quotes)
            t3.at 'a' . to_vector . should_equal ['"y']
            t3.at 'b' . to_vector . should_equal ['z"']
            t3.at 'c' . to_vector . should_equal ['a']

        group_builder.specify "should support rows spanning multiple lines if quoted" <|
            t1 = Data.read (enso_project.data / "multiline_quoted.csv") (Delimited "," headers=True value_formatter=Nothing)
            t1.at 'a' . to_vector . should_equal ['1', '4']
            t1.at 'b' . to_vector . should_equal ['start\n\ncontinue', '5']
            t1.at 'c' . to_vector . should_equal ['3', '6']

        group_builder.specify "should fail in presence of a mismatched quote" <|
            [Problem_Behavior.Report_Error, Problem_Behavior.Report_Warning, Problem_Behavior.Ignore].each pb->
                format = (Delimited "," headers=True value_formatter=Nothing)
                r1 = Data.read (enso_project.data / "mismatched_quote.csv") format on_problems=pb
                r1.should_fail_with File_Error
                r1.catch.should_be_a File_Error.Corrupted_Format
                r1.catch.to_display_text.should_contain "quote has been opened but never closed"
                r1.catch.to_display_text.should_contain '["\n7,8,9\n]'

                r2 = Data.read (enso_project.data / "mismatched_quote2.csv") format on_problems=pb
                r2.should_fail_with File_Error
                r2.catch.should_be_a File_Error.Corrupted_Format

                format3 = format . with_quotes quote_escape="\"
                r3 = Data.read (enso_project.data / "mismatched_quote3.csv") format3 on_problems=pb
                r3.should_fail_with File_Error
                r3.catch.should_be_a File_Error.Corrupted_Format

                r4 = Data.read (enso_project.data / "mismatched_quote4.csv") format on_problems=pb
                r4.should_fail_with File_Error
                r4.catch.should_be_a File_Error.Corrupted_Format

                r5 = Data.read (enso_project.data / "mismatched_quote5.csv") format on_problems=pb
                r5.should_fail_with File_Error
                r5.catch.should_be_a File_Error.Corrupted_Format

        group_builder.specify "should fail in presence of a mismatched quote (2)" pending="ToDo: To be fixed in https://github.com/enso-org/enso/issues/5839" <|
            [Problem_Behavior.Report_Error, Problem_Behavior.Report_Warning, Problem_Behavior.Ignore].each pb->
                format = (Delimited "," headers=True value_formatter=Nothing)
                format3 = format . with_quotes quote_escape="\"
                f6 = enso_project.data / "transient" / "mismatched_quote3.csv"
                # There is no trailing newline compared to regular `mismatched_quote3.csv`.
                contents = 'a,b,c\n1,2,3\nabc,def,"g h i\\"'
                contents.write f6 on_existing_file=Existing_File_Behavior.Overwrite
                r6 = Data.read f6 format3 on_problems=pb
                r6.should_fail_with File_Error
                r6.catch.should_be_a File_Error.Corrupted_Format
                f6.delete

        group_builder.specify "should handle quotes if they are opened in the middle of an unquoted cell in a sane way" pending="ToDo: To be fixed in https://github.com/enso-org/enso/issues/5839" <|
            t1 = Data.read (enso_project.data / "mismatched_quote_at_end.csv") (Delimited "," headers=True value_formatter=Nothing)
            t1.column_names . should_equal ["a", "b", "c"]
            t1.at 'a' . to_vector . should_equal ['1', 'abc', '7']
            t1.at 'b' . to_vector . should_equal ['2', 'def', '8']
            t1.at 'c' . to_vector . should_equal ['3', 'g h i"', '9']

            t2 = Data.read (enso_project.data / "weird_quoting_stuff.csv") (Delimited "," headers=True value_formatter=Nothing)
            t2.column_names . should_equal ["A", "B", "C", "D", "E"]
            t2.at 'A' . to_vector . should_equal ['Te,s"t', 'Te,s"t']
            t2.at 'B' . to_vector . should_equal ['An " other', 'An " other"']
            t2.at 'C' . to_vector . should_equal ['He\nllo', 'He\nllo']
            t2.at 'D' . to_vector . should_equal ['This is an escaped quote \\"', 'This is an escaped quote \\"']
            t2.at 'E' . to_vector . should_equal ['Excel escapes "" with 8 quotes """"""', 'Excel escapes "" with 8 quotes """"""']

            t3 = Data.read (enso_project.data / "weird_quoting_stuff2.csv") (Delimited "," headers=True value_formatter=Nothing)
            IO.println t3
            t3.column_names.should_equal ["A", "B", "C"]
            t3.print

        group_builder.specify "should handle too long and too short rows" <|
            action keep_invalid_rows on_problems =
                Data.read (enso_project.data / "varying_rows.csv") (Delimited "," headers=True keep_invalid_rows=keep_invalid_rows value_formatter=Nothing) on_problems=on_problems

            tester_kept table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['1', '1', '1', Nothing, '1', '1']
                table.at 'b' . to_vector . should_equal ['2', '2', '2', Nothing, Nothing, '2']
                table.at 'c' . to_vector . should_equal ['3', '3', Nothing, Nothing, Nothing, '3']
            problems_kept = [Invalid_Row.Error 2 0 ['1', '2', '3', '4'] 3, Invalid_Row.Error 4 2 ['1', '2'] 3, Invalid_Row.Error 5 3 [Nothing] 3, Invalid_Row.Error 6 4 ['1'] 3, Invalid_Row.Error 7 5 ['1', '2', '3', '4', '5', '6', '7', '8'] 3]
            Problems.test_problem_handling (action keep_invalid_rows=True) problems_kept tester_kept

            tester_dropped table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['1']
                table.at 'b' . to_vector . should_equal ['2']
                table.at 'c' . to_vector . should_equal ['3']
            problems_dropped = [Invalid_Row.Error 2 Nothing ['1', '2', '3', '4'] 3, Invalid_Row.Error 4 Nothing ['1', '2'] 3, Invalid_Row.Error 5 Nothing [Nothing] 3, Invalid_Row.Error 6 Nothing ['1'] 3, Invalid_Row.Error 7 Nothing ['1', '2', '3', '4', '5', '6', '7', '8'] 3]
            Problems.test_problem_handling (action keep_invalid_rows=False) problems_dropped tester_dropped

            r2 = Data.read (enso_project.data / "varying_rows2.csv") (Delimited "," headers=True keep_invalid_rows=False value_formatter=Nothing)
            r2.column_names . should_equal ['a', 'b', 'c']
            Problems.expect_only_warning (Invalid_Row.Error 3 Nothing ['0', '0', '0', '10'] 3) r2
            warning2 = Problems.get_attached_warnings r2 . first
            warning2.to_display_text . should_equal "The row (line 3) had too many columns (expected 3, got 4)."
            r2.at 'a' . to_vector . should_equal ['1', '4']
            r2.at 'b' . to_vector . should_equal ['2', '5']
            r2.at 'c' . to_vector . should_equal ['3', '6']

            r3 = Data.read (enso_project.data / "varying_rows3.csv") (Delimited "," headers=True keep_invalid_rows=True value_formatter=Nothing)
            r3.column_names . should_equal ['a', 'b', 'c']
            Problems.expect_only_warning (Invalid_Row.Error 3 1 ['0', '0'] 3) r3
            warning3 = Problems.get_attached_warnings r3 . first
            warning3.to_display_text . should_equal "The row (line 3, table row 1) had too few columns (expected 3, got 2)."
            r3.at 'a' . to_vector . should_equal ['1', '0', '4']
            r3.at 'b' . to_vector . should_equal ['2', '0', '5']
            r3.at 'c' . to_vector . should_equal ['3', Nothing, '6']

        group_builder.specify "should aggregate invalid rows over some limit" <|
            action on_problems =
                Data.read (enso_project.data / "many_invalid_rows.csv") (Delimited "," headers=True keep_invalid_rows=False value_formatter=Nothing) on_problems

            tester table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['0', '5']
                table.at 'b' . to_vector . should_equal ['x', 'u']
                table.at 'c' . to_vector . should_equal ['y', 'v']
            problems = [Invalid_Row.Error 3 Nothing ['1'] 3, Invalid_Row.Error 4 Nothing ['2'] 3, Invalid_Row.Error 5 Nothing ['3'] 3, Invalid_Row.Error 6 Nothing ['4'] 3, Invalid_Row.Error 8 Nothing ['6'] 3, Invalid_Row.Error 9 Nothing ['7'] 3, Invalid_Row.Error 10 Nothing ['8'] 3, Invalid_Row.Error 11 Nothing ['9'] 3, Invalid_Row.Error 12 Nothing ['10'] 3, Invalid_Row.Error 13 Nothing ['11'] 3, Additional_Invalid_Rows.Error 3]
            Problems.test_problem_handling action problems tester

        group_builder.specify "should allow to skip rows" <|
            t1 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False skip_rows=3 value_formatter=Nothing)
            t1.at "Column 1" . to_vector . should_equal ['7', '10']

            t2 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True skip_rows=3 value_formatter=Nothing)
            t2.columns.map .name . should_equal ['7', '8', '9']
            t2.at "7" . to_vector . should_equal ['10']

        group_builder.specify "should allow to set a limit of rows to read" <|
            t1 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False row_limit=2 value_formatter=Nothing)
            t1.at "Column 1" . to_vector . should_equal ['a', '1']

            t2 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True row_limit=2 value_formatter=Nothing)
            t2.at "a" . to_vector . should_equal ['1', '4']

            t3 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False skip_rows=3 row_limit=1 value_formatter=Nothing)
            t3.at "Column 1" . to_vector . should_equal ['7']

            t4 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False row_limit=0 value_formatter=Nothing)
            t4.columns.map .name . should_equal ['Column 1', 'Column 2', 'Column 3']
            t4.row_count . should_equal 0

            t5 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True row_limit=0 value_formatter=Nothing)
            t5.columns.map .name . should_equal ['a', 'b', 'c']
            t5.at 'a' . to_vector . should_equal []
            t5.row_count . should_equal 0

            t6 = Data.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False skip_rows=3 row_limit=1000 value_formatter=Nothing)
            t6.at "Column 1" . to_vector . should_equal ['7', '10']

        group_builder.specify "should check arguments" <|
            path = (enso_project.data / "simple_empty.csv")
            pb = Problem_Behavior.Report_Error
            path.read (Delimited "," headers=False . with_quotes quote='abc') pb . should_fail_with Illegal_Argument
            path.read (Delimited "," headers=False . with_quotes quote='ðŸš§') pb . should_fail_with Illegal_Argument
            path.read (Delimited "," headers=False . with_quotes quote_escape='//') pb . should_fail_with Illegal_Argument
            path.read (Delimited 'a\u{301}' headers=False) pb . should_fail_with Illegal_Argument

        group_builder.specify "should correctly guess column types" <|
            t = (enso_project.data / "data_small.csv") . read (Delimited "," headers=True)
            t.at "Code" . to_vector . should_equal ["gxl", "wca", "nfw", "der"]
            t.at "Index" . to_vector . should_equal [7, 0, 1, 7]
            t.at "Flag" . to_vector . should_equal [True, False, True, True]
            t.at "Value" . to_vector . should_equal [38.76109, -66.77495, 88.65713, 0.86658]
            t.at "ValueWithNothing" . to_vector . should_equal [63.13, 31.0, -68.71, Nothing]
            t.at "TextWithNothing" . to_vector . should_equal ["pq6igd2wyd", "  2pr4102wc4  ", "", Nothing]
            t.at "Hexadecimal" . to_vector . should_equal ["4DD4675B", Nothing, "01896EAB", "F32E1EFE"]
            t.at "Leading0s" . to_vector . should_equal ["001", "002", "123", Nothing]
            t.at "QuotedNumbers" . to_vector . should_equal ["1", "2", Nothing, "34"]
            t.at "Mixed Types" . to_vector . should_equal ["33", Nothing, "45", "True"]

            t2 = (enso_project.data / "data_small.csv") . read (Delimited "," headers=True value_formatter=(Data_Formatter.Value allow_leading_zeros=True))
            t2.at "Leading0s" . to_vector . should_equal [1, 2, 123, Nothing]

        group_builder.specify "should be able to detect types automatically" <|
            t1 = (enso_project.data / "data_small.csv") . read
            t1.at "Code" . to_vector . should_equal ["gxl", "wca", "nfw", "der"]
            t1.at "Index" . to_vector . should_equal [7, 0, 1, 7]

            t2 = (enso_project.data / "sample.tsv") . read
            t2.at "a" . to_vector . should_equal [1, 4]
            t2.at "b" . to_vector . should_equal [2, 5]
            t2.at "c" . to_vector . should_equal [3, 6]
            t2.columns.map .name . should_equal ["a", "b", "c"]

        group_builder.specify "should be able to read in a file without splitting it to columns" <|
            t1 = (enso_project.data / "data_small.csv") . read (Delimited "" headers=False)
            expected = ['Code,Index,Flag,Value,ValueWithNothing,TextWithNothing,"Hexadecimal",Leading0s,QuotedNumbers,"Mixed Types"']
                + ['gxl,7,True,38.76109,63.13,   pq6igd2wyd  ,4DD4675B,001,"1","33"']
                + ['wca,0,False,-66.77495,31,"  2pr4102wc4  ",,002,"2",']
                + ['nfw,1,  True ,  88.65713\t\t\t,-68.71,"",01896EAB,123,,45']
                + ['der,7,True,0.86658,,,F32E1EFE,,"34",True']
            t1.at 0 . to_vector . should_equal expected

        group_builder.specify "should be able to parse raw text" <|
            text1 = """
                a,b,c
                1,2,3
                4,5,6
            t1 = Table.from text1 (format = Delimited ",")
            t1.columns.map .name . should_equal ["a", "b", "c"]
            t1.at "a" . to_vector . should_equal [1, 4]
            t1.at "b" . to_vector . should_equal [2, 5]
            t1.at "c" . to_vector . should_equal [3, 6]

            text2 = 'a\tb\n1\t2\n3\t4'
            t2 = Table.from text2
            t2.columns.map .name . should_equal ["a", "b"]
            t2.at "a" . to_vector . should_equal [1, 3]
            t2.at "b" . to_vector . should_equal [2, 4]

        group_builder.specify "should be able to read column names starting with #" <|
            reference_table = Table.new [["#", ["a", ";1", "5"]], ["x", [42, 2, 6]], ["y", ["c # comment??", "3", "7;comment?"]]]
            table = Data.read (enso_project.data / "comments.csv")
            table.should_equal reference_table

        group_builder.specify "should be able to handle comments if enabled" <|
            table_hash = Table.new [["a", [";1", "5"]], ["42", [2, 6]], ["c # comment??", ["3", "7;comment?"]]]
            table_semicolon = Table.new [["#", ["a", "5"]], ["x", [42, 6]], ["y", ["c # comment??", "7;comment?"]]]

            Data.read (enso_project.data / "comments.csv") (Delimited ',' . with_comments . with_headers) . should_equal table_hash
            Data.read (enso_project.data / "comments.csv") (Delimited ',' . with_comments ';' . with_headers) . should_equal table_semicolon

        group_builder.specify "should manage to parse a file containing null characters" pending="Parsing NULL character in CSV currently does not handle some edge cases. It may need to be revised. See issue https://github.com/enso-org/enso/issues/5655" <|
            f = enso_project.data / "transient" / "slash_zero.csv"
            f.delete_if_exists
            txt = 'a,b\n\0,\0\nx\0y,zw\na#b,c\0d'
            txt.write f

            table = Data.read f
            table.print
            expected_table = Table.new [['a', ['\0', 'x\0y', 'a#b']], ['b', ['\0', 'zw', 'c\0d']]]
            table.should_equal expected_table

            f.delete_if_exists

        group_builder.specify "should allow to build the Delimited configuration using builders" <|
            Delimited "," . clone . should_equal (Delimited ",")
            Delimited "," encoding=Encoding.ascii skip_rows=123 row_limit=100 headers=False value_formatter=Nothing . clone . should_equal (Delimited "," headers=False value_formatter=Nothing skip_rows=123 row_limit=100 encoding=Encoding.ascii)
            Delimited "," . clone quote_style=Quote_Style.No_Quotes headers=False value_formatter=Nothing . should_equal (Delimited "," headers=False value_formatter=Nothing quote_style=Quote_Style.No_Quotes)

            Delimited '\t' . with_quotes "|" . should_equal (Delimited '\t' quote_style=(Quote_Style.With_Quotes quote='|' quote_escape='|'))
            Delimited '\t' . with_quotes "-" '\\' True . should_equal (Delimited '\t' quote_style=(Quote_Style.With_Quotes always_quote=True quote='-' quote_escape='\\'))
            Delimited '\t' . without_quotes . should_equal (Delimited '\t' quote_style=Quote_Style.No_Quotes)

            Delimited ',' . with_headers . should_equal (Delimited ',' headers=True)
            Delimited ',' . without_headers . should_equal (Delimited ',' headers=False)
            Delimited "," skip_rows=123 headers=False value_formatter=Nothing quote_style=Quote_Style.No_Quotes . with_headers . should_equal (Delimited "," skip_rows=123 value_formatter=Nothing quote_style=Quote_Style.No_Quotes headers=True)
            Delimited "," skip_rows=123 headers=True value_formatter=Nothing quote_style=Quote_Style.No_Quotes . without_headers . should_equal (Delimited "," skip_rows=123 value_formatter=Nothing quote_style=Quote_Style.No_Quotes headers=False)

            Delimited ',' . with_parsing . should_equal (Delimited ',')
            Delimited ',' . without_parsing . should_equal (Delimited ',' value_formatter=Nothing)
            custom_formatter = Data_Formatter.Value true_values=["A", "B", "C"] false_values=["D", "E", "F"]
            Delimited ',' . with_parsing custom_formatter . should_equal (Delimited ',' value_formatter=custom_formatter)
            Delimited ',' row_limit=456 . without_parsing . should_equal (Delimited ',' value_formatter=Nothing row_limit=456)

            Delimited ',' . with_comments . should_equal (Delimited ',' comment_character='#')
            Delimited ',' . with_comments ';' . should_equal (Delimited ',' comment_character=';')
            Delimited ',' comment_character='#' . without_comments . should_equal (Delimited ',' comment_character=Nothing)
            Delimited ',' . with_line_endings Line_Ending_Style.Unix . should_equal (Delimited ',' line_endings=Line_Ending_Style.Unix)

main =
    suite = Test.build suite_builder->
        add_specs suite_builder
    suite.run_with_filter

