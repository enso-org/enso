from Standard.Base import all
import Standard.Base.Runtime.Ref.Ref

import Standard.Table.Data.Type.Value_Type.Bits
from Standard.Table import Table, Value_Type

from Standard.Database import all

from Standard.AWS import Redshift_Details, AWS_Credential

from Standard.Test_New import all

import project.Database.Common.Common_Spec
import project.Database.Helpers.Name_Generator
import project.Common_Table_Operations

type Data
    Value ~data

    connection self = self.data.at 0
    t self = self.data.at 1

    setup create_connection_fn = Data.Value <|
        connection = create_connection_fn Nothing
        tinfo = Name_Generator.random_name "Tinfo"
        connection.execute_update 'CREATE TEMPORARY TABLE "'+tinfo+'" ("strs" VARCHAR, "ints" INTEGER, "bools" BOOLEAN, "reals" REAL)'
        t = connection.query (SQL_Query.Table_Name tinfo)
        row1 = ["a", Nothing, False, 1.2]
        row2 = ["abc", Nothing, Nothing, 1.3]
        row3 = ["def", 42, True, 1.4]
        Panic.rethrow <|
            t.update_rows (Table.from_rows ["strs", "ints", "bools", "reals"] [row1, row2, row3]) update_action=Update_Action.Insert
        [connection, t]

    teardown self = self.connection.close


add_redshift_specific_specs suite_builder create_connection_fn =
    suite_builder.group "[Redshift] Info" group_builder->
        data = Data.setup create_connection_fn

        group_builder.teardown <|
            data.teardown

        group_builder.specify "should return Table information" <|
            i = data.t.info
            i.at "Column" . to_vector . should_equal ["strs", "ints", "bools", "reals"]
            i.at "Items Count" . to_vector . should_equal [3, 1, 2, 3]
            i.at "Value Type" . to_vector . should_equal [Value_Type.Char, Value_Type.Integer Bits.Bits_32, Value_Type.Boolean, Value_Type.Float Bits.Bits_32]

        group_builder.specify "should infer standard types correctly" <|
            data.t.at "strs" . value_type . is_text . should_be_true
            data.t.at "ints" . value_type . is_integer . should_be_true
            data.t.at "bools" . value_type . is_boolean . should_be_true
            data.t.at "reals" . value_type . is_floating_point . should_be_true

add_database_specs suite_builder create_connection_fn =
    prefix = "[Redshift] "
    name_counter = Ref.new 0
    table_builder columns connection=(create_connection_fn Nothing) =
        ix = name_counter.get
        name_counter . put ix+1
        name = Name_Generator.random_name "table_"+ix.to_text

        in_mem_table = Table.new columns
        in_mem_table.select_into_database_table connection name primary_key=Nothing temporary=True

    materialize = .read

    Common_Spec.add_specs suite_builder prefix create_connection_fn
    add_redshift_specific_specs suite_builder create_connection_fn

    common_selection = Common_Table_Operations.Main.Test_Selection.Config supports_case_sensitive_columns=True order_by_unicode_normalization_by_default=True allows_mixed_type_comparisons=False supports_decimal_type=True
    aggregate_selection = Common_Table_Operations.Aggregate_Spec.Test_Selection.Config first_last_row_order=False aggregation_problems=False date_support=False
    agg_in_memory_table = (enso_project.data / "data.csv") . read
    agg_table_fn = _->
        connection = create_connection_fn Nothing
        agg_in_memory_table.select_into_database_table connection (Name_Generator.random_name "Agg1") primary_key=Nothing temporary=True

    empty_agg_table_fn = _->
        connection = create_connection_fn Nothing
        (agg_in_memory_table.take (First 0)).select_into_database_table connection (Name_Generator.random_name "Agg_Empty") primary_key=Nothing temporary=True

    setup = Common_Table_Operations.Main.Test_Setup.Config prefix agg_table_fn empty_agg_table_fn table_builder materialize is_database=True test_selection=common_selection aggregate_test_selection=aggregate_selection create_connection_func=create_connection_fn
    Common_Table_Operations.Main.add_specs suite_builder setup

connect_via_json_config =
    credentials = enso_project.data / 'redshift_credentials.json'
    msg = "Redshift connection is not set up. Please create a JSON file containing the credentials in `data/redshift_credentials.json`"

    if credentials.exists.not then msg else
        creds = Json.parse credentials.read_text
        access_key_id = creds.get 'access_key_id'
        secret_key = creds.get 'secret_access_key'
        uri = uri_parse (creds.get 'db_uri')
        db_uri = uri.at 0
        db_port = uri.at 1
        db_name = uri.at 2

        user = creds.get 'db_user'
        Redshift_Details.Redshift db_uri db_port db_name user credentials=(AWS_Credential.Key access_key_id secret_key)

connect_via_aws_environment db_host_port =
    db_host_port_split = uri_parse db_host_port
    db_uri = db_host_port_split.at 0
    db_port = db_host_port_split.at 1
    db_name = db_host_port_split.at 2

    db_user = Environment.get "ENSO_REDSHIFT_USER"
    access_key_id = Environment.get "AWS_ACCESS_KEY_ID"
    secret_key = Environment.get "AWS_SECRET_ACCESS_KEY"

    credentials = if (access_key_id.is_nothing || secret_key.is_nothing) then AWS_Credential.Profile (Environment.get "AWS_PROFILE" . if_nothing '') else
        AWS_Credential.Key access_key_id secret_key

    Redshift_Details.Redshift db_uri db_port db_name db_user credentials=credentials

uri_parse uri =
    host_db_split = uri.split '/'
    host_split = host_db_split.at 0 . split ':'

    db_host = host_split.first
    db_port = if host_split.length == 1 then 5439 else
        Integer.parse (host_split.at 1)

    db_name = if host_db_split.length == 1 then '' else host_db_split.at 1
    [db_host, db_port, db_name]

add_specs suite_builder =
    db_host_port = Environment.get "ENSO_REDSHIFT_URI"
    connection_details = if db_host_port.is_nothing then connect_via_json_config else
        connect_via_aws_environment db_host_port

    case connection_details of
        _ : Text ->
            suite_builder.group "[Redshift] Database tests" pending=connection_details (_-> Nothing)
        _ ->
            create_connection_fn = _->
                Database.connect connection_details
            add_database_specs suite_builder create_connection_fn

main =
    suite = Test.build suite_builder->
        add_specs suite_builder
    suite.run_with_filter
