from Standard.Base import all

from Standard.Base.Data.Text.Extensions import Index_Out_Of_Bounds_Error_Data
import Standard.Base.Data.Text.Regex.Engine.Default as Default_Engine

from Standard.Base.Data.Text.Text_Sub_Range.Text_Sub_Range import all
from Standard.Base.Data.Index_Sub_Range.Index_Sub_Range import all

from Standard.Test import Test, Test_Suite

type Auto
    Value a

type Manual
    Value b

    to_text self = "[[[MyREP " + self.b.to_text + "]]]"

## Specification of operations on the Text type.

   ? Guidelines on proper handling of edge cases in Text tests:

     The following edge cases should be considered:
     - Handling of empty arguments.
     - Using grapheme-cluster based indexing instead of code unit indexing where
       appropriate: this can be tested by adding tests with graphemes that
       consist of multiple code units, like 'e\u{301}' or emojis and ensuring
       that the offsets are correct.
     - Correct handling of Unicode normalization: some graphemes can be
       expressed using different combinations of code units. All alternative
       representations of the same grapheme should be treated as equivalent, i.e.
       equality checks or substring search should work consistently. Interesting
       examples are:
       - 'e\u{301}' and '\u00E9' (both meaning 'Ã©'),
       - reordering of modifiers (although this may not work for all sets), for
         example: 'e\u{321}\u{360}' should be equivalent to 'e\u{360}\u{321}'.
       - in general 's' should not be treated as a substring of 's\u{301}' since
         the latter is a two-codepoint encoding of a single grapheme 'Å›' that is
         different from 's'.
     - Be aware that changing case can change the length of a string (in
       extended grapheme clusters), a common example being `ÃŸ` becoming `SS` or
       `ï¬ƒ` becoming `FFI`. Case insensitive comparisons must take this into
       consideration. Note that due to this, if matching strings case
       insensitively, the length of the match can differ from the length of the
       term being matched.
     - Casing is locale-dependent. The pair of `i - I` is handled differently in
       Turkish and Azerbaijani - instead there are two separate pairs: 'Ä° - i'
       and 'I - Ä±'.
     - Handling of out of range indices should be checked. In particular, often
       the index `text.length` should still be valid to point just right at the
       end of the text. Moreover, negative indices are usually allowed to index
       from the back.
     - Note that currently the regex-based operations may not handle the edge
       cases described above too well.
spec =
    Test.group "Text" <|
        kshi = '\u0915\u094D\u0937\u093F'
        facepalm = '\u{1F926}\u{1F3FC}\u200D\u2642\uFE0F'
        accent_1 = '\u00E9'
        accent_2 = '\u0065\u{301}'
        utf_8_whitespace = 'foo\n bar     baz \u202F quux'
        utf_8_whitespace_split = ["foo", "bar", "baz", "quux"]
        sentences = '''
            I have a very long block of text, here. It goes on and on, containing
            things like decimal points (1.0314e3) and other language scripts as well
            ê±´ë°˜(Korean).
        sentence_words = ['I', 'have', 'a', 'very', 'long', 'block', 'of', 'text', ',', 'here', '.', 'It', 'goes', 'on', 'and', 'on', ',', 'containing', 'things', 'like', 'decimal', 'points', '(', '1.0314e3', ')', 'and', 'other', 'language', 'scripts', 'as', 'well', 'ê±´ë°˜', '(', 'Korean', ')', '.']

        Test.specify "should allow naive length computation over grapheme clusters" <|
            kshi.length . should_equal 1
            facepalm.length . should_equal 1

        Test.specify "should compare strings using utf normalization" <|
            "abc"=="def" . should_be_false
            'a'=='b' . should_be_false
            'a'=='a' . should_be_true
            'a'=='' . should_be_false
            ''=='' . should_be_true

            accent_1 . should_equal accent_2

            complex_letter_1 = 'e\u{301}\u{321}\u{338}\u{360}'
            complex_letter_2 = 'e\u{338}\u{321}\u{360}\u{301}'
            complex_letter_3 = 'e\u{360}\u{321}\u{301}\u{338}'
            common_prefix = 'a\u{360}\u{321}\u{301}\u{338}bcÄ…Ä™Ã³f'

            complex_letter_1 . should_equal complex_letter_2
            complex_letter_1 . should_equal complex_letter_3
            complex_letter_3 . should_equal complex_letter_2
            common_prefix+complex_letter_1+complex_letter_2+complex_letter_3 . compare_to common_prefix+complex_letter_3+complex_letter_1+complex_letter_2 . should_equal Ordering.Equal

            'e\u{301}'=='e\u{302}' . should_be_false

            'a\u0321\u0302'=='a\u0302\u0321' . should_be_true
            'a\u0321\u0302'=='A\u0302\u0321' . should_be_false

            accent_1+"a" . compare_to accent_2+"a" . should_equal Ordering.Equal
            accent_1+"A" . compare_to accent_2+"a" . should_equal Ordering.Less
            accent_1+"A" . compare_to_ignore_case accent_2+"a" . should_equal Ordering.Equal
            accent_1+"a" . compare_to accent_2+"b" . should_equal Ordering.Less
            accent_1+"a" . compare_to_ignore_case accent_2+"B" . should_equal Ordering.Less
            accent_2+"a" . compare_to accent_1+"b" . should_equal Ordering.Less
            accent_1+"a" . compare_to accent_2+"B" . should_equal Ordering.Greater
            accent_1+"a" . compare_to_ignore_case accent_2+"B" . should_equal Ordering.Less
            accent_1+"b" . compare_to accent_2+"a" . should_equal Ordering.Greater
            accent_2+"b" . compare_to accent_1+"a" . should_equal Ordering.Greater

            # Handling of Nothing
            (accent_1 == Nothing) . should_be_false
            (accent_1 != Nothing) . should_be_true
            accent_1 . compare_to Nothing . should_fail_with Type_Error_Data
            (accent_1 > Nothing) . should_fail_with Type_Error_Data
            accent_1 . compare_to_ignore_case Nothing . should_fail_with Type_Error_Data

            earlier_suffix = "aooooz"
            later_suffix = "bo"
            common_prefix+complex_letter_1+earlier_suffix . compare_to common_prefix+complex_letter_2+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_2+earlier_suffix . compare_to common_prefix+complex_letter_1+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_2+earlier_suffix . compare_to common_prefix+complex_letter_3+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_3+earlier_suffix . compare_to common_prefix+complex_letter_1+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_3+later_suffix . compare_to common_prefix+complex_letter_1+earlier_suffix . should_equal Ordering.Greater
            common_prefix+complex_letter_1+later_suffix . compare_to common_prefix+complex_letter_2+earlier_suffix . should_equal Ordering.Greater

        Test.specify "should correctly handle case-insensitive equality" <|
            "aBc" . equals_ignore_case "Abc" . should_be_true
            "abc" . equals_ignore_case "abd" . should_be_false
            "" . equals_ignore_case "" . should_be_true
            "aaaa" . equals_ignore_case "" . should_be_false

            'e\u0301' . equals_ignore_case 'Ã©' . should_be_true
            'E\u0301' . equals_ignore_case 'Ã‰' . should_be_true
            'e\u0301' . equals_ignore_case 'Ã‰' . should_be_true
            'E\u0301' . equals_ignore_case 'Ã©' . should_be_true
            'a\u0321\u0302' . equals_ignore_case 'A\u0302\u0321' . should_be_true
            'e\u0301' . equals_ignore_case 'e\u0303' . should_be_false

            "I" . equals_ignore_case "i" . should_be_true
            "Ä°" . equals_ignore_case "i" (locale = Locale.new "tr") . should_be_true
            "I" . equals_ignore_case "Ä±" (locale = Locale.new "az") . should_be_true
            "I" . equals_ignore_case "i" (locale = Locale.new "tr") . should_be_false

            "KongressstraÃŸe"=="Kongressstrasse" . should_be_false
            "KongressstraÃŸe" . equals_ignore_case "Kongressstrasse" . should_be_true

        Test.specify "should split the text into grapheme clusters" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.characters . should_equal [kshi, facepalm, accent_1, accent_2]

        Test.specify "should allow access by index to a grapheme cluster" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.at 0 . should_equal kshi
            str.at 1 . should_equal facepalm
            str.at 2 . should_equal accent_1
            str.at 3 . should_equal accent_2

        Test.specify "should allow access by negative index to a grapheme cluster" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.at -4 . should_equal kshi
            str.at -3 . should_equal facepalm
            str.at -2 . should_equal accent_1
            str.at -1 . should_equal accent_2

        Test.specify "should return a dataflow error when accessing characters out of bounds" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.at -5 . should_fail_with Index_Out_Of_Bounds_Error_Data
            str.at -5 . catch . should_equal (Index_Out_Of_Bounds_Error_Data -5 4)
            str.at 4 . should_fail_with Index_Out_Of_Bounds_Error_Data
            str.at 4 . catch . should_equal (Index_Out_Of_Bounds_Error_Data 4 4)

        Test.specify "should be able to split the text into words" <|
            "I have not one, but two cats.".words . should_equal ['I', 'have', 'not', 'one', ',', 'but', 'two', 'cats', '.']
            "à¹à¸¡à¸§à¸¡à¸µà¸ªà¸µà¹ˆà¸‚à¸²".words . should_equal ['à¹à¸¡à¸§', 'à¸¡à¸µ', 'à¸ªà¸µà¹ˆ', 'à¸‚à¸²']
            sentences.words . should_equal sentence_words
            "I â¤ï¸ Unicode! ğŸ™‚ğŸ™‚".words . should_equal ['I', 'â¤ï¸', 'Unicode', '!', 'ğŸ™‚', 'ğŸ™‚']
            '"à¹à¸¡à¸§à¸¡à¸µà¸ªà¸µà¹ˆà¸‚à¸²" means that a cat has four legs.'.words . should_equal ['"', 'à¹à¸¡à¸§', 'à¸¡à¸µ', 'à¸ªà¸µà¹ˆ', 'à¸‚à¸²', '"', 'means', 'that', 'a', 'cat', 'has', 'four', 'legs', '.']

        Test.specify "should be able to split the text into lines" <|
            utf_8_vertical = 'foo\n   bar \r\n baz \r quux'
            utf_8_vertical_split = ["foo", "   bar ", " baz ", " quux"]
            utf_8_vertical.lines . should_equal utf_8_vertical_split

            'a\nb\nc'.lines . should_equal ['a', 'b', 'c']
            '\na\n\nb\n\n\n'.lines . should_equal ['', 'a', '', 'b', '', '']
            '\na\nb\n'.lines keep_endings=True . should_equal ['\n', 'a\n', 'b\n']

            '\n\n\n'.lines . should_equal ['', '', '']
            '\r\r\r'.lines . should_equal ['', '', '']
            '\r\n\r\n\r\n'.lines . should_equal ['', '', '']
            '\n\n\n'.lines keep_endings=True . should_equal ['\n', '\n', '\n']
            'a\r\nb\n\rc'.lines keep_endings=True . should_equal ['a\r\n', 'b\n', '\r', 'c']
            'a\r\nb\n\rc'.lines . should_equal ['a', 'b', '', 'c']
            'abc'.lines . should_equal ['abc']
            'abc\n'.lines . should_equal ['abc']
            'abc\n'.lines keep_endings=True . should_equal ['abc\n']
            '\na'.lines . should_equal ['', 'a']

            multiline = """
               Hello
               world
            multiline.lines . should_equal ['Hello', 'world']
            'ğŸš€ğŸš§\n\u{301}a\u{301}\rê±´ë°˜'.lines . should_equal ['ğŸš€ğŸš§', '\u{301}a\u{301}', 'ê±´ë°˜']

        Test.specify "should be able to split the text on arbitrary text sequence" <|
            "foo, bar, baz" . split ", " . should_equal ["foo", "bar", "baz"]
            text = "Namespace::package::package::Type"
            text.split "::" . should_equal ["Namespace", "package", "package", "Type"]
            "..a.b.c.d" . split "." . should_equal ["", "", "a", "b", "c", "d"]
            "abc".split "." . should_equal ["abc"]
            "aaa".split "a" . should_equal ["", "", "", ""]
            ".a.".split "." . should_equal ["", "a", ""]
            "".split "." . should_equal [""]
            "abc[a-z]def".split "[a-z]" . should_equal ["abc", "def"]
            'aÅ›bs\u{301}c'.split 'Å›' . should_equal ['a', 'b', 'c']
            'abc'.split '' . should_fail_with Illegal_Argument_Error_Data

        Test.specify "should be able to split the text on arbitrary text sequence, case-insensitively" <|
            matcher = Text_Matcher.Case_Insensitive
            "AbCdABCDabDCba" . split "ab" matcher . should_equal ["", "Cd", "CD", "DCba"]
            "abc".split "d" matcher . should_equal ["abc"]
            "AAA".split "a" matcher . should_equal ["", "", "", ""]
            "baB".split "b" matcher . should_equal ["", "a", ""]
            "".split "a" matcher . should_equal [""]
            'aÅšbS\u{301}c'.split 'Å›' matcher . should_equal ['a', 'b', 'c']
            'abc'.split '' matcher . should_fail_with Illegal_Argument_Error_Data

        Test.specify "should be able to split the text on Regex patterns" <|
            "cababdabe" . split "ab" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ["c", "", "d", "e"]
            "cababdabe" . split "(ab)+" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ["c", "d", "e"]
            "abc" . split "[a-z]" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ["", "", "", ""]
            "abc--def==>ghi".split "[-=>]+" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) == ["abc", "def", "ghi"]
            "abc".split "." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ["", "", "", ""]
            "abc".split "d" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ["abc"]
            ".a.".split "\." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ["", "a", ""]
            "".split "a" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal [""]
            'aÅ›bs\u{301}c'.split 'Å›' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ['a', 'b', 'c']
            'abc'.split '' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_fail_with Illegal_Argument_Error_Data

        Test.specify "should be able to split the text on UTF-8 whitespace" <|
            utf_8_whitespace.split "\s+" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal utf_8_whitespace_split
            'abc  def\tghi'.split '\\s+' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_equal ["abc", "def", "ghi"]

        Test.specify "should convert any type to text automatically and using provided methods" <|
            t = Auto.Value (Manual.Value 123) . to_text
            t.should_equal "(Auto.Value [[[MyREP 123]]])"

        Test.specify "should escape special characters when debug-printing text" <|
            text_1 = '''
                foo
                bar\tbaz
            (text_1.replace '\r' "").to_text.should_equal "'foo\nbar\tbaz'"
            text_2 = '\n\t\a\b\f\r\v\e\''
            text_2.to_text.should_equal "'\n\t\a\b\f\r\v\e\''"

        Test.specify "should allow taking or dropping every other character" <|
            "ABCDE".take (Every 1) . should_equal "ABCDE"
            "ABCDE".take (Every 2) . should_equal "ACE"
            "ABCD".take (Every 2) . should_equal "AC"
            "ABCD".take (Every 2 first=1) . should_equal "BD"
            "ABCDE".take (Every 2 first=1) . should_equal "BD"
            "ABCDE".take (Every 3) . should_equal "AD"
            "ABCDEFG".take (Every 3) . should_equal "ADG"
            "ABCDEFG".take (Every 3 first=1) . should_equal "BE"
            "ABCDEFG".take (Every 3 first=6) . should_equal "G"
            "ABCDEFG".take (Every 10) . should_equal "A"

            "ABCDE".drop (Every 1) . should_equal ""
            "ABCDE".drop (Every 2) . should_equal "BD"
            "ABCD".drop (Every 2) . should_equal "BD"
            "ABCD".drop (Every 2 first=1) . should_equal "AC"
            "ABCDE".drop (Every 2 first=1) . should_equal "ACE"
            "ABCDE".drop (Every 3) . should_equal "BCE"
            "ABCDEFG".drop (Every 3) . should_equal "BCEF"
            "ABCDEFG".drop (Every 3 first=1) . should_equal "ACDFG"
            "ABCDEFGH".drop (Every 3 first=1) . should_equal "ACDFG"
            "ABCDEFGHI".drop (Every 3 first=1) . should_equal "ACDFGI"

        Test.specify "should allow taking or dropping a random sample of a substring" <|
            "AAAAA".take (Sample 3) . should_equal "AAA"
            "AAAAA".drop (Sample 3) . should_equal "AA"

            ## These tests are very brittle and can be invalidated by a valid
               implementation modification, so they may need to be updated.
            "ABCDEFGH".take (Sample 0) . should_equal ""
            "ABCDEFGH".take (Sample 8 seed=42) . should_equal "FGCHABED"
            "ABCDEFGH".take (Sample 4 seed=42) . should_equal "FGCH"
            "ABCDEFGH".take (Sample 2 seed=42) . should_equal "FG"
            "ABCDEFGH".take (Sample 1 seed=42) . should_equal "F"
            "ABCDEFGH".take (Sample 100 seed=42) . should_equal "FGCHABED"

            samples_1 = 0.up_to 10000 . map seed->
                "ABCD".take (Sample 2 seed)
            samples_1.should_contain_the_same_elements_as ["AB", "BA", "AC", "CA", "AD", "DA", "BC", "CB", "BD", "DB", "CD", "DC"]

            "ABCDEFGH".drop (Sample 0) . should_equal "ABCDEFGH"
            "ABCDEFGH".drop (Sample 1 seed=42) . should_equal "ABCDEGH"
            "ABCDEFGH".drop (Sample 2 seed=42) . should_equal "ABCDEH"
            "ABCDEFGH".drop (Sample 4 seed=42) . should_equal "ABDE"
            "ABCDEFGH".drop (Sample 8 seed=42) . should_equal ""
            "ABCDEFGH".drop (Sample 100 seed=42) . should_equal ""

            samples_2 = 0.up_to 10000 . map seed->
                "ABCD".drop (Sample 2 seed)
            samples_2.should_contain_the_same_elements_as ["AB", "AC", "AD", "BC", "CD", "BD"]

        Test.specify "should allow taking or dropping many indices or subranges (possibly overlapping)" <|
            "123"*1000 . take (By_Index (Vector.new 3000 ix-> 2999-ix)) . should_equal "321"*1000
            "123"*1000 . take (By_Index (Vector.new 3000 _-> 0)) . should_equal "1"*3000
            "123456"*1000 . take (By_Index (Vector.new 100 ix-> Range_Data 6*ix+1 6*ix+3)) . should_equal "23"*100
            "AB"*1000 . take (By_Index (Vector.new 100 ix-> Range_Data ix+1 ix+5)) . should_equal "BABAABAB"*50

            "123"*1000 . drop (By_Index (Vector.new 300 ix-> 2999-ix)) . should_equal "123"*900
            "123"*1000 . drop (By_Index (Vector.new 3000 _-> 0)) . should_equal "23"+"123"*999
            "123456"*1000 . drop (By_Index (Vector.new 1000 ix-> Range_Data 6*ix+1 6*ix+3)) . should_equal "1456"*1000
            "ABCD"*25 . drop (By_Index (Vector.new 90 ix-> Range_Data ix+1 ix+5)) . should_equal "ACDABCD"

            "ABCD"*1000 . take (Range_Data 0 4000 4) . should_equal "A"*1000
            "ABCD"*1000 . take (Every 4) . should_equal "A"*1000
            "ABCD"*1000 . take (By_Index [Range_Data 0 4000 4, Range_Data 1 4000 4]) . should_equal ("A"*1000 + "B"*1000)
            "ABCD"*1000 . take (By_Index [Range_Data 0 4000 4, Range_Data 2 4000 4]) . should_equal ("A"*1000 + "C"*1000)

            "ABCD"*1000 . drop (Range_Data 0 4000 4) . should_equal "BCD"*1000
            "ABCD"*1000 . drop (Every 4) . should_equal "BCD"*1000
            "ABCD"*1000 . drop (By_Index [Range_Data 0 4000 4, Range_Data 1 4000 4]) . should_equal "CD"*1000
            "ABCD"*1000 . drop (By_Index [Range_Data 0 4000 4, Range_Data 2 4000 4]) . should_equal "BD"*1000

            "0123456789".take (By_Index [Range_Data 0 4, Range_Data 4 6, Range_Data 8 9]) . should_equal "0123458"
            "0123456789".take (By_Index [Range_Data 4 6, Range_Data 0 4, 0, 0]) . should_equal "45012300"
            "0123456789".drop (By_Index [Range_Data 0 4, Range_Data 4 6, Range_Data 8 9]) . should_equal "679"
            "0123456789".drop (By_Index [Range_Data 4 6, Range_Data 0 4, 0, 0]) . should_equal "6789"
            "0123456789".drop (By_Index [Range_Data 2 5, Range_Data 0 3, 0, 0]) . should_equal "56789"

        Test.specify "should allow selecting substrings by characters" <|
            txt = kshi + facepalm + accent_1 + accent_2
            txt.take (First 2) . should_equal (kshi + facepalm)
            txt.drop (First 2) . should_equal (accent_1 + accent_2)
            txt.take 2 . should_equal (kshi + facepalm)
            txt.drop 2 . should_equal (accent_1 + accent_2)
            txt.take (Last 2) . should_equal (accent_1 + accent_2)
            txt.drop (Last 2) . should_equal (kshi + facepalm)
            txt.take (Range_Data 0 2) . should_equal (kshi + facepalm)
            txt.take (By_Index (Range_Data 0 2)) . should_equal (kshi + facepalm)
            txt.drop (Range_Data 0 2) . should_equal (accent_1 + accent_2)
            txt.take (Range_Data 2 4) . should_equal (accent_1 + accent_2)
            txt.drop (Range_Data 2 4) . should_equal (kshi + facepalm)
            txt.take (Every 2) . should_equal (kshi + accent_1)
            txt.take (Every 2 first=1) . should_equal (facepalm + accent_2)
            txt.drop (Every 2) . should_equal (facepalm + accent_2)
            txt.take (Range_Data 0 4 2) . should_equal (kshi + accent_1)
            txt.take (By_Index [0, 3]) . should_equal (kshi + accent_2)
            txt.take (By_Index 0) . should_equal kshi
            txt.take (By_Index 1) . should_equal facepalm
            txt.take (By_Index 2) . should_equal accent_1
            txt.take (By_Index 3) . should_equal accent_2
            txt.drop (By_Index [0, 3]) . should_equal (facepalm + accent_1)
            txt.drop (By_Index [0, 3, 0]) . should_equal (facepalm + accent_1)
            txt.drop (By_Index [0, 3, 0, 2, 1]) . should_equal ""
            txt.take (By_Index [0, 3, 0, 2, 1]) . should_equal (kshi + accent_2 + kshi + accent_1 + facepalm)
            txt.take (By_Index [0, 0, Range_Data 0 2]) . should_equal (kshi + kshi + kshi + facepalm)
            txt.drop (By_Index [Range_Data 2 4, Range_Data 0 2]) . should_equal ""

        Test.specify "take should work as in the examples" <|
            "Hello World!".take First . should_equal "H"
            "Hello World!".take (First 5) . should_equal "Hello"
            "Hello World!".take (First 100) . should_equal "Hello World!"
            "Hello World!".take (First 0) . should_equal ""
            "Hello World!".take . should_equal "H"
            "Hello World!".take 5 . should_equal "Hello"
            "Hello World!".take 100 . should_equal "Hello World!"
            "Hello World!".take 0 . should_equal ""
            "Hello World!".take Last . should_equal "!"
            "Hello World!".take (Last 6) . should_equal "World!"
            "Hello World!".take (Last 0) . should_equal ""
            "Hello World!".take (Last 100) . should_equal "Hello World!"
            "Hello World!".take (Before " ") . should_equal "Hello"
            "Hello World!".take (Before "z") . should_equal "Hello World!"
            "Hello World!".take (Before_Last "o") . should_equal "Hello W"
            "Hello World!".take (Before_Last "z") . should_equal "Hello World!"
            "Hello World!".take (After " ") . should_equal "World!"
            "Hello World!".take (After "z") . should_equal ""
            "Hello World!".take (After_Last "o") . should_equal "rld!"
            "Hello World!".take (After_Last "z") . should_equal ""
            "Hello World!".take (While c->c!=" ") . should_equal "Hello"
            "Hello World!".take (While c->c!="z") . should_equal "Hello World!"
            "Hello World!".take (Range_Data 3 5) . should_equal "lo"
            "Hello World!".take (Range_Data 5 12) . should_equal " World!"
            "Hello World!".take (Range_Data 6 12 2) . should_equal "Wrd"
            "Hello World!".take (Every 2 first=6) . should_equal "Wrd"
            "Hello World!".take (Every 3) . should_equal "HlWl"
            "Hello World!".take (By_Index 0) . should_equal "H"
            "Hello World!".take (By_Index [1, 0, 0, 6, 0]) . should_equal "eHHWH"
            "Hello World!".take (By_Index [Range_Data 0 3, 6, Range_Data 6 12 2]) . should_equal "HelWWrd"
            "Hello World!".take (Sample 3 seed=42) . should_equal "l d"

        Test.specify "take should report errors for start indices out of bounds but just go till the end if the end index is OOB" <|
            txt = "Hello World!"
            txt.take (Range_Data 0 14) . should_equal txt
            txt.take (Range_Data 6 100) . should_equal "World!"
            txt.take (Range_Data txt.length-1 txt.length) . should_equal "!"
            txt.take (Range_Data txt.length txt.length) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (Range_Data txt.length txt.length) . catch . should_equal (Index_Out_Of_Bounds_Error_Data txt.length txt.length)
            txt.take (Range_Data txt.length 100) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (First 100) . should_equal txt
            txt.take 100 . should_equal txt
            txt.take (Last 100) . should_equal txt
            txt.take (By_Index 100) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index 13) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [0, 1, 13]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [0, Range_Data 14 15, 1]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [0, 1, Range_Data 6 100]) . should_equal "HeWorld!"
            txt.take (By_Index [0, 1, Range_Data 6 100 2]) . should_equal "HeWrd"
            txt.take (Range_Data 13 12) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".take (Range_Data 0 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".take (Range_Data 0 0) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 0 0)
            "".take (By_Index 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "ABC".take (By_Index 3) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (Range_Data 13 20) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (Range_Data 13 20 2) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [Range_Data 0 2, Range_Data 13 20]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [Range_Data 0 0, Range_Data 13 10, Range_Data 2 2 2]) . should_equal ""
            txt.take (By_Index [Range_Data 0 2 2, Range_Data 13 20 2]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [Range_Data 0 2 2, Range_Data 13 20 2]) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 13 12)
            txt.take (By_Index [Range_Data 0 2 2, Range_Data txt.length 100 2]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".take (By_Index 0) . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "take should work on grapheme clusters" <|
            txt_1 = 'He\u0302llo\u0308 Wo\u0301rld!'
            txt_2 = 'He\u0302llo\u0308 Wo\u0308rld!'
            txt_1.take (Every 2) . should_equal 'Hlo\u0308Wrd'
            txt_1.take (First 2) . should_equal 'He\u{302}'
            txt_1.take (First 5) . should_equal 'He\u{302}llo\u{308}'
            txt_1.take 2 . should_equal 'He\u{302}'
            txt_1.take 5 . should_equal 'He\u{302}llo\u{308}'
            txt_1.take (Last 6) . should_equal 'Wo\u{301}rld!'
            txt_1.take (Last 5) . should_equal 'o\u{301}rld!'
            txt_1.take (Before 'e\u{302}') . should_equal 'H'
            txt_1.take (Before 'Ãª') . should_equal 'H'
            txt_1.take (Before 'e') . should_equal txt_1
            txt_2.take (Before_Last 'o\u{308}') . should_equal 'He\u{302}llo\u{308} W'
            txt_2.take (Before_Last 'Ã¶') . should_equal 'He\u{302}llo\u{308} W'
            txt_2.take (Before_Last 'o') . should_equal txt_2
            txt_1.take (After 'e\u{302}') . should_equal 'llo\u{308} Wo\u{301}rld!'
            txt_1.take (After 'Ãª') . should_equal 'llo\u{308} Wo\u{301}rld!'
            txt_1.take (After 'e\u{308}') . should_equal ''
            txt_1.take (After 'e') . should_equal ''
            txt_2.take (After_Last 'o\u{308}') . should_equal 'rld!'
            txt_2.take (After_Last 'Ã¶') . should_equal 'rld!'
            txt_2.take (After_Last 'o') . should_equal ''
            txt_2.take (While c->c!='e\u{302}') . should_equal 'H'
            txt_2.take (While c->c!='Ãª') . should_equal 'H'
            txt_2.take (While c->c!='e') . should_equal txt_2
            txt_2.take (Range_Data 3 5) . should_equal 'lo\u{308}'
            txt_2.take (Range_Data 5 12) . should_equal ' Wo\u{308}rld!'

        Test.specify "take should work on emojis" <|
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take First . should_equal 'âœ¨'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (First 2) . should_equal 'âœ¨ğŸš€'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take . should_equal 'âœ¨'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take 2 . should_equal 'âœ¨ğŸš€'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take Last . should_equal 'â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (Last 0) . should_equal ''
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (Last 3) . should_equal 'ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (Before 'ğŸ˜') . should_equal 'âœ¨ğŸš€ğŸš§'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (Before_Last 'ğŸ˜') . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒ'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (After 'ğŸ˜') . should_equal 'ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (After_Last 'ğŸ˜') . should_equal 'ğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (While c->c!="ğŸ˜ƒ") . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.take (Range_Data 3 6) . should_equal 'ğŸ˜ğŸ˜ƒğŸ˜'

        Test.specify "take should correctly handle edge cases" <|
            "ABC".take . should_equal "A"

            "".take First . should_equal ""
            "".take Last . should_equal ""

            "".take (After "a") . should_equal ""
            "".take (After_Last "a") . should_equal ""
            "".take (Before "a") . should_equal ""
            "".take (Before_Last "a") . should_equal ""

            "".take (After "") . should_equal ""
            "".take (After_Last "") . should_equal ""
            "".take (Before "") . should_equal ""
            "".take (Before_Last "") . should_equal ""

            "".take (While _->True) . should_equal ""

            'ABC\u{301}'.take (Range_Data 0 0) . should_equal ""

            'ABC\u{301}'.take (After "") . should_equal 'ABC\u{301}'
            'ABC\u{301}'.take (After_Last "") . should_equal ""
            'ABC\u{301}'.take (Before "") . should_equal ""
            'ABC\u{301}'.take (Before_Last "") . should_equal 'ABC\u{301}'

            "ABC".take (By_Index -1) . should_equal "C"
            "ABC".take (By_Index [-1, -1, -1, -3, 2]) . should_equal "CCCAC"
            "ABC".take (By_Index []) . should_equal ""
            "ABC".take (By_Index (Range_Data -2 -1)) . should_fail_with Illegal_Argument_Error_Data
            "".take (Every 2) . should_equal ""
            "".take (Every 2 first=1) . should_equal ""
            "ABC".take (Every 5) . should_equal "A"
            "A".take (Every 5) . should_equal "A"
            "ABC".take (Every 5 first=4) . should_equal ""
            "".take (Sample 0) . should_equal ""
            "".take (Sample 100) . should_equal ""

        Test.specify "drop should work as in the examples" <|
            "Hello World!".drop First . should_equal "ello World!"
            "Hello World!".drop (First 5) . should_equal " World!"
            "Hello World!".drop (First 100) . should_equal ""
            "Hello World!".drop (First 0) . should_equal "Hello World!"
            "Hello World!".drop . should_equal "ello World!"
            "Hello World!".drop 5 . should_equal " World!"
            "Hello World!".drop 100 . should_equal ""
            "Hello World!".drop 0 . should_equal "Hello World!"
            "Hello World!".drop Last . should_equal "Hello World"
            "Hello World!".drop (Last 6) . should_equal "Hello "
            "Hello World!".drop (Last 100) . should_equal ""
            "Hello World!".drop (Before " ") . should_equal " World!"
            "Hello World!".drop (Before "z") . should_equal ""
            "Hello World!".drop (Before_Last "o") . should_equal "orld!"
            "Hello World!".drop (Before_Last "z") . should_equal ""
            "Hello World!".drop (After " ") . should_equal "Hello "
            "Hello World!".drop (After "z") . should_equal "Hello World!"
            "Hello World!".drop (After_Last "o") . should_equal "Hello Wo"
            "Hello World!".drop (After_Last "z") . should_equal "Hello World!"
            "Hello World!".drop (While c->c!=" ") . should_equal " World!"
            "Hello World!".drop (While c->c!="z") . should_equal ""
            "Hello World!".drop (Range_Data 3 5) . should_equal "Hel World!"
            "Hello World!".drop (Range_Data 5 12) . should_equal "Hello"
            "Hello World!".drop (Range_Data 6 12 2) . should_equal "Hello ol!"
            "Hello World!".drop (Every 2 first=6) . should_equal "Hello ol!"
            "Hello World!".drop (Every 3) . should_equal "elo ord!"
            "Hello World!".drop (By_Index 0) . should_equal "ello World!"
            "Hello World!".drop (By_Index [1, 0, 0, 6, 0]) . should_equal "llo orld!"
            "Hello World!".drop (By_Index [Range_Data 0 3, 6, Range_Data 6 12 2]) . should_equal "lo ol!"
            "Hello World!".drop (Sample 3 seed=42) . should_equal "HeloWorl!"

        Test.specify "drop should report errors for start indices out of bounds but just go till the end if the end index is OOB" <|
            txt = "Hello World!"
            txt.drop (Range_Data 0 14) . should_equal ""
            txt.drop (First 100) . should_equal ""
            txt.drop 100 . should_equal ""
            txt.drop (Last 100) . should_equal ""
            txt.drop (By_Index 100) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index 100) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 100 12)
            txt.drop (By_Index 13) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index [0, 1, 13]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index [0, Range_Data 14 15, 1]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index [0, 1, Range_Data 6 100]) . should_equal "llo "
            txt.drop (Range_Data 13 12) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (Range_Data 14 15) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".drop (By_Index 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".drop (Range_Data 0 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".drop (Range_Data 0 0) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 0 0)
            txt.drop (Range_Data 0 0) . should_equal txt
            txt.drop (Range_Data 5 100) . should_equal "Hello"
            txt.drop (Range_Data 5 100 2) . should_equal "HelloWrd"
            txt.drop (By_Index [0, 1, 0, Range_Data 5 100 2]) . should_equal "lloWrd"

        Test.specify "drop should work on grapheme clusters" <|
            txt_1 = 'He\u0302llo\u0308 Wo\u0301rld!'
            txt_2 = 'He\u0302llo\u0308 Wo\u0308rld!'
            txt_1.drop (Every 2) . should_equal 'e\u0302l o\u0301l!'
            txt_1.drop (First 2) . should_equal 'llo\u{308} Wo\u{301}rld!'
            txt_1.drop (First 5) . should_equal ' Wo\u{301}rld!'
            txt_1.drop 2 . should_equal 'llo\u{308} Wo\u{301}rld!'
            txt_1.drop 5 . should_equal ' Wo\u{301}rld!'
            txt_1.drop (Last 6) . should_equal 'He\u{302}llo\u{308} '
            txt_1.drop (Last 5) . should_equal 'He\u{302}llo\u{308} W'
            txt_1.drop (Before 'e\u{302}') . should_equal 'e\u{302}llo\u{308} Wo\u{301}rld!'
            txt_1.drop (Before 'Ãª') . should_equal 'e\u{302}llo\u{308} Wo\u{301}rld!'
            txt_1.drop (Before 'e') . should_equal ''
            txt_2.drop (Before_Last 'o\u{308}') . should_equal 'o\u{308}rld!'
            txt_2.drop (Before_Last 'Ã¶') . should_equal 'o\u{308}rld!'
            txt_2.drop (Before_Last 'o') . should_equal ''
            txt_1.drop (After 'e\u{302}') . should_equal 'He\u{302}'
            txt_1.drop (After 'Ãª') . should_equal 'He\u{302}'
            txt_1.drop (After 'e\u{308}') . should_equal txt_1
            txt_1.drop (After 'e') . should_equal txt_1
            txt_2.drop (After_Last 'o\u{308}') . should_equal 'He\u{302}llo\u{308} Wo\u{308}'
            txt_2.drop (After_Last 'Ã¶') . should_equal 'He\u{302}llo\u{308} Wo\u{308}'
            txt_2.drop (After_Last 'o') . should_equal txt_2
            txt_2.drop (While c->c!='e\u{302}') . should_equal 'e\u{302}llo\u{308} Wo\u{308}rld!'
            txt_2.drop (While c->c!='Ãª') . should_equal 'e\u{302}llo\u{308} Wo\u{308}rld!'
            txt_2.drop (While c->c!='e') . should_equal ''
            txt_2.drop (Range_Data 3 5) . should_equal 'He\u{302}l Wo\u{308}rld!'
            txt_2.drop (Range_Data 5 12) . should_equal 'He\u{302}llo\u{308}'

        Test.specify "drop should work on emojis" <|
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop First . should_equal 'ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (First 2) . should_equal 'ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop . should_equal 'ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop 2 . should_equal 'ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop Last . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (Last 3) . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (Before 'ğŸ˜') . should_equal 'ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (Before_Last 'ğŸ˜') . should_equal 'ğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (After 'ğŸ˜') . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (After_Last 'ğŸ˜') . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (While c->c!="ğŸ˜ƒ") . should_equal 'ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'.drop (Range_Data 3 6) . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜™ğŸ˜‰â˜º'

        Test.specify "drop should correctly handle edge cases" <|
            "ABC".drop . should_equal "BC"

            "".drop First . should_equal ""
            "".drop Last . should_equal ""

            "".drop (After "a") . should_equal ""
            "".drop (After_Last "a") . should_equal ""
            "".drop (Before "a") . should_equal ""
            "".drop (Before_Last "a") . should_equal ""

            "".drop (After "") . should_equal ""
            "".drop (After_Last "") . should_equal ""
            "".drop (Before "") . should_equal ""
            "".drop (Before_Last "") . should_equal ""

            "".drop (While _->True) . should_equal ""

            "".drop (Range_Data 0 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            'ABC\u{301}'.drop (Range_Data 0 0) . should_equal 'ABC\u{301}'

            'ABC\u{301}'.drop (After "") . should_equal ''
            'ABC\u{301}'.drop (After_Last "") . should_equal 'ABC\u{301}'
            'ABC\u{301}'.drop (Before "") . should_equal 'ABC\u{301}'
            'ABC\u{301}'.drop (Before_Last "") . should_equal ''

            "ABC".drop (By_Index -1) . should_equal "AB"
            "ABC".drop (By_Index [-1, -1, -1, -3, 2]) . should_equal "B"
            "ABC".drop (By_Index []) . should_equal "ABC"
            "".drop (Every 2) . should_equal ""
            "".drop (Every 2 first=1) . should_equal ""
            "ABC".drop (Every 5) . should_equal "BC"
            "ABC".drop (Every 5 first=4) . should_equal "ABC"
            "".drop (Sample 0) . should_equal ""
            "".drop (Sample 100) . should_equal ""

        Test.specify "should correctly convert character case" <|
            "FooBar Baz".to_case Case.Lower . should_equal "foobar baz"
            "FooBar Baz".to_case Case.Upper . should_equal "FOOBAR BAZ"

            "foo bar baz".to_case Case.Title . should_equal "Foo Bar Baz"
            "foo-bar, baz.baz foo_foo".to_case Case.Title . should_equal "Foo-Bar, Baz.baz Foo_foo"
            "jAck the rippER".to_case Case.Title (Locale.uk) . should_equal "Jack The Ripper"

            "i".to_case Case.Upper . should_equal "I"
            "I".to_case Case.Lower . should_equal "i"
            "i".to_case Case.Upper (Locale.new "tr") . should_equal "Ä°"
            "I".to_case Case.Lower (Locale.new "tr") . should_equal "Ä±"
            "Ä°".to_case Case.Lower . should_equal "iÌ‡"
            "Ä±".to_case Case.Upper . should_equal "I"

            "StraÃŸe".to_case Case.Upper . should_equal "STRASSE"
            "STRASSE".to_case Case.Lower . should_equal "strasse"
            "et cÃ¦tera".to_case Case.Upper . should_equal "ET CÃ†TERA"
            ("Î²".to_case Case.Upper == "B") . should_be_false
            "Î´Î»Ï†Î¾".to_case Case.Upper . should_equal "Î”Î›Î¦Î"
            "Î”Î›Î¦Î".to_case Case.Lower . should_equal "Î´Î»Ï†Î¾"
            "Î´Î» Ï†Î¾".to_case Case.Title . should_equal "Î”Î» Î¦Î¾"

            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.to_case Case.Upper . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.to_case Case.Lower . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'.to_case Case.Title . should_equal 'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜™ğŸ˜‰â˜º'

            "123".to_case Case.Upper . should_equal "123"
            "abc123".to_case Case.Upper . should_equal "ABC123"

        Test.specify "should dump characters to a vector" <|
            kshi_chars = kshi.char_vector
            kshi_chars . should_equal [2325, 2381, 2359, 2367]

        Test.specify "should convert a vector of characters to text" <|
            kshi_chars = [2325, 2381, 2359, 2367]
            Text.from_char_vector kshi_chars . should_equal kshi

        Test.specify "should insert text at a non-negative index position" <|
            "Hello World!".insert 0 " Cruel" . should_equal " CruelHello World!"
            "Hello World!".insert 5 " Cruel" . should_equal "Hello Cruel World!"
            "Hello World!".insert ("Hello World!".length - 1) " Cruel" . should_equal "Hello World Cruel!"
            "Hello World!".insert "Hello World!".length " Cruel" . should_equal "Hello World! Cruel"
            txt = kshi + facepalm + accent_1
            txt.insert 0 " Cruel" . should_equal (" Cruel" + kshi + facepalm + accent_1)
            txt.insert 1 " Cruel" . should_equal (kshi + " Cruel" + facepalm + accent_1)
            txt.insert 2 " Cruel" . should_equal (kshi + facepalm + " Cruel" + accent_1)
            txt.insert 3 " Cruel" . should_equal (kshi + facepalm + accent_1 + " Cruel")

        Test.specify "should report Index_Out_Of_Bounds_Error_Data when inserting text at an invalid non-negative index position" <|
            "Hello World!".insert ("Hello World!".length + 1) "foo" . should_fail_with Index_Out_Of_Bounds_Error_Data
            (kshi + facepalm + accent_1).insert 4 "foo" . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should insert text at a negative index position" <|
            "Hello World!".insert -1 " Cruel" . should_equal "Hello World! Cruel"
            "Hello World!".insert -5 " Cruel" . should_equal "Hello Wo Cruelrld!"
            "Hello World!".insert -("Hello World!".length) " Cruel" . should_equal "H Cruelello World!"
            "Hello World!".insert -("Hello World!".length + 1) " Cruel" . should_equal " CruelHello World!"
            txt = kshi + facepalm + accent_1
            txt.insert -1 " Cruel" . should_equal (txt + " Cruel")
            txt.insert -(txt.length) " Cruel" . should_equal (kshi + " Cruel" + facepalm + accent_1)

        Test.specify "should report Index_Out_Of_Bounds_Error_Data when inserting text at an invalid negative index position" <|
            "Hello World!".insert -("Hello World!".length + 2) " Cruel" . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt = kshi + facepalm + accent_1
            txt.insert -(txt.length + 2) " Cruel" . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to check by index if is a digit" <|
            str = kshi + "A12" + accent_2
            str.is_digit . should_be_false
            str.is_digit 1 . should_be_false
            str.is_digit 2 . should_be_true
            str.is_digit 3 . should_be_true
            str.is_digit 4 . should_be_false
            str.is_digit 5 . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to check by negative index if is a digit" <|
            str = kshi + "A12" + accent_2
            str.is_digit -1 . should_be_false
            str.is_digit -2 . should_be_true
            str.is_digit -3 . should_be_true
            str.is_digit -4 . should_be_false
            str.is_digit -5 . should_be_false
            str.is_digit -100 . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to check if a text consists only of whitespace" <|
            '  \t\n'.is_whitespace . should_be_true
            'AB'.is_whitespace . should_be_false
            '  A   '.is_whitespace . should_be_false

            '\v\f\u{200a}\u{202f}\u{205F}\u{3000}'.is_whitespace . should_be_true
            # The Unicode Zero Width Space is not considered whitespace
            '\u{200b}'.is_whitespace . should_be_false

        Test.specify "should return a dataflow error when checking is digit for out of bounds" <|
            str = kshi + "A12" + accent_2
            str.at -6 . should_fail_with Index_Out_Of_Bounds_Error_Data
            str.at 5 . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to reverse characters" <|
            "Hello World!".reverse . should_equal "!dlroW olleH"

            "".reverse . should_equal ""
            'e\u{301}'.reverse . should_equal 'e\u{301}'
            'e\u{301}\u00E9'.reverse . should_equal '\u00E9e\u{301}'
            'e\u{321}\u{360}'.reverse . should_equal 'e\u{321}\u{360}'
            'IÃ±tÃ«rnÃ¢tiÃ´nÃ lizÃ¦tiÃ¸nâ˜ƒğŸ’©'.reverse . should_equal 'ğŸ’©â˜ƒnÃ¸itÃ¦zilÃ nÃ´itÃ¢nrÃ«tÃ±I'
            'ã»ã’ã»ã’'.reverse . should_equal 'ã’ã»ã’ã»'
            '\u{10000}'.reverse . should_equal '\u{10000}'

        Test.specify "should allow to iterate over characters" <|
            str = kshi + accent_1 + accent_2 + 'abc'
            builder = Vector.new_builder
            str.each builder.append
            builder.to_vector . should_equal [kshi, accent_1, accent_2, 'a', 'b', 'c']

            builder2 = Vector.new_builder
            'a'.each builder2.append
            builder2.to_vector . should_equal ['a']

        Test.specify "should check for contains using Unicode normalization" <|
            "Hello".contains "ell" . should_be_true

            "CzeÅ›Ä‡".contains 's\u{301}' . should_be_true
            "CzeÅ›Ä‡".contains 'c\u{301}' . should_be_true
            "CzeÅ›Ä‡".contains 'Å›Ä‡' . should_be_true
            'Czes\u{301}c\u{301}'.contains 'Å›' . should_be_true
            'Czes\u{301}c\u{301}'.contains 'Ä‡' . should_be_true
            'Czes\u{301}c\u{301}'.contains 'Å›Ä‡' . should_be_true
            "CzeÅ›Ä‡".contains 'sc' . should_be_false
            'Czes\u{301}c\u{301}'.contains 'sc' . should_be_false
            "CzeÅ›Ä‡".contains 's' . should_be_false
            "CzeÅ›Ä‡".contains 'c' . should_be_false
            'Czes\u{301}c\u{301}'.contains 's' . should_be_false

            "ABC" . contains "a" . should_be_false
            "" . contains "foo" . should_be_false
            "abc" . contains "" . should_be_true
            "" . contains "" . should_be_true
            "foo foo foo" . contains "foo" . should_be_true

            "Hello!".contains "lo" . should_be_true
            "Hello!".contains "Lo" . should_be_false

        Test.specify "should allow for case-insensitive contains checks" <|
            "Hello!".contains 'LO' Text_Matcher.Case_Insensitive . should_be_true
            "FoObar" . contains "foo" Text_Matcher.Case_Insensitive . should_be_true
            "aaaIAAA" . contains "i" Text_Matcher.Case_Insensitive . should_be_true
            "Foo" . contains "bar" Text_Matcher.Case_Insensitive . should_be_false
            "Åšciana" . contains "Å›" Text_Matcher.Case_Insensitive . should_be_true
            "Åšciana" . contains "s" Text_Matcher.Case_Insensitive . should_be_false

            "StraÃŸe" . contains "ss" . should_be_false
            "Strasse" . contains "ÃŸ" . should_be_false
            "StraÃŸe" . contains "ss" Text_Matcher.Case_Insensitive . should_be_true
            "Strasse" . contains "ÃŸ" Text_Matcher.Case_Insensitive . should_be_true

        Test.specify "should allow for Regex contains checks" <|
            "Hello!".contains "[a-z]" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "foobar" . contains "b.." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "foob" . contains "b.." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false

            "123 meters and 4 centimeters" . contains "[0-9]+" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "foo" . contains "[0-9]+" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false

            'Å›' . contains 's' . should_be_false
            's\u{301}' . contains 's' . should_be_false
            's\u{301}' . contains 'Å›' . should_be_true
            'Å›' . contains 's\u{301}' . should_be_true

            ## These first two cases are not really desirable, but we are
               documenting here what is the current behaviour.
            ## This shows what regex is doing by default and we cannot easily fix
               that.
            's\u{301}' . contains 's' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            'Å›' . contains 's' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            's\u{301}' . contains 'Å›' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            'Å›' . contains 's\u{301}' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true

            "CzeÅ›Ä‡" . contains "Å›" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "CzeÅ›Ä‡" . contains 's\u{301}' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            'Czes\u{301}c\u{301}' . contains 's\u{301}' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            'Czes\u{301}c\u{301}' . contains 'Å›' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            ## These two tests below are disabled due to how regex is handling
               letters with accents. See the tests above for explanation.
            #"CzeÅ›Ä‡" . contains "s" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            #'Czes\u{301}c\u{301}' . contains 's' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false

            "fooBar" . contains "b.." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_true
            "foar" . contains "b.." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_false

            long_text = """
                Hello from a long text. EOL
                SOL Hmm...
            (long_text.replace '\r' "") . contains "EOL.SOL" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive dot_matches_newline=True) . should_be_true
            (long_text.replace '\r' "") . contains "EOL.SOL" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive dot_matches_newline=False) . should_be_false

        Test.specify "should check for starts_with using Unicode normalization" <|
            "Hello".starts_with "He" . should_be_true

            "Åšciana".starts_with 'S\u{301}' . should_be_true
            "Åšciana".starts_with 'Åš' . should_be_true
            "Åšciana".starts_with 'S' . should_be_false
            'S\u{301}ciana'.starts_with 'Åš' . should_be_true
            'S\u{301}ciana'.starts_with 'S\u{301}' . should_be_true
            'S\u{301}ciana'.starts_with 'S' . should_be_false

            "ABC" . starts_with "A" . should_be_true
            "ABC" . starts_with "a" . should_be_false
            "" . starts_with "foo" . should_be_false
            "abc" . starts_with "" . should_be_true
            "" . starts_with "" . should_be_true
            "foo foo foo" . starts_with "foo" . should_be_true

            "Hello!".starts_with "he" . should_be_false

        Test.specify "starts_with should work as shown in the examples" <|
            "Hello!".starts_with "Hello" . should_be_true
            "Hello!".starts_with "hello" . should_be_false
            "Hello!".starts_with "hello" Text_Matcher.Case_Insensitive . should_be_true
            "Hello!".starts_with "[a-z]" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            "Hello!".starts_with "[A-Z]" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true

        Test.specify "should allow for case-insensitive starts_with checks" <|
            "Hello".starts_with "he" Text_Matcher.Case_Insensitive . should_be_true

            "Åšciana".starts_with 's\u{301}' Text_Matcher.Case_Insensitive . should_be_true
            "Åšciana".starts_with 's' Text_Matcher.Case_Insensitive . should_be_false
            'S\u{301}ciana'.starts_with 'Å›' Text_Matcher.Case_Insensitive . should_be_true
            'S\u{301}ciana'.starts_with 's\u{301}' Text_Matcher.Case_Insensitive . should_be_true
            'S\u{301}ciana'.starts_with 's' Text_Matcher.Case_Insensitive . should_be_false

            "ABC" . starts_with "A" Text_Matcher.Case_Insensitive . should_be_true
            "ABC" . starts_with "a" Text_Matcher.Case_Insensitive . should_be_true
            "ABC" . starts_with "C" Text_Matcher.Case_Insensitive . should_be_false
            "" . starts_with "foo" Text_Matcher.Case_Insensitive . should_be_false
            "abc" . starts_with "" Text_Matcher.Case_Insensitive . should_be_true
            "" . starts_with "" Text_Matcher.Case_Insensitive . should_be_true
            "fOo FOO foo" . starts_with "FoO" Text_Matcher.Case_Insensitive . should_be_true

            "Hello!".starts_with "he" Text_Matcher.Case_Insensitive . should_be_true

        Test.specify "should allow for Regex starts_with checks" <|
            "Hello!".starts_with "[A-Z]" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "foobar" . starts_with ".o." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "foob" . starts_with ".f." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false

            "123 meters and 4 centimeters" . starts_with "[0-9]+" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "foo 123" . starts_with "[0-9]+" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false

            # Correct non-regex behaviour for reference.
            'Å›' . starts_with 's' == False
            's\u{301}' . starts_with 's' == False
            's\u{301}' . starts_with 'Å›' == True
            'Å›' . starts_with 's\u{301}' == True

            # These two behave as expected.
            's\u{301}' . starts_with 'Å›' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) == True
            'Å›' . starts_with 's\u{301}' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) == True

            ## These two are included to document the current behaviour
               (even though ideally, we would want them to return False).
            'Å›' . starts_with 's' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) == True
            's\u{301}' . starts_with 's' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) == True

            "Å›ciana" . starts_with "Å›" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "Å›ciana" . starts_with 's\u{301}' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            's\u{301}ciana' . starts_with 's\u{301}' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            's\u{301}ciana' . starts_with 'Å›' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true

            ## These two tests below are disabled due to how regex is handling
               letters with accents. See the tests above for explanation.
            #"Å›ciana" . starts_with "s" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            # 's\u{301}ciana' . starts_with 's' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false

            "fOOBar" . starts_with ".o." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_true
            "faaaar" . starts_with ".o." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_false

            long_text = """
                EOL
                SOL Hmm...
            (long_text.replace '\r' "") . starts_with "EOL.SOL" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive dot_matches_newline=True) . should_be_true
            (long_text.replace '\r' "") . starts_with "EOL.SOL" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive dot_matches_newline=False) . should_be_false

            "aaazzz" . starts_with "a|b" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "bbbzzz" . starts_with "a|b" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "zzzaaa" . starts_with "a|b" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            "zzzbbb" . starts_with "a|b" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            "aaazzz" . starts_with "(a|b){2}" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "bbbzzz" . starts_with "(a|b){2}" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "zzzaaa" . starts_with "(a|b){2}" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            "ABC" . starts_with "\AA" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "ABC" . starts_with "\AA\z" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_false
            "foobar" . starts_with "" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "" . starts_with "" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true

        Test.specify "should check for ends_with using Unicode normalization" <|
            "Hello".ends_with "lo" . should_be_true
            "Hello".ends_with "LO" . should_be_false

            "rzeczywistoÅ›Ä‡".ends_with 'c\u{301}' . should_be_true
            "rzeczywistoÅ›Ä‡".ends_with 'Ä‡' . should_be_true
            "rzeczywistoÅ›Ä‡".ends_with 'c' . should_be_false
            'rzeczywistos\u{301}c\u{301}'.ends_with 'Ä‡' . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'c\u{301}' . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'c' . should_be_false

            "ABC" . ends_with "C" . should_be_true
            "ABC" . ends_with "c" . should_be_false
            "" . ends_with "foo" . should_be_false
            "abc" . ends_with "" . should_be_true
            "" . ends_with "" . should_be_true
            "foo foo foo" . ends_with "foo" . should_be_true

        Test.specify "ends_with should work as shown in the examples" <|
            "Hello World".ends_with "World" . should_be_true
            "Hello World".ends_with "world" . should_be_false
            "Hello World".ends_with "world" Text_Matcher.Case_Insensitive . should_be_true
            "Hello World".ends_with "[A-Z][a-z]{4}" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true

        Test.specify "should allow for case-insensitive ends_with checks" <|
            "Hello".ends_with "LO" Text_Matcher.Case_Insensitive . should_be_true

            "rzeczywistoÅ›Ä‡".ends_with 'C\u{301}' Text_Matcher.Case_Insensitive . should_be_true
            "rzeczywistoÅ›Ä‡".ends_with 'C' Text_Matcher.Case_Insensitive . should_be_false
            'rzeczywistos\u{301}c\u{301}'.ends_with 'Ä†' Text_Matcher.Case_Insensitive . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'C\u{301}' Text_Matcher.Case_Insensitive . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'C' Text_Matcher.Case_Insensitive . should_be_false

            "ABC" . ends_with "C" Text_Matcher.Case_Insensitive . should_be_true
            "ABC" . ends_with "c" Text_Matcher.Case_Insensitive . should_be_true
            "ABC" . ends_with "A" Text_Matcher.Case_Insensitive . should_be_false
            "" . ends_with "foo" Text_Matcher.Case_Insensitive . should_be_false
            "abc" . ends_with "" Text_Matcher.Case_Insensitive . should_be_true
            "" . ends_with "" Text_Matcher.Case_Insensitive . should_be_true
            "fOo FOO fOo" . ends_with "FoO" Text_Matcher.Case_Insensitive . should_be_true

        Test.specify "should allow for Regex ends_with checks" <|
            "Hello".ends_with "[a-z]" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Sensitive) . should_be_true
            "Hello!".ends_with "[a-z]" Regex_Matcher.Regex_Matcher_Data . should_be_false

            "foobar" . ends_with ".o." Regex_Matcher.Regex_Matcher_Data . should_be_false
            "foobar" . ends_with ".a." Regex_Matcher.Regex_Matcher_Data . should_be_true

            "123 meters and 4 centimeters" . ends_with "[0-9]+" Regex_Matcher.Regex_Matcher_Data . should_be_false
            "foo 123" . ends_with "[0-9]+" Regex_Matcher.Regex_Matcher_Data . should_be_true

            "rzeczywistoÅ›Ä‡" . ends_with "Ä‡" Regex_Matcher.Regex_Matcher_Data . should_be_true
            "rzeczywistoÅ›Ä‡" . ends_with 'c\u{301}' Regex_Matcher.Regex_Matcher_Data . should_be_true
            'rzeczywistos\u{301}c\u{301}' . ends_with 'c\u{301}' Regex_Matcher.Regex_Matcher_Data . should_be_true
            'rzeczywistos\u{301}c\u{301}' . ends_with 'Ä‡' Regex_Matcher.Regex_Matcher_Data . should_be_true
            "rzeczywistoÅ›Ä‡" . ends_with "c" Regex_Matcher.Regex_Matcher_Data . should_be_false
            'rzeczywistos\u{301}c\u{301}' . ends_with 'c' Regex_Matcher.Regex_Matcher_Data . should_be_false

            'rzeczywistos\u{301}c\u{301}' . ends_with 'Ä†' (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_true
            "fOOBar" . ends_with ".A." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_true
            "faaaar" . ends_with ".o." (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_false

            long_text = """
                Hnnnn EOL
                SOL
            (long_text.replace '\r' "") . ends_with "EOL.SOL" (Regex_Matcher.Regex_Matcher_Data dot_matches_newline=True) . should_be_true
            (long_text.replace '\r' "") . ends_with "EOL.SOL" (Regex_Matcher.Regex_Matcher_Data dot_matches_newline=False) . should_be_false

            "zzzaaa" . ends_with "a|b" Regex_Matcher.Regex_Matcher_Data . should_be_true
            "zzzbbb" . ends_with "a|b" Regex_Matcher.Regex_Matcher_Data . should_be_true
            "aaazzz" . ends_with "a|b" Regex_Matcher.Regex_Matcher_Data . should_be_false
            "bbbzzz" . ends_with "a|b" Regex_Matcher.Regex_Matcher_Data . should_be_false
            "zzzaaa" . ends_with "(a|b){2}" Regex_Matcher.Regex_Matcher_Data . should_be_true
            "zzzbbb" . ends_with "(a|b){2}" Regex_Matcher.Regex_Matcher_Data . should_be_true
            "aaazzz" . ends_with "(a|b){2}" Regex_Matcher.Regex_Matcher_Data . should_be_false
            "ABC" . ends_with "C\z" Regex_Matcher.Regex_Matcher_Data . should_be_true
            "ABC" . ends_with "\AC\z" Regex_Matcher.Regex_Matcher_Data . should_be_false
            "foobar" . ends_with "" Regex_Matcher.Regex_Matcher_Data . should_be_true
            "" . ends_with "" Regex_Matcher.Regex_Matcher_Data . should_be_true

        Test.specify "should allow to pad a text" <|
            "Hello World!".pad 15 . should_equal "Hello World!   "
            "HELLO".pad 9 "AB" . should_equal "HELLOABAB"
            "HELLO".pad 8 "AB" . should_equal "HELLOABA"
            "HELLO".pad 8 "AB" Location.Start . should_equal "BABHELLO"
            "".pad 4 . should_equal "    "
            "A".pad 3 "" . should_fail_with Illegal_Argument_Error_Data
            "ABCDE".pad 3 "" . should_fail_with Illegal_Argument_Error_Data
            "".pad 0 "" . should_fail_with Illegal_Argument_Error_Data

            "".pad 0 . should_equal ""
            "ABC".pad 3 . should_equal "ABC"
            "AB".pad -1 . should_equal "AB"
            "ABC".pad -100 . should_equal "ABC"

            'a\u{301}'.pad 2 . should_equal 'a\u{301} '
            "".pad 2 'a\u{302}' . should_equal 'a\u{302}a\u{302}'
            'XX'.pad 5 'yy\u{301}' . should_equal 'XXyy\u{301}y'
            'XX'.pad 5 'y\u{301}y' . should_equal 'XXy\u{301}yy\u{301}'
            'XX'.pad 4 'yy\u{301}Z' . should_equal 'XXyy\u{301}'

            'ğŸš€'.pad 3 'B' Location.End . should_equal 'ğŸš€BB'
            'ğŸš€'.pad 3 'B' Location.Start . should_equal 'BBğŸš€'

            ## It is technically possible to use a combining diacritical mark as
               the padding, then the actual length of the text will not increase
               because all padding will still constitute a single grapheme
               cluster.
            'e'.pad 7 '\u{301}' . length . should_equal 1

        Test.specify "should allow to trim a text" <|
            " Hello! ".trim . should_equal  "Hello!"
            " Hello! ".trim Location.Start . should_equal  "Hello! "
            " Hello! ".trim Location.End . should_equal  " Hello!"
            "ABC123".trim Location.Start "ABC" . should_equal  "123"
            "ABBA123".trim Location.Start "ABC" . should_equal  "123"
            "ABCZ-]".trim Location.Both "[A-Z]" . should_equal "BC"

            "   ".trim . should_equal ""
            "  Hello World!   ".trim . should_equal  "Hello World!"
            "  Hello World!   ".trim Location.Start . should_equal  "Hello World!   "
            "  Hello World!   ".trim Location.End . should_equal  "  Hello World!"
            "ABCD".trim Location.Start "ABCDEF" . should_equal ""
            "ABCD".trim Location.End "ABCDEF" . should_equal ""
            "ABCD".trim Location.Both "ABCDEF" . should_equal ""

            "".trim . should_equal ""
            "A".trim . should_equal "A"
            " A ".trim . should_equal "A"
            '   A\u{301} \n   '.trim . should_equal 'A\u{301}'
            "ğŸš§".trim . should_equal "ğŸš§"
            "  ğŸš§  ğŸš§  ".trim . should_equal "ğŸš§  ğŸš§"
            "  ğŸš§  ğŸš§  ".trim Location.End . should_equal "  ğŸš§  ğŸš§"

            "ABCD".trim Location.Start (_ -> True) . should_equal ""
            "ABCD".trim Location.Both (_ -> True) . should_equal ""
            "ABCD".trim Location.Both (_ -> False) . should_equal "ABCD"
            "123AB98".trim Location.Both _.is_digit . should_equal "AB"

            ' \t\n\r'.trim . should_equal ''
            '\t\t  Test\nFoo\r\n'.trim . should_equal 'Test\nFoo'
            # Check various kinds of Unicode whitespace
            '\v\f\u{200a}\u{202f}\u{205F}\u{3000}'.trim . should_equal ''

            # A whitespace with an accent is not treated as whitespace anymore
            '      \u{301}   '.trim . should_equal ' \u{301}'
            ' \u{301}'.trim . should_equal ' \u{301}'

        Test.specify "should allow repeating as in the examples" <|
            "ABBA".repeat 5 . should_equal "ABBAABBAABBAABBAABBA"
            "A".repeat 5 . should_equal "AAAAA"
            "Hello ".repeat 2 . should_equal "Hello Hello "

        Test.specify "should allow more general repeating" <|
            'He\u{302}llo\u{308}'.repeat 1 . should_equal 'He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'.repeat 3 . should_equal 'He\u{302}llo\u{308}He\u{302}llo\u{308}He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'.repeat 0 . should_equal ''
            'He\u{302}llo\u{308}'.repeat -5 . should_equal ''

            ''.repeat 100 . should_equal ''

            'âœ¨ğŸš€ğŸš§'.repeat 2 . should_equal 'âœ¨ğŸš€ğŸš§âœ¨ğŸš€ğŸš§'

        Test.specify "should allow repeating using * as in the examples" <|
            "ABBA"*5 . should_equal "ABBAABBAABBAABBAABBA"
            "A"*5 . should_equal "AAAAA"
            "Hello "*2 . should_equal "Hello Hello "

        Test.specify "should allow more general repeating using *" <|
            'He\u{302}llo\u{308}'*1 . should_equal 'He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'*3 . should_equal 'He\u{302}llo\u{308}He\u{302}llo\u{308}He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'*0 . should_equal ''
            'He\u{302}llo\u{308}'*(-5) . should_equal ''

            ''*100 . should_equal ''

            'âœ¨ğŸš€ğŸš§'*2 . should_equal 'âœ¨ğŸš€ğŸš§âœ¨ğŸš€ğŸš§'

        Test.specify "locate should work as shown in examples" <|
            example_1 =
                "Hello World!".locate "J" == Nothing
                "Hello World!".locate "o" == Span_Data (Range_Data 4 5) "Hello World!"
                "Hello World!".locate "o" mode=Matching_Mode.Last == Span_Data (Range_Data 4 5) "Hello World!"

            example_2 =
                term = "straÃŸe"
                text = "MONUMENTENSTRASSE 42"
                match = text . locate term matcher=Text_Matcher.Case_Insensitive
                term.length . should_equal 6
                match.length . should_equal 7

            example_3 =
                ligatures = "ï¬ƒï¬„"
                ligatures.length . should_equal 2
                term_1 = "IFF"
                match_1 = ligatures . locate term_1 matcher=Text_Matcher.Case_Insensitive
                term_1.length . should_equal 3
                match_1.length . should_equal 2
                term_2 = "ffiffl"
                match_2 = ligatures . locate term_2 matcher=Text_Matcher.Case_Insensitive
                term_2.length . should_equal 6
                match_2.length . should_equal 2
                match_1 . should_equal match_2

            example_4 =
                "Hello World!".locate_all "J" . should_equal []
                "Hello World!".locate_all "o" . map .start . should_equal [4, 7]

            example_5 =
                term = "strasse"
                text = "MONUMENTENSTRASSE ist eine groÃŸe StraÃŸe."
                match = text . locate_all term matcher=Text_Matcher.Case_Insensitive
                term.length . should_equal 7
                match . map .length . should_equal [7, 6]

            example_6 =
                ligatures = "ï¬ƒï¬„FFIFF"
                ligatures.length . should_equal 7
                match_1 = ligatures . locate_all "IFF" matcher=Text_Matcher.Case_Insensitive
                match_1 . map .length . should_equal [2, 3]
                match_2 = ligatures . locate_all "ffiff" matcher=Text_Matcher.Case_Insensitive
                match_2 . map .length . should_equal [2, 5]

            # Put them in blocks to avoid name clashes.
            example_1
            example_2
            example_3
            example_4
            example_5
            example_6

        Test.specify "should allow to find locate occurrences within a text" <|
            "Hello World!".locate_all "J" . should_equal []
            "Hello World!".locate_all "o" . map .start . should_equal [4, 7]

            accents = 'a\u{301}e\u{301}o\u{301}'
            accents.locate accent_1 . should_equal (Span_Data (Range_Data 1 2) accents)

            "".locate "foo" . should_equal Nothing
            "".locate "foo" mode=Matching_Mode.Last . should_equal Nothing
            "".locate_all "foo" . should_equal []
            "".locate "" . should_equal (Span_Data (Range_Data 0 0) "")
            "".locate "" mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 0 0) "")
            "".locate_all "" . should_equal [Span_Data (Range_Data 0 0) ""]
            abc = 'A\u{301}ÃŸC'
            abc.locate "" . should_equal (Span_Data (Range_Data 0 0) abc)
            abc.locate "" mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 3 3) abc)
            abc.locate_all "" . should_equal [Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 1 1) abc, Span_Data (Range_Data 2 2) abc, Span_Data (Range_Data 3 3) abc]

        Test.specify "should allow case-insensitive matching in locate" <|
            hello = "Hello WORLD!"
            case_insensitive = Text_Matcher.Case_Insensitive
            hello.locate "world" . should_equal Nothing
            hello.locate "world" matcher=case_insensitive . should_equal (Span_Data (Range_Data 6 11) hello)

            hello.locate "o" mode=Regex_Mode.First matcher=case_insensitive . should_equal (Span_Data (Range_Data 4 5) hello)
            hello.locate "o" mode=Matching_Mode.Last matcher=case_insensitive . should_equal (Span_Data (Range_Data 7 8) hello)

            accents = 'A\u{301}E\u{301}O\u{301}'
            accents.locate accent_1 matcher=case_insensitive . should_equal (Span_Data (Range_Data 1 2) accents)

            "Strasse".locate "ÃŸ" matcher=case_insensitive . should_equal (Span_Data (Range_Data 4 6) "Strasse")
            "MonumentenstraÃŸe 42".locate "STRASSE" matcher=case_insensitive . should_equal (Span_Data (Range_Data 10 16) "MonumentenstraÃŸe 42")

            '\u0390'.locate '\u03B9\u0308\u0301' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 1) '\u0390')
            'ÔµÕ’'.locate 'Ö‡' . should_equal Nothing
            'ÔµÕ’'.locate 'Ö‡' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 2) 'ÔµÕ’')
            'Ö‡'.locate 'ÔµÕ’' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 1) 'Ö‡')

            ligatures = 'ffaï¬€ï¬ï¬‚ï¬ƒï¬„ï¬…ï¬†Z'
            ligatures.locate 'FFI' matcher=case_insensitive . should_equal (Span_Data (Range_Data 3 5) ligatures)
            ligatures.locate 'FF' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 2) ligatures)
            ligatures.locate 'ff' matcher=case_insensitive mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 7 8) ligatures)
            ligatures.locate_all 'ff' . should_equal [Span_Data (Range_Data 0 2) ligatures]
            ligatures.locate_all 'FF' matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 2) ligatures, Span_Data (Range_Data 3 4) ligatures, Span_Data (Range_Data 6 7) ligatures, Span_Data (Range_Data 7 8) ligatures]
            ligatures.locate_all 'ffi' matcher=case_insensitive . should_equal [Span_Data (Range_Data 3 5) ligatures, Span_Data (Range_Data 6 7) ligatures]
            'fffi'.locate_all 'ï¬€' matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 2) 'fffi']
            'fffi'.locate_all 'ï¬ƒ' . should_equal []
            'fffi'.locate_all 'ï¬ƒ' matcher=case_insensitive . should_equal [Span_Data (Range_Data 1 4) 'fffi']
            'FFFI'.locate 'ï¬ƒ' matcher=case_insensitive . should_equal (Span_Data (Range_Data 1 4) 'FFFI')

            'ï¬ƒï¬„'.locate 'IF' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 2) 'ï¬ƒï¬„')
            'ï¬ƒï¬„'.locate 'F' Matching_Mode.Last matcher=case_insensitive . should_equal (Span_Data (Range_Data 1 2) 'ï¬ƒï¬„')
            'ï¬ƒï¬„'.locate_all 'F' matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 1) 'ï¬ƒï¬„', Span_Data (Range_Data 0 1) 'ï¬ƒï¬„', Span_Data (Range_Data 1 2) 'ï¬ƒï¬„', Span_Data (Range_Data 1 2) 'ï¬ƒï¬„']
            'aaï¬ƒbb'.locate_all 'af' matcher=case_insensitive . should_equal [Span_Data (Range_Data 1 3) 'aaï¬ƒbb']
            'aaï¬ƒbb'.locate_all 'affi' matcher=case_insensitive . should_equal [Span_Data (Range_Data 1 3) 'aaï¬ƒbb']
            'aaï¬ƒbb'.locate_all 'ib' matcher=case_insensitive . should_equal [Span_Data (Range_Data 2 4) 'aaï¬ƒbb']
            'aaï¬ƒbb'.locate_all 'ffib' matcher=case_insensitive . should_equal [Span_Data (Range_Data 2 4) 'aaï¬ƒbb']

            "".locate "foo" matcher=case_insensitive . should_equal Nothing
            "".locate "foo" matcher=case_insensitive mode=Matching_Mode.Last . should_equal Nothing
            "".locate_all "foo" matcher=case_insensitive . should_equal []
            "".locate "" matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 0) "")
            "".locate "" matcher=case_insensitive mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 0 0) "")
            "".locate_all "" matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 0) ""]
            abc = 'A\u{301}ÃŸC'
            abc.locate "" matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 0) abc)
            abc.locate "" matcher=case_insensitive mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 3 3) abc)
            abc.locate_all "" matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 1 1) abc, Span_Data (Range_Data 2 2) abc, Span_Data (Range_Data 3 3) abc]

        Test.specify "should allow regexes in locate" <|
            hello = "Hello World!"
            regex = Regex_Matcher.Regex_Matcher_Data
            regex_insensitive = Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive
            hello.locate ".o" Matching_Mode.First matcher=regex . should_equal (Span_Data (Range_Data 3 5) hello)
            hello.locate ".o" Matching_Mode.Last matcher=regex . should_equal (Span_Data (Range_Data 6 8) hello)
            hello.locate_all ".o" matcher=regex . map .start . should_equal [3, 6]

            "foobar".locate "BAR" Regex_Mode.First matcher=regex_insensitive . should_equal (Span_Data (Range_Data 3 6) "foobar")

            ## Regex matching does not do case folding
            "Strasse".locate "ÃŸ" Regex_Mode.First matcher=regex_insensitive . should_equal Nothing

            ## But it should handle the Unicode normalization
            accents = 'a\u{301}e\u{301}o\u{301}'
            accents.locate accent_1 Regex_Mode.First matcher=regex . should_equal (Span_Data (Range_Data 1 2) accents)
        Test.specify "should correctly handle regex edge cases in locate" pending="Figure out how to make Regex correctly handle empty patterns." <|
            regex = Regex_Matcher.Regex_Matcher_Data
            "".locate "foo" matcher=regex . should_equal Nothing
            "".locate "foo" matcher=regex mode=Matching_Mode.Last . should_equal Nothing
            "".locate_all "foo" matcher=regex . should_equal []
            "".locate "" matcher=regex . should_equal (Span_Data (Range_Data 0 0) "")
            "".locate_all "" matcher=regex . should_equal [Span_Data (Range_Data 0 0) ""]
            "".locate "" matcher=regex mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 0 0) "")
            abc = 'A\u{301}ÃŸC'
            abc.locate "" matcher=regex . should_equal (Span_Data (Range_Data 0 0) abc)
            abc.locate_all "" matcher=regex . should_equal [Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 1 1) abc, Span_Data (Range_Data 2 2) abc, Span_Data (Range_Data 3 3) abc]
            abc.locate "" matcher=regex mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 3 3) abc)

        Test.specify "should handle overlapping matches as shown in the examples" <|
            "aaa".locate "aa" mode=Matching_Mode.Last matcher=Text_Matcher.Case_Sensitive . should_equal (Span_Data (Range_Data 1 3) "aaa")
            "aaa".locate "aa" mode=Matching_Mode.Last matcher=Regex_Matcher.Regex_Matcher_Data . should_equal (Span_Data (Range_Data 0 2) "aaa")

            "aaa aaa".locate "aa" mode=Matching_Mode.Last matcher=Text_Matcher.Case_Sensitive . should_equal (Span_Data (Range_Data 5 7) "aaa aaa")
            "aaa aaa".locate "aa" mode=Matching_Mode.Last matcher=Regex_Matcher.Regex_Matcher_Data . should_equal (Span_Data (Range_Data 4 6) "aaa aaa")

        Test.specify "should allow to match one or more occurrences of a pattern in the text" <|
            "abacadae".match_all "a[bc]" . should_equal ["ab", "ac"]
            "abacadae".match_all "a." . should_equal ["ab", "ac", "ad", "ae"]
            "abacadae".match_all "a.*" . should_equal ["abacadae"]
            "abacadae".match_all "a.+?" . should_equal ["ab", "ac", "ad", "ae"]

            "abacadae".match "a[bc]" mode=Matching_Mode.Last . should_equal "ac"
            "abacadae".match "a." mode=Matching_Mode.Last . should_equal "ae"
            "abacadae".match "a.*" mode=Matching_Mode.Last . should_equal "abacadae"
            "abacadae".match "a.+?" mode=Matching_Mode.Last . should_equal "ae"

            "abacadae".match "a[bc]" matcher=Text_Matcher.Case_Sensitive . should_equal Nothing
            "abABacAC".match "ab" matcher=Text_Matcher.Case_Sensitive mode=Matching_Mode.Last . should_equal "ab"
            "abABacAC".match "ab" matcher=Text_Matcher.Case_Insensitive mode=Matching_Mode.Last . should_equal "AB"

            "abABacAC".match_all "ab" matcher=Text_Matcher.Case_Sensitive . should_equal ["ab"]
            "abABacAC".match_all "ab" matcher=Text_Matcher.Case_Insensitive . should_equal ["ab", "AB"]
            "abacadae".match_all "a[bc]" matcher=Text_Matcher.Case_Sensitive . should_equal []

            "Strasse and StraÃŸe".match_all "STRASSE" matcher=Text_Matcher.Case_Sensitive . should_equal []
            "Strasse and StraÃŸe".match_all "STRASSE" matcher=Text_Matcher.Case_Insensitive . should_equal ["Strasse", "StraÃŸe"]

        Test.specify "should default to exact matching for locate but regex for match" <|
            txt = "aba[bc]adacae"
            "ab".locate "ab" . should_equal (Span_Data (Range_Data 0 2) "ab")
            "ab".locate "a[bc]" . should_equal Nothing
            "ab".locate_all "a[bc]" . should_equal []

            txt.locate "a[bc]" . should_equal (Span_Data (Range_Data 2 7) txt)
            txt.locate_all "a[bc]" . should_equal [Span_Data (Range_Data 2 7) txt]

            "ab".match "a[bc]" . should_equal "ab"
            "a[bc]".match "a[bc]" . should_equal Nothing
            "a[bc]".match_all "a[bc]" . should_equal []

            txt.match "a[bc]" . should_equal "ab"
            txt.match_all "a[bc]" . should_equal ["ab", "ac"]

    Test.group "Regex matching" <|
        Test.specify "should be possible on text" <|
            match = "My Text: Goes Here".match "^My Text: (.+)$"
            match.should_equal "My Text: Goes Here"

        Test.specify "should be possible on unicode text" <|
            txt = "mazaê±´ë°˜zaa"
            txt.match "^a..z$" . should_equal Nothing
            txt.match "^m..a..z.a$" . should_equal txt
            txt.match "a..z" . should_equal "aê±´ë°˜z"

        Test.specify "should be possible in ascii mode" <|
            match = "Ä°".match "\w" matcher=(Regex_Matcher.Regex_Matcher_Data match_ascii=True)
            match.should_equal Nothing

        Test.specify "should be possible in case-insensitive mode" <|
            match = "MY".match "my" matcher=(Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive)
            match.should_equal "MY"

        Test.specify "should be possible in dot_matches_newline mode" <|
            match = 'Foo\n'.match "(....)" matcher=(Regex_Matcher.Regex_Matcher_Data dot_matches_newline=True)
            match.should_equal 'Foo\n'

        Test.specify "should be possible in multiline mode" <|
            text = """
                Foo
                bar
            match = text.match_all "^(...)$" matcher=(Regex_Matcher.Regex_Matcher_Data multiline=True)
            match.should_equal ["Foo", "bar"]

        Test.specify "should be possible in comments mode" <|
            match = "abcde".match "(..) # Match two of any character" matcher=(Regex_Matcher.Regex_Matcher_Data comments=True)
            match.should_equal "ab"

    Test.group "Text.is_match" <|
        Test.specify "should default to regex" <|
            "My Text: Goes Here".is_match "^My Text: (.+)$" . should_be_true
            "555-801-1923".is_match "^\d{3}-\d{3}-\d{4}$" . should_be_true
            "Hello".is_match "^[a-z]+$" . should_be_false
            "Hello".is_match "^[a-z]+$" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_true

        Test.specify "should only match whole input" <|
            "Hello".is_match "[a-z]" . should_be_false
            "x".is_match "[a-z]" . should_be_true

        Test.specify "should allow Text_Matcher too" <|
            "foobar".is_match "foobar" matcher=Text_Matcher.Case_Sensitive . should_be_true
            "foobar".is_match "FOOBAR" matcher=Text_Matcher.Case_Sensitive . should_be_false
            "foobar".is_match "foo.*" matcher=Text_Matcher.Case_Sensitive . should_be_false
            "foobar".is_match "foo" matcher=Text_Matcher.Case_Sensitive . should_be_false

            "foobar".is_match "foobar" matcher=Text_Matcher.Case_Insensitive . should_be_true
            "foobar".is_match "FOOBAR" matcher=Text_Matcher.Case_Insensitive . should_be_true
            "foobar".is_match "foo.*" matcher=Text_Matcher.Case_Insensitive . should_be_false
            "foobar".is_match "foo" matcher=Text_Matcher.Case_Insensitive . should_be_false

        Test.specify "should be possible on unicode text" <|
            "Korean: ê±´ë°˜".is_match "^Korean: (.+)$" . should_be_true

        Test.specify "should be possible in ascii mode" <|
            "Ä°".is_match "\w" (Regex_Matcher.Regex_Matcher_Data match_ascii=True) . should_be_false

        Test.specify "should be possible in case-insensitive mode" <|
            "MY".is_match "my" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive) . should_be_true

        Test.specify "should be possible in dot_matches_newline mode" <|
            'Foo\n'.is_match "(....)" (Regex_Matcher.Regex_Matcher_Data  dot_matches_newline=True) . should_be_true

        multiline_matches_message = """
            This test does not make sense once we require matches to match the
            whole string. The `multiline` parameter may not make sense for the
            `matches` function. This should be revisited when Text library is
            being redesigned.
        Test.specify "should be possible in multiline mode" pending=multiline_matches_message <|
            text = """
                Foo
                bar
            text.is_match "^(...)$" (Regex_Matcher.Regex_Matcher_Data  multiline=True) . should_be_true

        Test.specify "should be possible in comments mode" <|
            "abcde".is_match "(.....) # Match any five characters" (Regex_Matcher.Regex_Matcher_Data  comments=True) . should_be_true

    Test.group "Regex finding" <|
        Test.specify "should be possible on text" <|
            match = "My Text: Goes Here".match "^My Text: (.+)$" mode=Matching_Mode.First
            match . should_be_a Text
            match . should_equal "My Text: Goes Here"

        Test.specify "should be possible on unicode text" <|
            match = "Korean: ê±´ë°˜".match "^Korean: (.+)$" mode=Matching_Mode.First
            match . should_be_a Text
            match . should_equal "Korean: ê±´ë°˜"

        Test.specify "should be possible in ascii mode" <|
            match = "Ä°".match "\w" matcher=(Regex_Matcher.Regex_Matcher_Data match_ascii=True)
            match . should_equal Nothing

        Test.specify "should be possible in case-insensitive mode" <|
            match = "MY".match "my" matcher=(Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive)
            match . should_be_a Text
            match . should_equal "MY"

        Test.specify "should be possible in dot_matches_newline mode" <|
            match = 'Foo\n'.match "(....)" matcher=(Regex_Matcher.Regex_Matcher_Data dot_matches_newline=True)
            match . should_be_a Text
            match . should_equal 'Foo\n'

        Test.specify "should be possible in multiline mode" <|
            text = """
                Foo
                bar
            match = text.match_all "^(...)$" matcher=(Regex_Matcher.Regex_Matcher_Data multiline=True)
            match . should_equal ["Foo", "bar"]

        Test.specify "should be possible in comments mode" <|
            match = "abcde".match "(..) # Match two of any character" matcher=(Regex_Matcher.Regex_Matcher_Data comments=True)
            match . should_be_a Text
            match . should_equal "ab"

    Test.group "Regex splitting" <|
        Test.specify "should be possible on text" <|
            splits = "abcde".split "[bd]" Regex_Matcher.Regex_Matcher_Data
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "c"
            splits.at 2 . should_equal "e"

        Test.specify "should be possible on unicode text" <|
            match = "Korean: ê±´ë°˜ (hangul)".split " " Regex_Matcher.Regex_Matcher_Data
            match.length . should_equal 3
            match.at 0 . should_equal "Korean:"
            match.at 1 . should_equal "ê±´ë°˜"
            match.at 2 . should_equal "(hangul)"

        Test.specify "should be possible in ascii mode" <|
            splits = "Ä°iÄ°".split "\w" (Regex_Matcher.Regex_Matcher_Data match_ascii=True)
            splits.length . should_equal 2
            splits.at 0 . should_equal "Ä°"
            splits.at 1 . should_equal "Ä°"

        Test.specify "should be possible in case-insensitive mode" <|
            splits = "abaBa".split "b" (Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive)
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "a"
            splits.at 2 . should_equal "a"

        Test.specify "should be possible in dot_matches_newline mode" <|
            splits = 'ab\nabcd'.split "b." (Regex_Matcher.Regex_Matcher_Data dot_matches_newline=True)
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "a"
            splits.at 2 . should_equal "d"

        Test.specify "should be possible in multiline mode" <|
            text = """
                Foo
                bar
            match = text.split "$" (Regex_Matcher.Regex_Matcher_Data multiline=True)
            match.length . should_equal 3

        Test.specify "should be possible in comments mode" <|
            splits = "abcde".split "[bd] # Split on the letters `b` and `d`" (Regex_Matcher.Regex_Matcher_Data comments=True)
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "c"
            splits.at 2 . should_equal "e"

    Test.group "Text.replace" <|
        Test.specify "should work as in examples" <|
            'aaa'.replace 'aa' 'b' . should_equal 'ba'
            "Hello World!".replace "[lo]" "#" matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "He### W#r#d!"
            "Hello World!".replace "l" "#" mode=Matching_Mode.First . should_equal "He#lo World!"
            '"abc" foo "bar" baz'.replace '"(.*?)"' '($1)' matcher=Regex_Matcher.Regex_Matcher_Data . should_equal '(abc) foo (bar) baz'
            'ÃŸ'.replace 'S' 'A' matcher=Text_Matcher.Case_Insensitive . should_equal 'AA'
            'aï¬ƒb'.replace 'i' 'X' matcher=Text_Matcher.Case_Insensitive . should_equal 'aXb'

        Test.specify "should correctly handle empty-string edge cases" <|
            [Regex_Mode.All, Matching_Mode.First, Matching_Mode.Last] . each mode->
                'aaa'.replace '' 'foo' mode=mode . should_equal 'aaa'
                ''.replace '' '' mode=mode . should_equal ''
                'a'.replace 'a' '' mode=mode . should_equal ''
                ''.replace 'a' 'b' mode=mode . should_equal ''

            'aba' . replace 'a' '' Matching_Mode.First . should_equal 'ba'
            'aba' . replace 'a' '' Matching_Mode.Last . should_equal 'ab'
            'aba' . replace 'a' '' . should_equal 'b'
            'aba' . replace 'c' '' . should_equal 'aba'

        Test.specify "should correctly handle first, all and last matching with overlapping occurrences" <|
            "aaa aaa".replace "aa" "c" . should_equal "ca ca"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.First . should_equal "ca aaa"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.Last . should_equal "aaa ac"

        Test.specify "should correctly handle case-insensitive matches" <|
            'AaÄ…Ä„' . replace "A" "-" matcher=Text_Matcher.Case_Insensitive . should_equal '--Ä…Ä„'
            'AaÄ…Ä„' . replace "A" "-" . should_equal '-aÄ…Ä„'
            'HeLlO wOrLd' . replace 'hElLo' 'Hey,' matcher=Text_Matcher.Case_Sensitive . should_equal 'HeLlO wOrLd'
            'HeLlO wOrLd' . replace 'hElLo' 'Hey,' matcher=Text_Matcher.Case_Insensitive . should_equal 'Hey, wOrLd'

            "IiÄ°Ä±" . replace "i" "-" . should_equal "I-Ä°Ä±"
            "IiÄ°Ä±" . replace "I" "-" . should_equal "-iÄ°Ä±"
            "IiÄ°Ä±" . replace "Ä°" "-" . should_equal "Ii-Ä±"
            "IiÄ°Ä±" . replace "Ä±" "-" . should_equal "IiÄ°-"

            "IiÄ°Ä±" . replace "i" "-" matcher=Text_Matcher.Case_Insensitive . should_equal "--Ä°Ä±"
            "IiÄ°Ä±" . replace "I" "-" matcher=Text_Matcher.Case_Insensitive . should_equal "--Ä°Ä±"
            "IiÄ°Ä±" . replace "Ä°" "-" matcher=Text_Matcher.Case_Insensitive . should_equal "Ii-Ä±"
            "IiÄ°Ä±" . replace "Ä±" "-" matcher=Text_Matcher.Case_Insensitive . should_equal "IiÄ°-"

            tr_insensitive = Text_Matcher.Case_Insensitive (Locale.new "tr")
            "IiÄ°Ä±" . replace "i" "-" matcher=tr_insensitive . should_equal "I--Ä±"
            "IiÄ°Ä±" . replace "I" "-" matcher=tr_insensitive . should_equal "-iÄ°-"
            "IiÄ°Ä±" . replace "Ä°" "-" matcher=tr_insensitive . should_equal "I--Ä±"
            "IiÄ°Ä±" . replace "Ä±" "-" matcher=tr_insensitive . should_equal "-iÄ°-"

        Test.specify "should correctly handle Unicode edge cases" <|
            'sÅ›s\u{301}' . replace 's' 'O' . should_equal 'OÅ›s\u{301}'
            'sÅ›s\u{301}' . replace 's' 'O' Matching_Mode.Last . should_equal 'OÅ›s\u{301}'
            'Å›s\u{301}s' . replace 's' 'O' Matching_Mode.First . should_equal 'Å›s\u{301}O'

            'sÅ›s\u{301}' . replace 'Å›' 'O' . should_equal 'sOO'
            'sÅ›s\u{301}' . replace 's\u{301}' 'O' . should_equal 'sOO'

            'SÅšS\u{301}' . replace 's' 'O' . should_equal 'SÅšS\u{301}'
            'SÅšS\u{301}' . replace 's' 'O' Matching_Mode.Last . should_equal 'SÅšS\u{301}'
            'ÅšS\u{301}S' . replace 's' 'O' Matching_Mode.First . should_equal 'ÅšS\u{301}S'

            'SÅšS\u{301}' . replace 'Å›' 'O' . should_equal 'SÅšS\u{301}'
            'SÅšS\u{301}' . replace 's\u{301}' 'O' . should_equal 'SÅšS\u{301}'

            'SÅšS\u{301}' . replace 's' 'O' matcher=Text_Matcher.Case_Insensitive . should_equal 'OÅšS\u{301}'
            'SÅšS\u{301}' . replace 's' 'O' Matching_Mode.Last matcher=Text_Matcher.Case_Insensitive . should_equal 'OÅšS\u{301}'
            'ÅšS\u{301}S' . replace 's' 'O' Matching_Mode.First matcher=Text_Matcher.Case_Insensitive . should_equal 'ÅšS\u{301}O'

            'SÅšS\u{301}' . replace 'Å›' 'O' matcher=Text_Matcher.Case_Insensitive . should_equal 'SOO'
            'SÅšS\u{301}' . replace 's\u{301}' 'O' matcher=Text_Matcher.Case_Insensitive . should_equal 'SOO'

            'âœ¨ğŸš€ğŸš§ğŸ˜ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º' . replace 'ğŸš§ğŸ˜' '|-|:)' . should_equal 'âœ¨ğŸš€|-|:)ğŸ˜ƒğŸ˜ğŸ˜ğŸ˜™ğŸ˜‰â˜º'
            'Rocket Science' . replace 'Rocket' 'ğŸš€' . should_equal 'ğŸš€ Science'

            "Korean: ê±´ë°˜".replace "ê±´ë°˜" "keyboard" . should_equal "Korean: keyboard"

        Test.specify "will approximate ligature matches" <|
            # TODO do we want to improve this? highly non-trivial for very rare edge cases
            ## Currently we lack 'resolution' to extract a partial match from
               the ligature to keep it, probably would need some special
               mapping.
            'ï¬ƒï¬ƒ'.replace 'ff' 'aa' matcher=Text_Matcher.Case_Insensitive . should_equal 'aaaa'
            'ï¬ƒï¬ƒ'.replace 'ff' 'aa' mode=Matching_Mode.First matcher=Text_Matcher.Case_Insensitive . should_equal 'aaï¬ƒ'
            'ï¬ƒï¬ƒ'.replace 'ff' 'aa' mode=Matching_Mode.Last matcher=Text_Matcher.Case_Insensitive . should_equal 'ï¬ƒaa'
            'aï¬ƒï¬ƒb'.replace 'IF' 'X' matcher=Text_Matcher.Case_Insensitive . should_equal 'aXb'
            'aiï¬ƒffz' . replace 'if' '-' matcher=Text_Matcher.Case_Insensitive . should_equal 'a--fz'
            'AFFIB'.replace 'ï¬ƒ' '-' matcher=Text_Matcher.Case_Insensitive . should_equal 'A-B'

            'ÃŸ'.replace 'SS' 'A' matcher=Text_Matcher.Case_Insensitive . should_equal 'A'
            'ÃŸ'.replace 'S' 'A' matcher=Text_Matcher.Case_Insensitive . should_equal 'AA'
            'ÃŸ'.replace 'S' 'A' mode=Matching_Mode.First matcher=Text_Matcher.Case_Insensitive . should_equal 'A'
            'ÃŸ'.replace 'S' 'A' mode=Matching_Mode.Last matcher=Text_Matcher.Case_Insensitive . should_equal 'A'
            'STRASSE'.replace 'ÃŸ' '-' matcher=Text_Matcher.Case_Insensitive . should_equal 'STRA-E'

        Test.specify "should perform simple replacement in Regex mode" <|
            "ababab".replace "b" "a" matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "aaaaaa"
            "ababab".replace "b" "a" mode=Matching_Mode.First matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "aaabab"
            "ababab".replace "b" "a" mode=Matching_Mode.Last matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "ababaa"

            "aaaa".replace "aa" "c" matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "cc"
            "aaaa".replace "aa" "c" mode=Matching_Mode.First matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "caa"
            "aaaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "aac"

            "aaa".replace "aa" "c" matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "ca"
            "aaa".replace "aa" "c" mode=Matching_Mode.First matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "ca"
            "aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Text_Matcher.Case_Sensitive . should_equal "ac"
            "aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "ca"

            "aaa aaa".replace "aa" "c" matcher=Text_Matcher.Case_Sensitive . should_equal "ca ca"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.First matcher=Text_Matcher.Case_Sensitive . should_equal "ca aaa"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Text_Matcher.Case_Sensitive . should_equal "aaa ac"
            "aaa aaa".replace "aa" "c" matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "ca ca"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.First matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "ca aaa"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "aaa ca"

        Test.specify "in Regex mode should work with Unicode" <|
            "Korean: ê±´ë°˜".replace "ê±´ë°˜" "keyboard" matcher=Regex_Matcher.Regex_Matcher_Data . should_equal "Korean: keyboard"
            'sÅ›s\u{301}'.replace 'Å›' '-' matcher=Regex_Matcher.Regex_Matcher_Data . should_equal 's--'
            'sÅ›s\u{301}'.replace 's\u{301}' '-' matcher=Regex_Matcher.Regex_Matcher_Data . should_equal 's--'

        Test.specify "in Regex mode should support various Regex options" <|
            r1 = "Ä°iÄ°".replace "\w" "a" matcher=(Regex_Matcher.Regex_Matcher_Data match_ascii=True)
            r1 . should_equal "Ä°aÄ°"
            r2 = "abaBa".replace "b" "a" matcher=(Regex_Matcher.Regex_Matcher_Data case_sensitivity=Case_Sensitivity.Insensitive)
            r2 . should_equal "aaaaa"
            r3 = 'ab\na'.replace "b." "a"  matcher=(Regex_Matcher.Regex_Matcher_Data dot_matches_newline=True)
            r3 . should_equal "aaa"

            text = """
                Foo
                bar
            r4 = text.replace "(\n|\r)" ""  matcher=(Regex_Matcher.Regex_Matcher_Data multiline=True)
            r4 . should_equal "Foobar"

            r5 = "ababd".replace "b\w # Replacing a `b` followed by any word character" "a" matcher=(Regex_Matcher.Regex_Matcher_Data comments=True)
            r5 . should_equal "aaa"

        Test.specify "in Regex mode should allow referring to capture groups in substitutions" <|
            '<a href="url">content</a>'.replace '<a href="(.*?)">(.*?)</a>' '$2 is at $1' matcher=Regex_Matcher.Regex_Matcher_Data . should_equal 'content is at url'
            '<a href="url">content</a>'.replace '<a href="(?<address>.*?)">(?<text>.*?)</a>' '${text} is at ${address}' matcher=Regex_Matcher.Regex_Matcher_Data . should_equal 'content is at url'

main = Test_Suite.run_main spec
