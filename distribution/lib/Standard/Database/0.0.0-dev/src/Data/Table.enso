from Standard.Base import all
import Standard.Base.Data.Array_Proxy.Array_Proxy
import Standard.Base.Error.Common.Index_Out_Of_Bounds
import Standard.Base.Error.Common.Type_Error
import Standard.Base.Error.File_Error.File_Error
import Standard.Base.Error.Illegal_Argument.Illegal_Argument
import Standard.Base.Error.Illegal_State.Illegal_State
import Standard.Base.Error.Incomparable_Values.Incomparable_Values
import Standard.Base.Error.Unimplemented.Unimplemented

from Standard.Table import Auto_Detect, Aggregate_Column, Data_Formatter, Column_Name_Mapping, Column_Selector, Sort_Column, Match_Columns, Position, Set_Mode
import Standard.Table.Data.Column_Type_Selection.Column_Type_Selection
import Standard.Table.Data.Expression.Expression
import Standard.Table.Data.Expression.Expression_Error
import Standard.Table.Data.Join_Condition.Join_Condition
import Standard.Table.Data.Join_Kind.Join_Kind
import Standard.Table.Data.Report_Unmatched.Report_Unmatched
import Standard.Table.Data.Row.Row
import Standard.Table.Data.Table.Table as Materialized_Table
import Standard.Table.Data.Value_Type.Value_Type
import Standard.Table.Internal.Aggregate_Column_Helper
import Standard.Table.Internal.Java_Exports
import Standard.Table.Internal.Table_Helpers
import Standard.Table.Internal.Table_Helpers.Table_Column_Helper
import Standard.Table.Internal.Problem_Builder.Problem_Builder
import Standard.Table.Internal.Widget_Helpers
from Standard.Table.Data.Column import get_item_string, normalize_string_for_display
from Standard.Table.Data.Table import print_table
from Standard.Table.Internal.Filter_Condition_Helpers import make_filter_column
from Standard.Table.Errors import all

import project.Data.Column.Column
import project.Data.SQL_Statement.SQL_Statement
import project.Data.SQL_Type.SQL_Type
import project.Internal.Helpers
import project.Internal.Aggregate_Helper
import project.Internal.Common.Database_Join_Helper
import project.Internal.IR.Context.Context
import project.Internal.IR.SQL_Expression.SQL_Expression
import project.Internal.IR.From_Spec.From_Spec
import project.Internal.IR.Internal_Column.Internal_Column
import project.Internal.IR.SQL_Join_Kind.SQL_Join_Kind
import project.Internal.IR.Query.Query

from project.Errors import Unsupported_Database_Operation, Integrity_Error, Unsupported_Name

import project.Connection.Connection.Connection
polyglot java import java.sql.JDBCType
polyglot java import java.util.UUID

## Represents a column-oriented table data structure backed by a database.
type Table
    ## PRIVATE

       Represents a column-oriented table data structure backed by a database.

       Arguments:
       - name: The name of the table.
       - connection: The connection with which the table is associated.
       - internal_columns: The internal representation of the table columns.
       - context: The context associated with this table.
    Value name:Text connection:Connection (internal_columns:(Vector Internal_Column)) context:IR.Context

    ## UNSTABLE

       Returns a text containing an ASCII-art table displaying this data.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
         - format_terminal: whether ANSI-terminal formatting should be used
    display : Integer -> Boolean -> Text
    display self show_rows=10 format_terminal=False =
        df = self.read max_rows=show_rows
        all_rows_count = self.row_count
        display_dataframe df indices_count=0 all_rows_count format_terminal

    ## UNSTABLE

       Prints an ASCII-art table with this data to the standard output.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
    print : Integer -> Nothing
    print self show_rows=10 =
        IO.println (self.display show_rows format_terminal=True)
        IO.println ''

    ## UNSTABLE

       Converts this column to JS_Object representation.
    to_js_object : JS_Object
    to_js_object self = case self.internal_columns.is_empty of
        True -> JS_Object.from_pairs [["query", Nothing], ["message", "The table has no columns so a query cannot be generated."]]
        False -> self.to_sql.to_js_object

    ## UNSTABLE

       Returns the column with the given name.

       Arguments:
       - selector: The name or index of the column to get.
    @selector Widget_Helpers.make_column_name_selector
    at : Text | Integer -> Column ! No_Such_Column | Index_Out_Of_Bounds
    at self selector=0 = case selector of
        _ : Integer -> self.make_column (self.internal_columns.at selector)
        _ -> self.get selector (Error.throw (No_Such_Column.Error selector))

    ## Returns the column with the given name or index.

       Arguments:
       - selector: The name or index of the column being looked up.
       - if_missing: The value to use if the selector isn't present.
    @selector Widget_Helpers.make_column_name_selector
    get : Text | Integer -> Any -> Column | Any
    get self selector=0 ~if_missing=Nothing =
        internal_column = case selector of
            _ : Integer -> self.internal_columns.get selector if_missing=Nothing
            _ : Text -> self.internal_columns.find (p -> p.name == selector) if_missing=Nothing
            _ -> Error.throw (Illegal_Argument.Error "expected 'selector' to be either a Text or an Integer, but got "+(Meta.get_simple_type_name selector)+".")
        if internal_column.is_nothing then if_missing else self.make_column internal_column

    ## Gets the first column.
    first_column : Column ! Index_Out_Of_Bounds
    first_column self = self.at 0

    ## Gets the second column
    second_column : Column ! Index_Out_Of_Bounds
    second_column self = self.at 1

    ## Gets the last column
    last_column : Column ! Index_Out_Of_Bounds
    last_column self = self.at -1

    ## Returns the number of columns in the table.
    column_count : Integer
    column_count self = self.internal_columns.length

    ## Returns a new table with a chosen subset of columns, as specified by the
       `columns`, from the input table. Any unmatched input columns will be
       dropped from the output.

       Arguments:
       - columns: Column selection criteria - a single instance or Vector of
         names, indexes or `Column_Selector`.
       - reorder: By default, or if set to `False`, columns in the output will
         be in the same order as in the input table. If `True`, the order in the
         output table will match the order in the columns list. If a column is
         matched by multiple selectors in reorder mode, it will be placed at
         the position of the first one matched.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range` is
           raised as an error, unless `error_on_missing_columns` is set to
           `False`, in which case the problem is reported according to the
           `on_problems` setting.
       > Example
         Select columns by name.

             table.select_columns ["bar", "foo"]

       > Example
         Select columns using names passed as a Vector.

             table.select_columns ["bar", "foo"]

       > Example
         Select columns matching a regular expression.

             table.select_columns (Column_Selector.By_Name "foo.+" Case_Sensitivity.Insensitive use_regex=True)

       > Example
         Select the first two columns and the last column, moving the last one to front.

             table.select_columns [-1, 0, 1] reorder=True

       Icon: select_column
    select_columns : Text | Integer | Column_Selector | Vector (Integer | Text | Column_Selector) -> Boolean -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns | Column_Indexes_Out_Of_Range
    select_columns self (columns = [0]) (reorder = False) (error_on_missing_columns = True) (on_problems = Report_Warning) =
        new_columns = self.columns_helper.select_columns selectors=columns reorder=reorder error_on_missing_columns=error_on_missing_columns on_problems=on_problems
        self.updated_columns new_columns

    ## Returns a new table with the chosen set of columns, as specified by the
       `columns`, removed from the input table. Any unmatched input columns will
       be kept in the output. Columns are returned in the same order as in the
       input.

       Arguments:
       - columns: Column selection criteria - a single instance or Vector of
         names, indexes or `Column_Selector`, which are to be removed.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `False`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is reported according to the `on_problems`
           setting, unless `error_on_missing_columns` is set to `True`, in which
           case it is raised as an error.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range` is
           reported according to the `on_problems` setting, unless
           `error_on_missing_columns` is set to `True`, in which case it is
           raised as an error.

       > Example
         Remove columns with given names.

             table.remove_columns ["bar", "foo"]

       > Example
         Remove columns using names passed as a Vector.

             table.remove_columns ["bar", "foo"]

       > Example
         Remove columns matching a regular expression.

             table.remove_columns (Column_Selector.By_Name "foo.+" Case_Sensitivity.Insensitive use_regex=True)

       > Example
         Remove the first two columns and the last column.

             table.remove_columns [-1, 0, 1]
    remove_columns : Text | Integer | Column_Selector | Vector (Integer | Text | Column_Selector) -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns | Column_Indexes_Out_Of_Range
    remove_columns self (columns = [0]) (error_on_missing_columns = False) (on_problems = Report_Warning) =
        new_columns = self.columns_helper.remove_columns selectors=columns error_on_missing_columns=error_on_missing_columns on_problems=on_problems
        self.updated_columns new_columns

    ## Returns a new table with the specified selection of columns moved to
       either the start or the end in the specified order.

       Arguments:
       - columns: Column selection criteria - a single instance or Vector of
         names, indexes or `Column_Selector`, which should be reordered and
         specifying their order.
       - position: Specifies how to place the selected columns in relation to
         the remaining columns which were not matched by `columns` (if any).
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `False`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is reported according to the `on_problems`
           setting, unless `error_on_missing_columns` is set to `True`, in which
           case it is raised as an error.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range` is
           reported according to the `on_problems` setting, unless
           `error_on_missing_columns` is set to `True`, in which case it is
           raised as an error.

       > Example
         Move a column with a specified name to back.

             table.reorder_columns ["foo"] position=Position.After_Other_Columns

       > Example
         Move columns using names passed as a Vector.

             table.reorder_columns ["bar", "foo"] position=Position.After_Other_Columns

       > Example
         Move columns matching a regular expression to front, keeping columns matching "foo.+" before columns matching "b.*".

             table.reorder_columns (Column_Selector.By_Name "foo.+" Case_Sensitivity.Insensitive use_regex=True)

       > Example
         Swap the first two columns.

             table.reorder_columns [1, 0]

       > Example
         Move the first column to back.

             table.reorder_columns [0] position=Position.After_Other_Columns
    reorder_columns : Text | Integer | Column_Selector | Vector (Integer | Text | Column_Selector) -> Position -> Boolean -> Problem_Behavior -> Table ! Missing_Input_Columns | Column_Indexes_Out_Of_Range
    reorder_columns self (columns = [0]) (position = Position.Before_Other_Columns) (error_on_missing_columns = False) (on_problems = Report_Warning) =
        new_columns = self.columns_helper.reorder_columns selectors=columns position=position error_on_missing_columns on_problems=on_problems
        self.updated_columns new_columns

    ## Returns a new table with the columns sorted by name according to the
       specified sort method. By default, sorting will be according to
       case-sensitive ascending order based on the normalized Unicode ordering.

       Arguments:
       - order: Whether sorting should be in ascending or descending order.
       - text_ordering: The sort methodology to use.

       > Example
         Sort columns according to the default ordering.

             table.sort_columns

       > Example
         Sort columns according to the natural case-insensitive ordering.

             table.sort_columns text_ordering=(Text_Ordering.Case_Insensitive sort_digits_as_numbers=True)

       > Example
         Sort columns in descending order.

             table.reorder_columns Sort_Direction.Descending
    sort_columns : Sort_Direction -> Text_Ordering -> Table
    sort_columns self order=Sort_Direction.Ascending text_ordering=Text_Ordering.Default =
        new_columns = Table_Helpers.sort_columns internal_columns=self.internal_columns order text_ordering
        self.updated_columns new_columns

    ## Returns a new table with the columns renamed based on either a mapping
       from the old name to the new or a positional list of new names.

       Arguments:
       - column_map: Mapping from old column names to new or a vector of new
         column names to apply by position.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range` is
           raised as an error, unless `error_on_missing_columns` is set to
           `False`, in which case the problem is reported according to the
           `on_problems` setting.
         - Other problems are reported according to the `on_problems` setting:
             - If a column is matched by two selectors resulting in a different
               name mapping, a `Ambiguous_Column_Rename`.
             - If in `By_Position` mode and more names than columns are
               provided, a `Too_Many_Column_Names_Provided`.
             - If any of the new names are invalid, an
               `Invalid_Output_Column_Names`.
             - If any of the new names clash either with existing names or each
               other, a `Duplicate_Output_Column_Names`.

       > Example
         Rename the first column to "FirstColumn"

              table.rename_columns (Column_Name_Mapping.By_Position ["FirstColumn"])

       > Example
         Rename the first column to "FirstColumn" passed as a Vector

              table.rename_columns ["FirstColumn"]

       > Example
         Add a prefix to all column names.

              table.rename_columns (table.columns.map c-> "prefix_" + c.name)

       > Example
         For all columns starting with the prefix `name=`, replace it with `key:`.

              table.rename_columns (Column_Name_Mapping.By_Name (Map.from_vector [["name=(.*)", "key:$1"]]) Regex_Matcher.Value)
    rename_columns : Map | Vector Text | Column_Name_Mapping -> Boolean -> Problem_Behavior -> Table ! Missing_Input_Columns | Column_Indexes_Out_Of_Range | Ambiguous_Column_Rename | Too_Many_Column_Names_Provided | Invalid_Output_Column_Names | Duplicate_Output_Column_Names
    rename_columns self (column_map=(Column_Name_Mapping.By_Position ["Column"])) (error_on_missing_columns=True) (on_problems=Report_Warning) = case column_map of
        _ : Vector ->
            self.rename_columns (Column_Name_Mapping.By_Position column_map) error_on_missing_columns on_problems
        _ : Map ->
            self.rename_columns (Column_Name_Mapping.By_Name column_map) error_on_missing_columns on_problems
        _ ->
            case Table_Helpers.rename_columns internal_columns=self.internal_columns mapping=column_map error_on_missing_columns=error_on_missing_columns on_problems=on_problems of
                new_names ->
                    new_columns = self.internal_columns.map_with_index i->c->(c.rename (new_names.at i))
                    self.updated_columns new_columns

    ## PRIVATE

       Resolves the column name to a column within this table.

       Arguments:
       - column: The name (or column handle) for the column you want to resolve.

       If instead of a name, a column is provided, it is returned as-is as long
       as it comes from the same context.
    resolve : Text | Column -> Column
    resolve self column = case column of
        _ : Text -> Panic.rethrow (self.at column)
        _ ->
            if Helpers.check_integrity self column then column else
                Panic.throw (Integrity_Error.Error "Column "+column.name)

    ## ALIAS Filter Rows

       Selects only the rows of this table that correspond to `True` values of
       `filter`.

       Arguments:
       - column: The column to use for filtering. Can be a column name, index or
         the `Column` object itself.
       - filter: The filter to apply to the column. It can either be an instance
         of `Filter_Condition` or a predicate taking a cell value and returning
         a boolean value indicating whether the corresponding row should be kept
         or not.
       - on_problems: Specifies how to handle if a non-fatal problem occurs,
         attaching a warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If a column index is invalid, an `Index_Out_Of_Bounds` dataflow error
           is raised.
         - If the column is an invalid type for the filter, an
           `Invalid_Value_Type` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If filtering by equality on a floating-point column,
             a `Floating_Point_Equality`.

       > Example
         Get people older than 30.

             people.filter "Age" (Greater 30)

       > Example
         Filter people between 30 and 40.

             people.filter "Age" (Between 30 40)

       > Example
         Select rows where more than 50% of the stock is sold.

             table.filter "sold_stock" (Greater (table.at "total_stock" / 2))

       > Example
         Select people celebrating a jubilee.

             people.filter "age" (age -> (age%10 == 0))
    @column Widget_Helpers.make_column_name_selector
    @filter Filter_Condition.default_widget
    filter : (Column | Text | Integer) -> (Filter_Condition|(Any->Boolean)) -> Problem_Behavior -> Table ! No_Such_Column | Index_Out_Of_Bounds | Invalid_Value_Type
    filter self column filter=(Filter_Condition.Is_True) on_problems=Report_Warning = case column of
       _ : Column ->
           mask filter_column = case Helpers.check_integrity self filter_column of
               False ->
                   Error.throw (Integrity_Error.Error "Column "+filter_column.name)
               True ->
                   new_filters = self.context.where_filters + [filter_column.expression]
                   new_ctx = self.context.set_where_filters new_filters
                   self.updated_context new_ctx
           case filter of
               _ : Filter_Condition -> mask (make_filter_column column filter on_problems)
               _ : Function -> Error.throw (Unsupported_Database_Operation.Error "Filtering with a custom predicate is not supported in the database.")
       _ ->
           table_at = self.at column
           self.filter table_at filter on_problems

    ## ALIAS Filter Rows

       Selects only the rows of this table that correspond to `True` values of
       `filter`.

       Arguments:
       - expression: The expression to evaluate to filter the rows.
       - on_problems: Specifies how to handle non-fatal problems, attaching a
         warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - If the expression returns a column that does not have a boolean type,
           an `Invalid_Value_Type` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.

       > Example
         Select people celebrating a jubilee.

             people.filter_by_expression "[age] % 10 == 0"
    filter_by_expression : Text -> Problem_Behavior -> Table ! No_Such_Column | Invalid_Value_Type | Expression_Error
    filter_by_expression self expression on_problems=Report_Warning =
        column = self.compute expression on_problems
        self.filter column Filter_Condition.Is_True

    ## PRIVATE
    with_no_rows self =
        false_expression = SQL_Expression.Operation "==" [SQL_Expression.Constant SQL_Type.integer 1, SQL_Expression.Constant SQL_Type.integer 2]
        new_filters = self.context.where_filters + [false_expression]
        new_ctx = self.context.set_where_filters new_filters
        self.updated_context new_ctx

    ## UNSTABLE
       Creates a new Table with the specified range of rows from the input
       Table.

       Arguments:
       - range: The selection of rows from the table to return.
    take : (Index_Sub_Range | Range | Integer) -> Table
    take self range=(First 1) =
        _ = range
        msg = "`Table.take` is not yet implemented."
        Error.throw (Unsupported_Database_Operation.Error msg)

    ## UNSTABLE
       Creates a new Table from the input with the specified range of rows
       removed.


       Arguments:
       - range: The selection of rows from the table to remove.
    drop : (Index_Sub_Range | Range | Integer) -> Table
    drop self range=(First 1) =
        _ = range
        msg = "`Table.drop` is not yet implemented."
        Error.throw (Unsupported_Database_Operation.Error msg)

    ## UNSTABLE

       Returns a new Table that will include at most `max_rows` rows from the
       original Table.

       Arguments:
       - max_rows: The maximum number of rows to get from the table.

       Since this Table is backed by an SQL database, the Table returned by the
       `limit` method is deterministic only if the Table has been ordered (using
       the `order_by` method).

       Otherwise, no order is imposed, so the returned Table will include at most
       `max_rows` rows, but there are no guarantees on which rows will be
       selected. Moreover, even if the underlying table in the database did not
       change, different sets of rows may be returned each time the returned
       Table is materialized.

       The limit is applied at the very end, so the new Table behaves exactly as
       the old one, just limiting its results when being materialized.
       Specifically, applying further filters will still apply to the whole
       result set and the limit will be taken after applying these filters.

       > For example:
         In the call below, assuming that the table of `t1` contains rows for
         numbers 1, 2, ..., 10, will return rows starting from 6 and not an empty
         result as one could expect if the limit was applied before the filters.
             t1 = table.order_by ([Sort_Column.Name "A"]) . limit 5
             t2 = t1.filter 'A' (Greater than=5)
             t2.read
    limit : Integer -> Table
    limit self max_rows =
        new_ctx = self.context.set_limit max_rows
        self.updated_context new_ctx

    ## UNSTABLE
       ALIAS Add Column, Update Column

       Sets the column value at the given name.

       Arguments:
       - column: The new column or expression to create column.
       - new_name: Optional new name for the column.
       - set_mode: Specifies the expected behaviour in regards to existing
         column with the same name.
       - on_problems: Specifies how to handle problems with expression
         evaluation.

       ! Error Conditions

         - In the Database backend, if the column name is not valid, an
           `Unsupported_Name` dataflow error is raised.
         - If the column name is already present and `set_mode` is `Add`, a
           `Existing_Column` dataflow error is raised.
         - If the column name is not present and `set_mode` is `Update`, a
           `Missing_Column` dataflow error is raised.
         - If a column name referenced from within an expression cannot be
           found, a `No_Such_Column` dataflow error is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - The following problems with expression evaluation may be reported
           according to the `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.

       > Example
         Create a table where the values of the total stock in the inventory is
         doubled.

             import Standard.Examples

             example_set =
                 table = Examples.inventory_table
                 double_inventory = table.at "total_stock" * 2
                 table.set double_inventory new_name="total_stock"
                 table.set "2 * [total_stock]" new_name="total_stock_expr"
    set : Column | Text -> Text | Nothing -> Problem_Behavior -> Table ! Unsupported_Name | Existing_Column | Missing_Column | No_Such_Column | Expression_Error
    set self column new_name=Nothing set_mode=Set_Mode.Add_Or_Update on_problems=Report_Warning =
        resolved = case column of
            _ : Text -> self.compute column on_problems
            _ -> column
        renamed = if new_name.is_nothing then resolved else resolved.rename new_name

        Helpers.ensure_name_is_sane renamed.name <|
            index = self.internal_columns.index_of (c -> c.name == renamed.name)
            to_add = case set_mode of
                Set_Mode.Add_Or_Update -> True
                Set_Mode.Add -> if index.is_nothing then True else Error.throw (Existing_Column.Error renamed.name)
                Set_Mode.Update -> if index.is_nothing then Error.throw (Missing_Column.Error renamed.name) else True
            if to_add then
                new_col = renamed.as_internal
                new_cols = if index.is_nothing then self.internal_columns + [new_col] else
                    Vector.new self.column_count i-> if i == index then new_col else self.internal_columns.at i
                self.updated_columns new_cols

    ## Given an expression, create a derived column where each value is the
       result of evaluating the expression for the row.

       Arguments:
       - expression: The expression to evaluate.
       - on_problems: Specifies how to handle non-fatal problems, attaching a
         warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.
    compute : Text -> Problem_Behavior -> Column ! No_Such_Column | Invalid_Value_Type | Expression_Error
    compute self expression on_problems=Report_Warning =
        get_column name = self.at name
        make_constant value =
            new_type = SQL_Type.approximate_type value
            other = SQL_Expression.Constant new_type value
            Column.Value ("Constant_" + UUID.randomUUID.to_text) self.connection new_type other self.context
        new_column = Expression.evaluate expression get_column make_constant "Standard.Database.Data.Column" "Column" Column.var_args_functions
        problems = Warning.get_all new_column . map .value
        new_name = Expression.to_column_name expression
        result = new_column.rename new_name
        on_problems.attach_problems_before problems <|
            Warning.set result []

    ## UNSTABLE

       Returns the vector of columns contained in this table.
    columns : Vector Column
    columns self = Vector.from_polyglot_array <|
        Array_Proxy.new self.internal_columns.length i->
            self.make_column (self.internal_columns.at i)

    ## UNSTABLE

       Returns the vector of column names contained in this table.
    column_names : Vector Text
    column_names self = Vector.from_polyglot_array <|
        Array_Proxy.new self.internal_columns.length i->
            self.internal_columns.at i . name

    ## Returns a vector of rows contained in this table.

       In the database backend, it first materializes the table to in-memory.

       Arguments:
       - max_rows: The maximum amount of rows to return. It is mainly meant for
         the Database backend, to limit how many rows are downloaded. In the
         in-memory backend it is only kept for API compatibility.
    rows : Integer -> Vector Row
    rows self max_rows=1000 =
        self.read max_rows=max_rows . rows

    ## ALIAS sort
       Sorts the rows of the table according to the specified columns and order.

       Arguments:
       - columns: The columns and order to sort the table.
       - text_ordering: The ordering method to use on text values.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range` is
           raised as an error, unless `error_on_missing_columns` is set to
           `False`, in which case the problem is reported according to the
           `on_problems` setting.
         - If no columns have been selected for ordering,
           a `No_Input_Columns_Selected` is raised as dataflow error regardless
           of any settings.
         - If a column used for ordering contains values that cannot be
           compared, an `Incomparable_Values` error is raised.

       ? Missing Values

         Missing (`Nothing`) values are sorted as less than any other object.

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`.

             table.order_by ['Quantity']

       > Example
         Sorting `table` in descending order by the value in column `'Quantity'`.

             table.order_by [Sort_Column.Name 'Quantity' Sort_Direction.Descending]

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` for breaking ties.

             table.order_by ['Quantity', 'Rating']

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` in descending order for breaking
         ties.

             table.order_by [Sort_Column.Name 'Quantity', Sort_Column.Name 'Rating' Sort_Direction.Descending]

       > Example
         Order the table by the second column in ascending order. In case of any
         ties, break them based on the 7th column from the end of the table in
         descending order.

             table.order_by [1, Sort_Column.Index -7 Sort_Direction.Descending]

       > Example
         Sort the table by columns whose names start with letter `a`.

              table.order_by [(Sort_Column.Select_By_Name "a.*" use_regex=True case_sensitivity=Case_Sensitivity.Insensitive)]
    order_by : Text | Sort_Column | Vector (Text | Sort_Column) -> Text_Ordering -> Boolean -> Problem_Behavior -> Table  ! Incomparable_Values | No_Input_Columns_Selected | Missing_Input_Columns | Column_Indexes_Out_Of_Range
    order_by self (columns = ([(Sort_Column.Name (self.columns.at 0 . name))])) text_ordering=Text_Ordering.Default error_on_missing_columns=True on_problems=Problem_Behavior.Report_Warning = Panic.handle_wrapped_dataflow_error <|
        problem_builder = Problem_Builder.new error_on_missing_columns=error_on_missing_columns types_to_always_throw=[No_Input_Columns_Selected]
        columns_for_ordering = Table_Helpers.prepare_order_by self.columns columns problem_builder
        problem_builder.attach_problems_before on_problems <|
            new_order_descriptors = columns_for_ordering.map selected_column->
                internal_column = selected_column.column
                associated_selector = selected_column.associated_selector
                ## FIXME [RW] this is only needed because `Vector.map` does not
                   propagate dataflow errors correctly. See:
                   https://www.pivotaltracker.com/story/show/181057718
                Panic.throw_wrapped_if_error <|
                    self.connection.dialect.prepare_order_descriptor internal_column associated_selector.direction text_ordering
            new_ctx = self.context.add_orders new_order_descriptors
            self.updated_context new_ctx

    ## Returns the distinct set of rows within the specified columns from the
       input table.

       When multiple rows have the same values within the specified columns, the
       first row of each such set is returned if possible, but in database
       backends any row from each set may be returned (for example if the row
       ordering is unspecified).

       For the in-memory table, the unique rows will be in the order they
       occurred in the input (this is not guaranteed for database operations).

       Arguments:
       - columns: The columns of the table to use for distinguishing the rows.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If no valid columns are selected, a `No_Input_Columns_Selected`, is
           reported as a dataflow error regardless of setting.
         - If floating points values are present in the distinct columns, a
           `Floating_Point_Equality` is reported according to the `on_problems`
           setting.
    distinct : Text | Integer | Column_Selector | Vector (Integer | Text | Column_Selector) -> Case_Sensitivity -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns | No_Input_Columns_Selected | Floating_Point_Equality
    distinct self columns=self.column_names case_sensitivity=Case_Sensitivity.Default error_on_missing_columns=True on_problems=Report_Warning =
        key_columns = self.columns_helper.select_columns selectors=columns reorder=True error_on_missing_columns=error_on_missing_columns on_problems=on_problems . catch No_Output_Columns _->
            Error.throw No_Input_Columns_Selected
        problem_builder = Problem_Builder.new
        new_table = self.connection.dialect.prepare_distinct self key_columns case_sensitivity problem_builder
        problem_builder.attach_problems_before on_problems new_table

    ## Joins two tables according to the specified join conditions.

       Arguments:
       - right: The table to join with.
       - join_kind: The `Join_Kind` for the joining the two tables.
       - on: A single condition or a common column name, or a list thereof, on
         which to correlate rows from the two tables. If multiple conditions
         are supplied, rows are correlated only if all are true.
         If common column names are provided, these columns should be present
         in both tables and an equality condition is added for each of them.
       - right_prefix: The prefix added to right table column names in case of
         name conflict.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If a column name cannot be found, a `No_Such_Column` is reported
           and an empty result is reported.
         - If a column index is invalid, an `Index_Out_Of_Bounds` is
           reported and an empty result is reported.
         - If there are column names that are clashing between the two tables, a
           `Duplicate_Output_Column_Names` is reported and the columns from the
           table are renamed as described below.
         - If a join condition correlates columns whose types are not compatible
           (for example comparing numeric types with text), an
           `Invalid_Value_Type` is reported.
         - If decimal columns are joined on equality, a
           `Floating_Point_Equality` is reported.

         In any of the above cases, if a problem occurs, the resulting table
         will have the desired structure, but it will be empty to indicate that
         the join has failed due to an erroneous join condition.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Result Ordering

         The ordering of rows in the resulting table is not specified.

       ? Joining on equality of columns with the same name

         When joining two columns with the same name and an equality condition,
         only one copy of column will be included in the output (avoiding
         unnecessary duplication and renaming).

       ? Same-name column join shorthand

         As a shorthand, providing a column name or a list of column names
         allows to join the two tables on equality of corresponding columns with
         the same name. So `table.join other on=["A", "B"]` is a shorthand for:
             table.join other on=[Join_Condition.Equals "A" "A", Join_Condition.Equals "B" "B"]
    @join_kind Widget_Helpers.join_kind_selector
    @on Widget_Helpers.make_column_name_selector
    join : Table -> Join_Kind -> Join_Condition | Text | Vector (Join_Condition | Text) -> Text -> Problem_Behavior -> Table
    join self right join_kind=Join_Kind.Inner on=[Join_Condition.Equals 0 0] right_prefix="Right_" on_problems=Report_Warning =
        can_proceed = if Table_Helpers.is_table right . not then Error.throw (Type_Error.Error Table right "right") else
            same_backend = case right of
                _ : Table -> True
                _ -> False
            if same_backend . not then Error.throw (Illegal_Argument.Error "Currently cross-backend joins are not supported. You need to upload the in-memory table before joining it with a database one, or materialize this table.") else
                True
        if can_proceed then
            left = self
            new_table_name = left.name + "_" + right.name

            needed_indicators = case join_kind of
                Join_Kind.Left_Exclusive  -> Pair.new False True
                Join_Kind.Right_Exclusive -> Pair.new True False
                _ -> Pair.new False False
            subquery_setups = Database_Join_Helper.prepare_subqueries left right needed_indicators.first needed_indicators.second
            left_setup = subquery_setups.first
            right_setup = subquery_setups.second

            problem_builder = Problem_Builder.new
            join_resolution = Database_Join_Helper.make_join_helpers left right left_setup.column_mapping right_setup.column_mapping . resolve on on_problems
            result_columns = Database_Join_Helper.select_columns_for_join join_kind left_setup.new_columns right_setup.new_columns join_resolution.redundant_column_names right_prefix problem_builder

            ## TODO proper equality of nulls in join conditions, see:
               https://www.pivotaltracker.com/story/show/184109759
            on_expressions = join_resolution.conditions

            where_expressions = case join_kind of
                Join_Kind.Left_Exclusive  ->
                    is_right_missing = SQL_Expression.Operation "IS_NULL" [right_setup.indicator_column.expression]
                    [is_right_missing]
                Join_Kind.Right_Exclusive ->
                    is_left_missing = SQL_Expression.Operation "IS_NULL" [left_setup.indicator_column.expression]
                    [is_left_missing]
                _ -> []

            sql_join_kind = case join_kind of
                Join_Kind.Inner           -> SQL_Join_Kind.Inner
                Join_Kind.Left_Outer      -> SQL_Join_Kind.Left
                Join_Kind.Right_Outer     -> SQL_Join_Kind.Right
                Join_Kind.Full            -> SQL_Join_Kind.Full
                Join_Kind.Left_Exclusive  -> SQL_Join_Kind.Left
                Join_Kind.Right_Exclusive -> SQL_Join_Kind.Right

            problem_builder.attach_problems_before on_problems <|
                self.connection.dialect.prepare_join self.connection sql_join_kind new_table_name left_setup.subquery right_setup.subquery on_expressions where_expressions columns_to_select=result_columns

    ## ALIAS Cartesian Join
       Joins tables by pairing every row of the left table with every row of the
       right table.

       Arguments:
       - right: The table to join with.
       - right_row_limit: If the number of rows in the right table exceeds this,
         then a `Cross_Join_Row_Limit_Exceeded` problem is raised. The check
         exists to avoid exploding the size of the table by accident. This check
         can be disabled by setting this parameter to `Nothing`.
       - right_prefix: The prefix added to right table column names in case of
         name conflict. See "Column Renaming" below for more information.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If the `right` table has more rows than the `right_row_limit` allows,
           a `Cross_Join_Row_Limit_Exceeded` is reported. In warning/ignore
           mode, the join is still executed.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Result Ordering

         Rows in the result are first ordered by the order of the corresponding
         rows from the left table and then the order of rows from the right
         table. This applies only if the order of the rows was specified (for
         example, by sorting the table; in-memory tables will keep the memory
         layout order while for database tables the order may be unspecified).
    cross_join : Table -> Integer | Nothing -> Text -> Problem_Behavior -> Table
    cross_join self right right_row_limit=100 right_prefix="Right_" on_problems=Report_Warning =
        _ = [right, right_row_limit, right_prefix, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "Table.cross_join is not implemented yet for the Database backends.")

    ## ALIAS Join By Row Position
       Joins two tables by zipping rows from both tables table together - the
       first row of the left table is correlated with the first one of the right
       one etc.

       Arguments:
       - right: The table to join with.
       - keep_unmatched: If set to `True`, the result will include as many rows
         as the larger of the two tables - the last rows of the larger table
         will have nulls for columns of the smaller one. If set to `False`, the
         result will have as many rows as the smaller of the two tables - the
         additional rows of the larger table will be discarded. The default
         value is `Report_Unmatched` which means that the user expects that two
         tables should have the same amount of rows; if they do not, the
         behaviour is the same as if it was set to `True` - i.e. the unmatched
         rows are kept with `Nothing` values for the other table, but a
         `Row_Count_Mismatch` problem is also reported.
       - right_prefix: The prefix added to right table column names in case of
         name conflict. See "Column Renaming" below for more information.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If the tables have different number of rows and `keep_unmatched` is
           set to `Report_Unmatched`, the join will report `Row_Count_Mismatch`.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Row Ordering

         This operation requires a well-defined order of rows in the input
         tables. In-memory tables rely on the ordering stemming directly from
         their layout in memory. Database tables may not impose a deterministic
         ordering. If the table defines a primary key, it is used to by default
         to ensure deterministic ordering. That can be overridden by specifying
         a different ordering using `Table.order_by`. If no primary key was
         defined nor any ordering was specified explicitly by the user, the
         order of columns is undefined and the operation will fail, reporting a
         `Undefined_Column_Order` problem and returning an empty table.
    zip : Table -> Boolean | Report_Unmatched -> Text -> Problem_Behavior -> Table
    zip self right keep_unmatched=Report_Unmatched right_prefix="Right_" on_problems=Report_Warning =
        _ = [right, keep_unmatched, right_prefix, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "Table.zip is not implemented yet for the Database backends.")

    ## ALIAS append, concat
       Appends records from other table(s) to this table.

       Arguments:
       - tables: A single table or a vector of tables to append to this one. The
         tables are concatenated in the order they are specified, with `self`
         being the first one.
       - match_columns: Specifies how to match the columns.
         - If `Match_Columns.By_Name` - the columns are matched by name across
           all provided tables.
           If unmatched columns are to be dropped, the resulting table will keep
           only the set of columns that appear in all provided tables, in the
           relative order that they appeared in the `self` table.
           If unmatched columns are kept, they are added in the order of
           appearance - i.e. first all columns from `self` will be added in the
           original order, then any columns from the second table that were not
           matched will be added at the end (preserving their relative order),
           and so on for all the remaining tables.
         - If `Match_Columns.By_Position` - the columns are mapped by position.
           If unmatched columns are to be dropped, the resulting table will have
           as many columns as the table that had the least columns and the
           column names of the first table (`self`) will be used.
           If unmatched columns are kept, the resulting table will have as many
           columns as the table with the most columns. Since the first table may
           not have all the necessary columns to provide column names for the
           result, the result will have column names taken from the first table
           that has the biggest number of columns.
       - keep_unmatched_columns: If set to `True`, unmatched columns are kept
         and are padded with `Nothing` for tables that did not have them.
         If set to `False`, only the common subset of columns is kept - any
         column that is not present in all tables is dropped. Defaults to
         `Report_Unmatched`, which behaves like `True` - unmatched columns are
         kept and padded with `Nothing`, but a problem is reported.
       - allow_type_widening: Specifies if the resulting column type should be
         adjusted to fit columns from all arguments. If `True`, a common type
         will be chosen for each column (see "Unifying Column Types" below).
         If `False`, the resulting column type will be the same as in the first
         table containing the column. In this case, all columns that are
         concatenated must have the same type as the first one (unless this
         had a `Mixed` type - in which case it will accept any other types).
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If `keep_unmatched_columns` is set to `Report_Unmatched` (the
           default):
           - If matching by name and there are columns that are not present in
             all tables, `Unmatched_Columns` is reported.
           - If matching by position and column counts of the merged tables
             differ, then a `Column_Count_Mismatch` is reported. The error will
             contain the greatest column count as its `expected` value and the
             smallest one as its `actual` value.
         - If `keep_unmatched_columns` is set to `False` and matching by name,
           it is possible that there are no columns that are common to all
           provided tables, in that case `No_Output_Columns` is thrown as a
           dataflow error regardless of the `on_problems` setting, because there
           are no columns to include in the resulting table.
         - If type widening is disabled and one of corresponding columns has a
           type that is incompatible with the type coming from the first table,
           a `Column_Type_Mismatch` is reported. The problematic column will be
           dropped from the resulting table. With type widening disabled, the
           subsequent tables must have the same types as the first one, unless
           the type of the first one was `Mixed` which will accept any other
           type.
         - If a common type coercion for a set of matched columns from
           concatenated tables cannot be found, a `No_Common_Type` is reported.
           In warning or ignore mode, the problematic column will be dropped
           from the resulting table.

       ? Unifying Column Types

         If `allow_type_widening` is set to `True`, then the following rules are
         used to find a common type that will fit values from all merged tables.

         Numeric columns are unified by finding the most general type that can
         fit all of the columns. The biggest integer type will be chosen and if
         integers and decimals are mixed, the decimal type will be chosen.
         If boolean columns are mixed with numeric columns, they will be coerced
         to the numeric type (and converted to 0 and 1).

         Text types will also be coerced according to the common rules - if
         constant-length texts of different lengths are mixed, they will be
         coerced to a varying-length type.

         If one of the matched columns has `Mixed` type, that type will be used
         regardless of types of other columns. Mixing any other types will
         result in a `No_Common_Type` problem. If columns of incompatible types
         are meant to be mixed, at least one of them should be explicitly
         retyped to the `Mixed` type to indicate that intention.
    union : (Table | Vector Table) -> Match_Columns -> Boolean | Report_Unmatched -> Boolean -> Problem_Behavior -> Table
    union self tables match_columns=Match_Columns.By_Name keep_unmatched_columns=Report_Unmatched allow_type_widening=True on_problems=Report_Warning =
        _ = [tables, match_columns, keep_unmatched_columns, allow_type_widening, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "Table.union is not implemented yet for the Database backends.")

    ## ALIAS group, summarize

       Aggregates the rows in a table using any `Group_By` entries in columns.
       The columns argument specifies which additional aggregations to perform and to return.

       Arguments:
       - columns: Vector of `Aggregate_Column` specifying the aggregated table.
         Expressions can be used within the aggregate column to perform more
         complicated calculations.
       - error_on_missing_columns: Specifies if a missing columns in aggregates
         should result in an error regardless of the `on_problems` settings.
         Defaults to `False`, meaning that problematic aggregate will not be
         included in the result and the problem reported according to the
         `on_problems` setting.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range` is
           reported according to the `on_problems` setting, unless
           `error_on_missing_columns` is set to `True`, in which case it is
           raised as an error. Problems resolving `Group_By` columns are
           reported as dataflow errors regardless of these settings, as a
           missing grouping will completely change semantics of the query.
         - If a column selector is given as a `Text` and it does not match any
           columns in the input table nor is it a valid expression, an
           `Invalid_Aggregate_Column` error is raised according to the
           `on_problems` settings (unless `error_on_missing_columns` is set to
           `True` in which case it will always be an error). Problems resolving
           `Group_By` columns are reported as dataflow errors regardless of
           these settings, as a missing grouping will completely change
           semantics of the query.
         - If an aggregation fails, an `Invalid_Aggregation` dataflow error is
           raised.
         - The following additional problems may be reported according to the
           `on_problems` settings:
           - If there are invalid column names in the output table,
             a `Invalid_Output_Column_Names`.
           - If there are duplicate column names in the output table,
             a `Duplicate_Output_Column_Names`.
           - If grouping on or computing the `Mode` on a floating point number,
             a `Floating_Point_Equality`.
           - If when concatenating values there is an quoted delimited,
             an `Unquoted_Delimiter`
           - If there are more than 10 issues with a single column,
             an `Additional_Warnings`.

       > Example
         Group by the Key column, count the rows

              table.aggregate [Aggregate_Column.Group_By "Key", Aggregate_Column.Count]
    aggregate : Vector Aggregate_Column -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Invalid_Aggregate_Column | Invalid_Output_Column_Names | Duplicate_Output_Column_Names | Floating_Point_Equality | Invalid_Aggregation | Unquoted_Delimiter | Additional_Warnings
    aggregate self columns (error_on_missing_columns=False) (on_problems=Report_Warning) =
        validated = Aggregate_Column_Helper.prepare_aggregate_columns columns self error_on_missing_columns=error_on_missing_columns
        on_problems.attach_problems_before validated.problems <|
            key_columns = validated.key_columns
            resolved_aggregates = validated.valid_columns
            key_expressions = key_columns.map .expression
            new_ctx = self.context.set_groups key_expressions
            results = resolved_aggregates.map p->
                agg = p.second
                new_name = p.first
                Aggregate_Helper.make_aggregate_column self agg new_name . catch

            partitioned = results.partition (_.is_a Internal_Column.Value)

            ## When working on join we may encounter further issues with having
               aggregate columns exposed directly, it may be useful to re-use
               the `lift_aggregate` method to push the aggregates into a
               subquery.
            new_columns = partitioned.first
            problems = partitioned.second
            on_problems.attach_problems_before problems <|
                self.updated_context_and_columns new_ctx new_columns subquery=True

    ## Returns a new table with a chosen subset of columns left unchanged and
       the other columns pivoted to rows with a single name field and a single
       value field.

       Arguments:
       - id_fields: Set of fields to remain as columns. These values will be
         repeated for each data field that is pivoted.
       - name_field: The name of the field that will contain the names of the
         pivoted fields. If this name is already in use, it will be renamed
         with a numeric suffix.
       - value_field: The name of the field that will contain the values of the
         pivoted fields. If this name is already in use, it will be renamed
         with a numeric suffix.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range` is
           raised as an error, unless `error_on_missing_columns` is set to
           `False`, in which case the problem is reported according to the
           `on_problems` setting.
         - If any column names in the new table are clashing, a
           `Duplicate_Output_Column_Names` is reported according to the
           `on_problems` setting.
    transpose :  Text | Integer | Column_Selector | Vector (Integer | Text | Column_Selector) -> Text -> Text -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns | Column_Indexes_Out_Of_Range | Duplicate_Output_Column_Names
    transpose self id_fields=[] (name_field="Name") (value_field="Value") (error_on_missing_columns=True) (on_problems = Report_Warning) =
        ## Avoid unused arguments warning. We cannot rename arguments to `_`,
           because we need to keep the API consistent with the in-memory table.
        _ = [id_fields, name_field, value_field, error_on_missing_columns, on_problems]
        msg = "Transposing columns is not supported in database tables, the table has to be materialized first with `read`."
        Error.throw (Unsupported_Database_Operation.Error msg)

    ## Returns a new table using a chosen field as the column header and then
       aggregating the rows within each value as specified. Optionally, a set of
       fields can be used to group the rows.

       Arguments:
       - group_by: Set of fields to group by. If not provided, a single row will
         be produced.
       - name_column: The field to use as the column header. If this field is
         not found, then each value will be a single column.
       - values: The aggregation to perform on each set of rows. Can be a single
         aggregation or a vector of aggregations. Expressions can be used within
         the aggregation to perform more complicated calculations.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `group_by` or `name_field` is not in the input table,
           a `Missing_Input_Columns` is raised as a dataflow error.
         - If a column index in `group_by`, `name_field` or `values` is out of
           range, a `Column_Indexes_Out_Of_Range` is raised as a dataflow error.
         - If a column selector in `values` given as a `Text` and it does not
           match any columns in the input table nor is it a valid expression, an
           `Invalid_Aggregate_Column` dataflow error is raised.
         - If an aggregation fails, an `Invalid_Aggregation` dataflow error is
           raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If grouping on, using as the column name, or computing the `Mode` on
             a floating point number, a `Floating_Point_Equality`.
           - If when concatenating values there is an quoted delimited,
             an `Unquoted_Delimiter`
           - If there are more than 10 issues with a single column,
             an `Additional_Warnings`.
    cross_tab : Text | Integer | Column_Selector | Vector (Integer | Text | Column_Selector) -> (Text | Integer | Column) -> Vector Aggregate_Column -> Problem_Behavior -> Table ! Missing_Input_Columns | Column_Indexes_Out_Of_Range | Invalid_Aggregate_Column | Floating_Point_Equality | Invalid_Aggregation | Unquoted_Delimiter | Additional_Warnings
    cross_tab self group_by=[] name_column=self.column_names.first values=Aggregate_Column.Count (on_problems=Report_Warning) =
        ## Avoid unused arguments warning. We cannot rename arguments to `_`,
           because we need to keep the API consistent with the in-memory table.
        _ = [group_by, name_column, values, on_problems]
        msg = "Cross tab of database tables is not supported, the table has to be materialized first with `read`."
        Error.throw (Unsupported_Database_Operation.Error msg)

    ## Parsing values is not supported in database tables, the table has to be
       loaded into memory first with `read`.
    parse_values : Data_Formatter -> (Nothing | Vector Column_Type_Selection) -> Problem_Behavior -> Table
    parse_values self value_formatter=Data_Formatter column_types=Nothing on_problems=Report_Warning =
        ## Avoid unused arguments warning. We cannot rename arguments to `_`,
           because we need to keep the API consistent with the in-memory table.
        _ = [value_formatter, column_types, on_problems]
        msg = "Parsing values is not supported in database tables, the table has to be materialized first with `read`."
        Error.throw (Unsupported_Database_Operation.Error msg)

    ## ALIAS dropna
       ALIAS drop_missing_rows
       Remove rows which are all blank or containing blank values.

       Arguments:
       - when_any: If `True`, then remove any row containing any blank values.
         If `False`, then only remove rows with all blank values.
       - treat_nans_as_blank: If `True`, then `Number.nan` is considered as blank.

       ? Blank values
         Blank values are `Nothing`, `""` and depending on setting `Number.nan`.
    filter_blank_rows : Boolean -> Boolean -> Table
    filter_blank_rows self when_any=False treat_nans_as_blank=False =
        Table_Helpers.filter_blank_rows self when_any treat_nans_as_blank

    ## ALIAS count
       Returns the amount of rows in this table.
    row_count : Integer
    row_count self = if self.internal_columns.is_empty then 0 else
        expr = SQL_Expression.Operation "COUNT_ROWS" []
        column_name = "row_count"
        ## We need to keep some column in the subquery which will determine if
           the query is performing regular selection or aggregation. To avoid
           computing too much we do not pass all the columns but only the first
           one.
        setup = self.context.as_subquery self.name [[self.internal_columns.first]]
        new_ctx = Context.for_subquery setup.subquery
        query = Query.Select [[column_name, expr]] new_ctx
        sql = self.connection.dialect.generate_sql query
        table = self.connection.read_statement sql
        table.at column_name . at 0

    ## UNSTABLE

       Returns a materialized dataframe containing rows of this table.

       Arguments:
       - max_rows: specifies a maximum amount of rows to fetch; if not set, all
         available rows are fetched.
    read : (Integer | Nothing) -> Materialized_Table
    read self max_rows=Nothing =
        preprocessed = self.limit max_rows
        case preprocessed.internal_columns.is_empty of
            True ->
                Error.throw (Illegal_Argument.Error "Cannot create a table with no columns.")
            False ->
                sql = preprocessed.to_sql
                expected_types = preprocessed.internal_columns.map .sql_type
                self.connection.read_statement sql expected_types

    ## UNSTABLE

       Returns an SQL statement that will be used for materializing this table.
    to_sql : SQL_Statement
    to_sql self =
        cols = self.internal_columns.map (c -> [c.name, c.expression])
        case cols.is_empty of
            True -> Error.throw <| Unsupported_Database_Operation.Error "Cannot generate SQL for a table with no columns."
            False ->
                query = Query.Select cols self.context
                self.connection.dialect.generate_sql query

    ## Returns a Table describing this table's contents.

       The table lists all columns, counts of non-null items and storage types
       of each column.
    info : Table
    info self =
        cols = self.internal_columns
        count_query =
            ## Performing a subquery is the most robust way to handle both
               regular columns and aggregates.
               Naively wrapping each column in a `COUNT(...)` will not
               always work as aggregates cannot be nested.
            setup = self.context.as_subquery self.name [self.internal_columns]
            new_ctx = Context.for_subquery setup.subquery
            new_columns = setup.new_columns.first.map column->
                [column.name, SQL_Expression.Operation "COUNT" [column.expression]]
            query = Query.Select new_columns new_ctx
            self.connection.dialect.generate_sql query
        count_table = self.connection.read_statement count_query
        counts = if cols.is_empty then [] else count_table.columns.map c-> c.at 0
        types = cols.map c-> c.sql_type.name
        Materialized_Table.new [["Column", cols.map .name], ["Items Count", counts], ["SQL Type", types]]

    ## PRIVATE

       Helper to create columns from internal columns.

       Arguments:
       - internal: The internal column to use for creating a column.
    make_column : Internal_Column -> Column
    make_column self internal =
        Column.Value internal.name self.connection internal.sql_type internal.expression self.context

    ## PRIVATE
    columns_helper : Table_Column_Helper
    columns_helper self =
        Table_Helpers.Table_Column_Helper.Value self.internal_columns self.make_column self .read

    ## PRIVATE

       Returns a copy of this table with updated internal columns.

       Arguments:
       - columns: The columns with which to update this table.
    updated_columns : Vector Internal_Column -> Table
    updated_columns self internal_columns = Table.Value self.name self.connection internal_columns self.context

    ## PRIVATE

       Returns a copy of this table with updated context.

       Arguments:
       - ctx: The new context for this table.
    updated_context : Context -> Table
    updated_context self ctx = Table.Value self.name self.connection self.internal_columns ctx

    ## PRIVATE

       Returns a copy of this table with updated context and columns.

       Arguments:
       - ctx: The new context for this table.
       - internal_columns: The new columns to include in the table.
       - subquery: A boolean indicating whether the operation should be wrapped
         in a subquery. This is a simple workaround for operations which may be
         affected by further operations if not wrapped. For example, a group-by
         may need to be wrapped in this way if a filter is to be performed on it
         later on. Ideally, this should be done only on demand, if the
         subsequent operation needs it and operations like join should try to
         avoid nesting subqueries without necessity. However, for now, for
         simplicity, we are always wrapping brittle operations. This may be
         revised in the future, to generate better and more concise SQL code.
    updated_context_and_columns : Context -> Vector Internal_Column -> Table
    updated_context_and_columns self ctx internal_columns subquery=False = case subquery of
        True ->
            setup = ctx.as_subquery self.name [internal_columns]
            new_ctx = Context.for_subquery setup.subquery
            new_columns = setup.new_columns.first
            Table.Value self.name self.connection new_columns new_ctx
        False ->
            Table.Value self.name self.connection internal_columns ctx

    ## PRIVATE

       Inserts a new row to the table.

       Arguments:
       - values: The values making up the row of the table.

       It actually modifies the underlying table in the database.  It can only
       be called on the Table if no operations modifying it have been performed
       like modifying, removing or adding columns, filtering, grouping etc.
    insert : Vector Any -> Nothing
    insert self values =
        table_name = case self.context.from_spec of
            From_Spec.Table name _ -> name
            _ -> Error.throw <| Illegal_State.Error "Inserting can only be performed on tables as returned by `query`, any further processing is not allowed."
        # TODO [RW] before removing the PRIVATE tag, add a check that no bad stuff was done to the table as described above
        pairs = self.internal_columns.zip values col-> value->
            [col.name, SQL_Expression.Constant col.sql_type value]
        query = self.connection.dialect.generate_sql <| Query.Insert table_name pairs
        affected_rows = self.connection.execute_update query
        case affected_rows == 1 of
            False -> Error.throw <| Illegal_State.Error "The update unexpectedly affected "+affected_rows.to_text+" rows."
            True -> Nothing

    ## Provides a simplified text representation for display in the REPL and errors.
    to_text : Text
    to_text self = "(Database Table "+self.name.to_text+")"

    ## This function writes the table into a file.

       The specific behavior of the various `File_Format`s is specified below.

       Arguments:
       - path: The path to the output file.
       - format: The format of the file.
         If `Auto_Detect` is specified; the provided file determines the
         specific type and configures it appropriately. Details of this type are
         below.
       - on_existing_file: Specified how to handle if the file already exists.
       - match_columns: Specifies how to match columns against an existing file.
         If `Match_Columns.By_Name` - the columns are mapped by name against an
         existing file. If there is a mismatch, then a `Column_Name_Mismatch`
         error is raised.
         If `Match_Columns.By_Position` - the columns are mapped by position
         against an existing file. If there is a mismatch, then a
         `Column_Count_Mismatch` error is raised.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default. The specific issues depend on the `File_Format`
         argument.

       Returns:
       - If an unsupported `File_Format` is specified, an
         `Illegal_Argument` is raised.
       - If the path to the parent location cannot be found or the filename is
         invalid, a `File_Error.Not_Found` is raised.
       - If another IO error occurs, such as access denied, an
         `File_Error.IO_Error` is raised.
       - If appending and the columns do not match, a `Column_Count_Mismatch` is
         raised.
       - Other specific errors or warnings that can be raised depend on the
         format argument.
       - Otherwise, the file is loaded following the rules of the format
         parameter.

       ? `File_Format` write behaviors

         - `Auto_Detect`: The file format is determined by the provided file.
         - `Bytes` and `Plain_Text`: The Table does not support these types in
            the `write` function. If passed as format, an
            `Illegal_Argument` is raised. To write out the table as plain
            text, the user needs to call the `Text.from Table` method and then
            use the `Text.write` function.

       > Example
         Write a database table to a CSV file.

             import Standard.Examples
             from Standard.Database import all

             example_to_csv =
                 connection = Database.connect (SQLite (File.new "db.sqlite"))
                 table = connection.query (SQL_Query.Table_Name "Table")
                 table.write (enso_project.data / "example_csv_output.csv")
    write : File|Text -> File_Format -> Existing_File_Behavior -> Match_Columns -> Problem_Behavior -> Nothing ! Column_Count_Mismatch | Illegal_Argument | File_Error
    write self path format=Auto_Detect on_existing_file=Existing_File_Behavior.Backup match_columns=Match_Columns.By_Name on_problems=Report_Warning =
        # TODO This should ideally be done in a streaming manner, or at least respect the row limits.
        self.read.write path format on_existing_file match_columns on_problems

## PRIVATE

   Creates a Table out of a connection, name and list of column names.

   Arguments:
   - connection: The connection to a database.
   - table_name: The name of the table to get.
   - columns: The names of the columns to get.
   - ctx: The context to use for the table.
# make_table : Connection -> Text -> Vector [Text, SQL_Type] -> Context -> Table
make_table : Connection -> Text -> Vector -> Context -> Table
make_table connection table_name columns ctx =
    if columns.is_empty then Error.throw (Illegal_State.Error "Unexpectedly attempting to create a Database Table with no columns. This is a bug in the Database library.") else
        cols = columns.map (p -> Internal_Column.Value p.first p.second (SQL_Expression.Column table_name p.first))
        Table.Value table_name connection cols ctx

## PRIVATE

   Renders an ASCII-art representation for a Table from a dataframe that
   contains a fragment of the underlying data and count of all rows.

   Arguments:
   - df: The materialized dataframe that contains the data to be displayed, it
     should have no indices set.
   - indices_count: Indicates how many columns from the materialized dataframe
     should be treated as indices in the display (index columns will be bold if
     `format_terminal` is enabled).
   - all_rows_count: The count of all rows in the underlying Table; if
     `all_rows_count` is bigger than the amount of rows of `df`, an additional
     line will be included that will say how many hidden rows there are.
   - format_term: A boolean flag, specifying whether to use ANSI escape codes
     for rich formatting in the terminal.
display_dataframe : Materialized_Table -> Integer -> Integer -> Boolean -> Text
display_dataframe df indices_count all_rows_count format_terminal =
    cols = Vector.from_polyglot_array df.java_table.getColumns
    col_names = cols.map .getName . map normalize_string_for_display
    col_vals = cols.map .getStorage
    display_rows = df.row_count
    rows = Vector.new display_rows row_num->
        col_vals.map col->
            if col.isNa row_num then "Nothing" else get_item_string col row_num
    table = print_table col_names rows indices_count format_terminal
    if display_rows == all_rows_count then table else
        missing_rows_count = all_rows_count - display_rows
        missing = '\n\u2026 and ' + missing_rows_count.to_text + ' hidden rows.'
        table + missing

## PRIVATE

   Transforms `preferred_names` names in such a way to not collide with
   `used_names`.

   Arguments:
   - used_names: The names that have already been used.
   - preferred_names: The names that the user wants to use.

   If a name from `preferred_names` does not collide with others, it is kept as
   is, otherwise numerical suffixes are added.
fresh_names : Vector Text -> Vector Text -> Vector Text
fresh_names used_names preferred_names =
   freshen currently_used name ix =
       new_name = if ix == 0 then name else name+"_"+ix.to_text
       case currently_used.contains new_name of
           False -> new_name
           True -> freshen currently_used name ix+1
   res = preferred_names . fold [used_names, []] acc-> name->
       used = acc.first
       new_name = freshen used name 0
       [used_names + [new_name], acc.second + [new_name]]
   res.second

## PRIVATE

   Ensures that the provided columns do not clash with the vector of names
   provided as first argument.

   Arguments:
   - used_names: The already used names.
   - columns: The columns to rename to avoid clashes.

   Original column names are kept if possible, but if they would clash, the
   columns are renamed.
freshen_columns : Vector Text -> Vector Internal_Column -> Vector Internal_Column
freshen_columns used_names columns =
    new_names = fresh_names used_names (columns.map .name)
    Helpers.rename_internal_columns columns new_names
