from Standard.Base import all
import Standard.Base.Data.Array_Proxy.Array_Proxy
import Standard.Base.Data.Filter_Condition as Filter_Condition_Module
import Standard.Base.Data.Time.Errors.Date_Time_Format_Parse_Error
import Standard.Base.Data.Vector.Builder
import Standard.Base.Errors.Common.Additional_Warnings
import Standard.Base.Errors.Common.Incomparable_Values
import Standard.Base.Errors.Common.Index_Out_Of_Bounds
import Standard.Base.Errors.Common.Type_Error
import Standard.Base.Errors.Deprecated.Deprecated
import Standard.Base.Errors.File_Error.File_Error
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument
import Standard.Base.Errors.Illegal_State.Illegal_State
import Standard.Base.Errors.Unimplemented.Unimplemented
import Standard.Base.System.File.Generic.Writable_File.Writable_File
from Standard.Base.Metadata import Display, make_single_choice, Widget
from Standard.Base.Runtime import assert
from Standard.Base.Widget_Helpers import make_any_selector, make_data_cleanse_vector_selector, make_delimiter_selector, make_format_chooser

import Standard.Table.Column_Operation.Column_Operation
import Standard.Table.Columns_To_Add.Columns_To_Add
import Standard.Table.Columns_To_Keep.Columns_To_Keep
import Standard.Table.Expression.Expression
import Standard.Table.Expression.Expression_Error
import Standard.Table.Internal.Add_Row_Number
import Standard.Table.Internal.Column_Naming_Helper.Column_Naming_Helper
import Standard.Table.Internal.Constant_Column.Constant_Column
import Standard.Table.Internal.Display_Helpers
import Standard.Table.Internal.Join_Kind_Cross.Join_Kind_Cross
import Standard.Table.Internal.Problem_Builder.Problem_Builder
import Standard.Table.Internal.Replace_Helpers
import Standard.Table.Internal.Table_Helpers
import Standard.Table.Internal.Table_Helpers.Table_Column_Helper
import Standard.Table.Internal.Table_Helpers.Union_Result_Type
import Standard.Table.Internal.Table_Ref.Table_Ref
import Standard.Table.Internal.Unique_Name_Strategy.Unique_Name_Strategy
import Standard.Table.Internal.Value_Type_Helpers
import Standard.Table.Internal.Widget_Helpers
import Standard.Table.Match_Columns as Match_Columns_Helpers
import Standard.Table.Row.Row
import Standard.Table.Rows_To_Read.Rows_To_Read
import Standard.Table.Value_Type.By_Type
from Standard.Table import Aggregate_Column, Auto, Blank_Selector, Column_Ref, Data_Formatter, Join_Condition, Join_Kind, Match_Columns, Position, Previous_Value, Report_Unmatched, Set_Mode, Simple_Expression, Sort_Column, Table, Value_Type
from Standard.Table.Errors import all
from Standard.Table.Internal.Filter_Condition_Helpers import make_filter_column
from Standard.Table.Table import make_fill_nothing_default_widget

import project.Connection.Connection.Connection
import project.DB_Column.DB_Column
import project.Feature.Feature
import project.Internal.Aggregate_Helper
import project.Internal.Base_Generator
import project.Internal.Common.Database_Join_Helper
import project.Internal.Common.Lookup_Query_Helper
import project.Internal.Common.Row_Number_Helpers
import project.Internal.DB_Data_Link_Helpers
import project.Internal.Helpers
import project.Internal.IR.Context.Context
import project.Internal.IR.From_Spec.From_Spec
import project.Internal.IR.Internal_Column.Internal_Column
import project.Internal.IR.Order_Descriptor.Order_Descriptor
import project.Internal.IR.Query.Query
import project.Internal.IR.SQL_Expression.SQL_Expression
import project.Internal.IR.SQL_Join_Kind.SQL_Join_Kind
import project.Internal.SQL_Type_Reference.SQL_Type_Reference
import project.SQL_Query.SQL_Query
import project.SQL_Statement.SQL_Statement
import project.SQL_Type.SQL_Type
import project.Take_Drop_Helpers
from project.Errors import Integrity_Error, SQL_Error, Table_Not_Found, Unsupported_Database_Operation
from project.Take_Drop_Helpers import Take_Drop

polyglot java import java.sql.JDBCType
polyglot java import java.util.UUID

## Represents a column-oriented table data structure backed by a database.
type DB_Table
    ## PRIVATE

       Represents a column-oriented table data structure backed by a database.

       Arguments:
       - internal_name: The name of the table.
       - connection: The connection with which the table is associated.
       - internal_columns: The internal representation of the table columns.
       - context: The context associated with this table.
    private Value internal_name:Text connection:(Connection | Any) (internal_columns:(Vector Internal_Column)) context:Context

    ## GROUP Standard.Base.Metadata
       ICON metadata
       The name of the table.
    name : Text
    name self = self.internal_name

    ## ICON metadata
       The name of the SQL Dialect used by the table.
    dialect_name : Text
    dialect_name self = self.connection.dialect.name

    ## PRIVATE
       ADVANCED
       Returns a text containing an ASCII-art table displaying this data.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
         - format_terminal: whether ANSI-terminal formatting should be used
    display : Integer -> Boolean -> Text
    display self show_rows:Integer=10 format_terminal:Boolean=False =
        data_fragment_with_warning = self.read (..First_With_Warning show_rows)
        has_more_rows = data_fragment_with_warning.has_warnings warning_type=Not_All_Rows_Downloaded
        data_fragment_cleared = data_fragment_with_warning.remove_warnings Not_All_Rows_Downloaded
        # `row_count` means another Database query is performed, so we only do it if we need to.
        all_rows_count = if has_more_rows then self.row_count else data_fragment_cleared.row_count
        Display_Helpers.display_table table=data_fragment_cleared add_row_index=False max_rows_to_show=show_rows all_rows_count=all_rows_count format_terminal=format_terminal

    ## PRIVATE
       ADVANCED
       Prints an ASCII-art table with this data to the standard output.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
    print : Integer -> Nothing
    print self show_rows=10 =
        IO.println (self.display show_rows format_terminal=True)
        IO.println ''

    ## PRIVATE
       Converts this column to JS_Object representation.
    to_js_object : JS_Object
    to_js_object self = case self.internal_columns.is_empty of
        True -> JS_Object.from_pairs [["query", Nothing], ["message", "The table has no columns so a query cannot be generated."]]
        False -> self.to_sql.to_js_object

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns the column with the given name.

       Arguments:
       - selector: The name or index of the column to get.
    @selector Widget_Helpers.make_column_name_selector
    at : Integer | Text -> DB_Column ! No_Such_Column | Index_Out_Of_Bounds
    at self (selector:(Integer | Text)=0) = 
        case selector of
            _ : Integer -> self.make_column (self.internal_columns.at selector)
            _ -> self.get selector (Error.throw (No_Such_Column.Error selector))

    ## ICON select_column
       Returns the column with the given name or index.

       Arguments:
       - selector: The name or index of the column being looked up.
       - if_missing: The value to use if the selector isn't present.
    @selector Widget_Helpers.make_column_name_selector
    get : Integer | Text -> Any -> DB_Column | Any
    get self (selector:(Integer | Text)=0) ~if_missing=Nothing =
        internal_column = case selector of
            _ : Integer -> self.internal_columns.get selector if_missing=Nothing
            _ : Text -> self.internal_columns.find (p -> p.name == selector) if_missing=Nothing
        if internal_column.is_nothing then if_missing else self.make_column internal_column

    ## ALIAS cell value, get cell
       GROUP Standard.Base.Selections
       ICON local_scope4
       Gets a value from the table.

       Arguments:
       - selector: The name or index of the column.
       - index: The index of the value to get within the column.
       - if_missing: The value to use if the selector isn't present.
    @selector Widget_Helpers.make_column_name_selector
    @if_missing (make_any_selector add_text=True add_regex=True add_number=True add_boolean=True add_named_pattern=True add_date=True add_time=True add_date_time=True add_nothing=True)
    get_value : Text | Integer -> Integer -> Any -> Any
    get_value self selector:(Text | Integer)=0 index:Integer=0 ~if_missing=Nothing =
        Feature.Column_Operations.if_supported_else_throw self.connection.dialect "get_value" <|
            col = self.get selector if_missing=Nothing
            if Nothing == col then if_missing else col.get index if_missing

    ## ALIAS row
       GROUP Standard.Base.Selections
       ICON select_row
       Gets a row from the table.
       This is a live read from the database, so the results may change on
       re-evaluation.

       Arguments:
       - index: The index of the row to get within the table.
       - if_missing: The value to use if the selector isn't present.
    get_row : Integer -> Any -> Any
    get_row self index:Integer=0 ~if_missing=Nothing =
        Feature.Sample.if_supported_else_throw self.connection.dialect "get_row" <|
            if index == -1 then self.last_row else
                real_row = (if index < 0 then index + self.row_count else index)
                if real_row < 0 then if_missing else
                    self.rows real_row+1 . get real_row if_missing

    ## ALIAS first cell
       GROUP Standard.Base.Selections
       ICON local_scope4
       Gets the top left value from the table.
    first_value : Any ! Index_Out_Of_Bounds
    first_value self =
        Feature.Column_Operations.if_supported_else_throw self.connection.dialect "first_value" <|
            self.at 0 . at 0

    ## ALIAS last cell
       GROUP Standard.Base.Selections
       ICON local_scope4
       Gets the bottom right value from the table.
    last_value : Any ! Index_Out_Of_Bounds
    last_value self =
        Feature.Column_Operations.if_supported_else_throw self.connection.dialect "last_value" <|
            self.last_row . at -1

    ## ALIAS first field
       GROUP Standard.Base.Selections
       ICON select_column
       Gets the first column.
    first_column : DB_Column ! Index_Out_Of_Bounds
    first_column self = 
        Feature.Column_Operations.if_supported_else_throw self.connection.dialect "first_column" <|
            self.at 0

    ## ALIAS last field
       GROUP Standard.Base.Selections
       ICON select_column
       Gets the last column
    last_column : DB_Column ! Index_Out_Of_Bounds
    last_column self = 
        Feature.Column_Operations.if_supported_else_throw self.connection.dialect "last_column" <|
            self.at -1

    ## ALIAS field count
       GROUP Standard.Base.Metadata
       ICON metadata
       Returns the number of columns in the table.
    column_count : Integer
    column_count self = self.internal_columns.length

    ## ALIAS select fields
       GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with a chosen subset of columns, as specified by the
       `columns`, from the input table. Any unmatched input columns will be
       dropped from the output.

       Arguments:
       - columns: Specifies columns by a single instance or Vector of names;
         indexes or regular expressions to match names; or a `By_Type` selector
         to choose columns by type. Note: specifying columns by type ignores
         size and precision.
       - reorder: By default, or if set to `False`, columns in the output will
         be in the same order as in the input table. If `True`, the order in the
         output table will match the order in the columns list. If a column is
         matched by multiple selectors in reorder mode, it will be placed at
         the position of the first one matched.
       - case_sensitivity: Controls whether to be case sensitive when matching
         column names.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
       > Example
         Select columns by name.

             table.select_columns ["bar", "foo"]

       > Example
         Select columns using names passed as a Vector.

             table.select_columns ["bar", "foo"]

       > Example
         Select columns matching a regular expression.

             table.select_columns "foo.+".to_regex case_sensitivity=Case_Sensitivity.Insensitive

       > Example
         Select the first two columns and the last column, moving the last one to front.

             table.select_columns [-1, 0, 1] reorder=True

       > Example
         Select integer columns.

             table.select_columns [..By_Type ..Integer]
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    select_columns :  Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type -> Boolean -> Case_Sensitivity -> Boolean -> Problem_Behavior -> DB_Table ! No_Output_Columns | Missing_Input_Columns
    select_columns self (columns : (Vector | Text | Integer | Regex | By_Type) = [self.columns.first.name]) (reorder:Boolean=False) (case_sensitivity:Case_Sensitivity=..Default) (error_on_missing_columns:Boolean=True) (on_problems:Problem_Behavior=..Report_Warning) =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "select_columns" <|
            new_columns = self.columns_helper.select_columns columns case_sensitivity reorder error_on_missing_columns on_problems
            self.updated_columns (new_columns.map _.as_internal)

    ## PRIVATE
       ALIAS select fields by type
       GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the chosen set of columns filtered by the type
       of the column.

       Arguments:
       - types: The types of columns to select.
       - strict: If `True`, only columns with exactly the specified types will
         be selected. If `False`, columns with related types will also be
         selected (i.e. ignore size, precision).
    @types Widget_Helpers.make_value_type_vector_selector
    select_columns_by_type : Vector Value_Type -> Boolean -> Table
    select_columns_by_type self types:Vector strict:Boolean=False =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "select_columns_by_type" <|
            new_columns = self.columns_helper.select_by_type types strict
            result = self.updated_columns (new_columns.map _.as_internal)
            Warning.attach (Deprecated.Warning "Standard.Database.DB_Table.DB_Table" "select_columns_by_type" "Deprecated: use `select_columns` with a `By_Type` instead.") result

    ## ALIAS drop fields, drop_columns, remove fields, select columns, select fields
       GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the chosen set of columns, as specified by the
       `columns`, removed from the input table. Any unmatched input columns will
       be kept in the output. Columns are returned in the same order as in the
       input.

       Arguments:
       - columns: Specifies columns by a single instance or Vector of names;
         indexes or regular expressions to match names; or a `By_Type` selector
         to choose columns by type. Note: specifying columns by type ignores
         size and precision.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `False`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is reported according to the `on_problems`
           setting, unless `error_on_missing_columns` is set to `True`, in which
           case it is raised as an error.

       > Example
         Remove columns with given names.

             table.remove_columns ["bar", "foo"]

       > Example
         Remove columns using names passed as a Vector.

             table.remove_columns ["bar", "foo"]

       > Example
         Remove columns matching a regular expression.

             table.remove_columns "foo.+".to_regex Case_Sensitivity.Insensitive

       > Example
         Remove the first two columns and the last column.

             table.remove_columns [-1, 0, 1]

       > Example
         Remove integer columns.

             table.remove_columns [..By_Type ..Integer]
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    remove_columns :  Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type -> Case_Sensitivity -> Boolean -> Problem_Behavior -> DB_Table ! No_Output_Columns | Missing_Input_Columns
    remove_columns self (columns : (Vector | Text | Integer | Regex | By_Type) = [self.columns.first.name]) (case_sensitivity:Case_Sensitivity=..Default) (error_on_missing_columns:Boolean=False) (on_problems:Problem_Behavior=..Report_Warning) =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "remove_columns" <|
            new_columns = self.columns_helper.remove_columns columns case_sensitivity error_on_missing_columns=error_on_missing_columns on_problems=on_problems
            self.updated_columns (new_columns.map _.as_internal)

    ## PRIVATE
       ALIAS remove fields by type, select columns by type, select fields by type
       GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the chosen set of columns filtering out based
       on the type of the column.

       Arguments:
       - types: The types of columns to remove.
       - strict: If `True`, only columns with exactly the specified types will
         be removed. If `False`, columns with related types will also be
         removed (i.e. ignore size, precision).
    @types Widget_Helpers.make_value_type_vector_selector
    remove_columns_by_type : Vector Value_Type -> Boolean -> Table
    remove_columns_by_type self types:Vector strict:Boolean=False =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "remove_columns_by_type" <|
            new_columns = self.columns_helper.remove_by_type types strict
            result = self.updated_columns (new_columns.map _.as_internal)
            Warning.attach (Deprecated.Warning "Standard.Database.DB_Table.DB_Table" "remove_columns_by_type" "Deprecated: use `remove_columns` with a `By_Type` instead.") result

    ## ALIAS select_blank_fields, select_missing_columns, select_na
       GROUP Standard.Base.Selections
       ICON select_column

       Select columns which are either all blank or contain blank values. If no
       rows are present, all columns are considered blank.

       Arguments:
       - when: By default, only columns consisting of all blank cells are
         selected. If set to Blank_Selector.Any_Cell, columns with one or
         more blank values are selected.
       - treat_nans_as_blank: specified whether `Number.nan` is considered as
         blank. By default, it is not.

       ? Blank values
         Blank values are `Nothing`, `""` and depending on setting `Number.nan`.

       > Example
         Select completely blank columns from a table.

             table.select_blank_columns
    select_blank_columns : Blank_Selector -> Boolean -> DB_Table
    select_blank_columns self (when : Blank_Selector = ..All_Cells) treat_nans_as_blank:Boolean=False =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "select_blank_columns" <|
            new_columns = self.columns_helper.select_blank_columns_helper when treat_nans_as_blank
            self.updated_columns new_columns

    ## ALIAS drop_missing_columns, drop_na, select_blank_columns, select_blank_fields, select_missing_columns, select_na
       GROUP Standard.Base.Selections
       ICON select_column

       Remove columns which are either all blank or contain blank values. If no
       rows are present, all columns are considered blank.

       Arguments:
       - when: By default, only columns consisting of all blank cells are
         selected. If set to Blank_Selector.Any_Cell, columns with one or
         more blank values are selected.
       - treat_nans_as_blank: specified whether `Number.nan` is considered as
         blank. By default, it is not.

       ? Blank values
         Blank values are `Nothing`, `""` and depending on setting `Number.nan`.

       > Example
         Remove completely blank columns from a table.

             table.remove_blank_columns
    remove_blank_columns : Blank_Selector -> Boolean -> DB_Table
    remove_blank_columns self (when : Blank_Selector = ..All_Cells) treat_nans_as_blank:Boolean=False =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "remove_blank_columns" <|
            new_columns = self.columns_helper.select_blank_columns_helper when treat_nans_as_blank invert_selection=True
            self.updated_columns new_columns

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the specified selection of columns moved to
       either the start or the end in the specified order.

       Arguments:
       - columns: Specifies columns by a name, type, index or regular expression to
         match names, or a Vector of these.
       - position: Specifies how to place the selected columns in relation to
         the remaining columns which were not matched by `columns` (if any).
       - case_sensitivity: Controls whether to be case sensitive when matching
         column names.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `False`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is reported according to the `on_problems`
           setting, unless `error_on_missing_columns` is set to `True`, in which
           case it is raised as an error.

       > Example
         Move a column with a specified name to back.

             table.reorder_columns ["foo"] position=Position.After_Other_Columns

       > Example
         Move columns using names passed as a Vector.

             table.reorder_columns ["bar", "foo"] position=Position.After_Other_Columns

       > Example
         Move columns matching a regular expression to front, keeping columns matching "foo.+" before columns matching "b.*".

             table.reorder_columns "foo.+".to_regex case_sensitivity=Case_Sensitivity.Insensitive

       > Example
         Swap the first two columns.

             table.reorder_columns [1, 0]

       > Example
         Move the first column to back.

             table.reorder_columns [0] position=Position.After_Other_Columns
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    reorder_columns : Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type -> Position -> Case_Sensitivity -> Boolean -> Problem_Behavior -> DB_Table ! Missing_Input_Columns
    reorder_columns self (columns : (Vector | Text | Integer | Regex | By_Type) = [self.columns.first.name]) (position:Position=..Before_Other_Columns) (case_sensitivity:Case_Sensitivity=..Default) (error_on_missing_columns:Boolean=False) (on_problems:Problem_Behavior=..Report_Warning) =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "reorder_columns" <|
            new_columns = self.columns_helper.reorder_columns columns position case_sensitivity error_on_missing_columns on_problems
            self.updated_columns (new_columns.map _.as_internal)

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the columns sorted by name according to the
       specified sort method. By default, sorting will be according to
       case-sensitive ascending order based on the normalized Unicode ordering.

       Arguments:
       - order: Whether sorting should be in ascending or descending order.
       - text_ordering: The sort methodology to use.

       > Example
         Sort columns according to the default ordering.

             table.sort_columns

       > Example
         Sort columns according to the natural case-insensitive ordering.

             table.sort_columns text_ordering=(Text_Ordering.Case_Insensitive sort_digits_as_numbers=True)

       > Example
         Sort columns in descending order.

             table.reorder_columns Sort_Direction.Descending
    sort_columns : Sort_Direction -> Text_Ordering -> DB_Table
    sort_columns self order:Sort_Direction=..Ascending text_ordering:Text_Ordering=..Default =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "sort_columns" <|
            new_columns = Table_Helpers.sort_columns internal_columns=self.internal_columns order text_ordering
            self.updated_columns new_columns

    ## GROUP Standard.Base.Metadata
       ICON table_edit
       Returns a new table with the columns renamed based on either a mapping
       from the old name to the new or a positional list of new names.

       Arguments:
       - column_map: Mapping from old column names to new or a vector of new
         column names to apply by position. `Regex` objects can be used
         within the mapping to do pattern based renaming.
         Can also be supplied as a `Table` either with a single column of new
         names or two columns with old (first column) and new names (second
         column).
       - case_sensitivity: Controls whether to be case sensitive when matching
         column names.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If any of the new names are invalid, an `Invalid_Column_Names`
           error is raised.
         - Other problems are reported according to the `on_problems` setting:
             - If a column is matched by two selectors resulting in a different
               name mapping, a `Ambiguous_Column_Rename`.
             - If in `By_Position` mode and more names than columns are
               provided, a `Too_Many_Column_Names_Provided`.
             - If any of the new names clash either with existing names or each
               other, a `Duplicate_Output_Column_Names`.

       > Example
         Rename the "Alpha" column to "Beta"

              table.rename_columns (Dictionary.from_vector [["Alpha", "Beta"]])

       > Example
         Rename the last column to "LastColumn"

              table.rename_columns (Dictionary.from_vector [[-1, "LastColumn"]])

       > Example
         Rename the "Alpha" column to "Beta" and last column to "LastColumn"

              table.rename_columns (Dictionary.from_vector [["Alpha", "Beta"], [-1, "LastColumn"]])

       > Example
         Rename the first column to "FirstColumn"

              table.rename_columns ["FirstColumn"]

       > Example
         Add a prefix to all column names.

              table.rename_columns (table.columns.map c-> "prefix_" + c.name)

       > Example
         For all columns starting with the prefix `name=`, replace it with `key:`.

              table.rename_columns (Dictionary.from_vector [["name=(.*)".to_regex, "key:$1"]])
    @column_map Widget_Helpers.make_rename_name_vector_selector
    rename_columns : Table | Dictionary (Text | Integer | Regex) Text | Vector Text | Vector Vector -> Case_Sensitivity -> Boolean -> Problem_Behavior -> DB_Table ! Missing_Input_Columns | Ambiguous_Column_Rename | Too_Many_Column_Names_Provided | Invalid_Column_Names | Duplicate_Output_Column_Names
    rename_columns self (column_map:(Table | Dictionary | Vector)=["Column"]) (case_sensitivity:Case_Sensitivity=..Default) (error_on_missing_columns:Boolean=True) (on_problems:Problem_Behavior=..Report_Warning) =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "rename_columns" <|
            case column_map of
                _ : Table ->
                    resolved = Table_Helpers.read_name_mapping_from_table column_map
                    self.rename_columns resolved case_sensitivity error_on_missing_columns on_problems
                _ ->
                    new_names = Table_Helpers.rename_columns self.column_naming_helper self.internal_columns column_map case_sensitivity error_on_missing_columns on_problems
                    Warning.with_suspended new_names names->
                        self.updated_columns (self.internal_columns.map c-> c.rename (names.at c.name))

    ## ALIAS rename, header
       GROUP Standard.Base.Metadata
       ICON table_edit
       Returns a new table with the columns renamed based on entries in the
       first row.

       Arguments:
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         The following problems can occur:
         - If any of the new names are invalid, an
           `Invalid_Column_Names`.
         - If any of the new names clash either with existing names or each
           other, a Duplicate_Output_Column_Names.

       > Example
         Rename the column based on the first row

              table.use_first_row_as_names
    use_first_row_as_names : Problem_Behavior -> DB_Table
    use_first_row_as_names self (on_problems:Problem_Behavior=..Report_Warning) =
        _ = on_problems
        Error.throw (Unsupported_Database_Operation.Error "use_first_row_as_names")

    ## PRIVATE

       Resolves the column name to a column within this table.

       Arguments:
       - column: The name (or column handle) for the column you want to resolve.

       If instead of a name, a column is provided, it is returned as-is as long
       as it comes from the same context.
    resolve : Text | DB_Column -> DB_Column
    resolve self column =
        Feature.Select_Columns.if_supported_else_throw self.connection.dialect "resolve" <|
            case column of
                _ : Text -> Panic.rethrow (self.at column)
                _ ->
                    if Helpers.check_integrity self column then column else
                        Panic.throw (Integrity_Error.Error "DB_Column "+column.name)

    ## ALIAS filter rows, where
       GROUP Standard.Base.Selections
       ICON preparation

       Selects only the rows of this table that correspond to `True` values of
       `filter`.

       Arguments:
       - column: The column to use for filtering. Can be a column name, index or
         the `Column` object itself.
       - filter: The filter to apply to the column. It can either be an instance
         of `Filter_Condition` or a predicate taking a cell value and returning
         a boolean value indicating whether the corresponding row should be kept
         or not.
       - on_problems: Specifies how to handle if a non-fatal problem occurs,
         attaching a warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If a column index is invalid, an `Index_Out_Of_Bounds` dataflow error
           is raised.
         - If the column is an invalid type for the filter, an
           `Invalid_Value_Type` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If filtering by equality on a floating-point column,
             a `Floating_Point_Equality`.

       > Example
         Get people older than 30.

             people.filter "Age" (Greater 30)

       > Example
         Filter people between 30 and 40.

             people.filter "Age" (Between 30 40)

       > Example
         Select rows where more than 50% of the stock is sold.

             table.filter "sold_stock" (Greater (table.at "total_stock" / 2))

       > Example
         Select people celebrating a jubilee.

             people.filter "age" (age -> (age%10 == 0))
    @column (Widget_Helpers.make_column_name_selector add_expression=True)
    @filter Widget_Helpers.make_filter_condition_selector
    filter : (DB_Column | Text | Integer) -> (Filter_Condition | (Any -> Boolean)) -> Problem_Behavior -> DB_Table ! No_Such_Column | Index_Out_Of_Bounds | Invalid_Value_Type
    filter self column (filter : Filter_Condition | (Any -> Boolean) = Filter_Condition.Equal True) on_problems:Problem_Behavior=..Report_Warning = 
        Feature.Filter.if_supported_else_throw self.connection.dialect "filter" <|
            case column of
                _ : DB_Column ->
                    mask filter_column = case Helpers.check_integrity self filter_column of
                        False ->
                            Error.throw (Integrity_Error.Error "DB_Column "+filter_column.name)
                        True ->
                            new_filters = self.context.where_filters + [filter_column.expression]
                            new_ctx = self.context.set_where_filters new_filters
                            self.updated_context new_ctx

                    filter_condition = Filter_Condition.resolve_auto_scoped filter
                    case filter_condition of
                        _ : Filter_Condition ->
                            resolved = (self:Table_Ref).resolve_condition filter_condition
                            mask (make_filter_column column resolved on_problems)
                        _ : Function ->
                            Error.throw (Unsupported_Database_Operation.Error "Filtering with a custom predicate")
                _ : Expression -> self.filter (self.evaluate_expression column on_problems) filter on_problems
                _ ->
                    table_at = self.at column
                    self.filter table_at filter on_problems

    ## PRIVATE
       ALIAS filter rows
       GROUP Standard.Base.Selections
       ICON preparation

       Selects only the rows of this table that correspond to `True` values of
       `filter`.

       Arguments:
       - expression: The expression to evaluate to filter the rows.
       - on_problems: Specifies how to handle non-fatal problems, attaching a
         warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - If the expression returns a column that does not have a boolean type,
           an `Invalid_Value_Type` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.

       > Example
         Select people celebrating a jubilee.

             people.filter_by_expression "[age] % 10 == 0"
    filter_by_expression : Text -> Problem_Behavior -> DB_Table ! No_Such_Column | Invalid_Value_Type | Expression_Error
    filter_by_expression self expression:Text on_problems:Problem_Behavior=..Report_Warning =
        Feature.Filter.if_supported_else_throw self.connection.dialect "filter_by_expression" <|
            column = self.evaluate_expression (Expression.Value expression) on_problems
            result = self.filter column Filter_Condition.Is_True
            Warning.attach (Deprecated.Warning "Standard.Database.DB_Table.DB_Table" "filter_by_expression" "Deprecated: use `filter` with an `Expression` instead.") result

    ## ALIAS first, head, keep, last, limit, sample, slice, tail, top
       GROUP Standard.Base.Selections
       ICON select_row
       Creates a new Table with the specified range of rows from the input
       Table.

       Arguments:
       - range: The selection of rows from the table to return.

       For the purposes of the `Index_Sub_Range.While` predicate a single
       "element" of the table is represented by the `Row` type.

       ? Supported Range Types

         Database backends support all range types except `While` and `Sample`

         In-memory tables support all range types.

       > Example
         Take first 10 rows of the table.

             table.take (..First 10)

       > Example
         Take rows from the top of the table as long as their values sum to 10.

             table.take (While row-> row.to_vector.compute Statistic.Sum == 10)
    @range Index_Sub_Range.default_widget
    take : (Index_Sub_Range | Range | Integer) -> DB_Table
    take self range:(Index_Sub_Range | Range | Integer)=..First =
        Feature.Sample.if_supported_else_throw self.connection.dialect "take" <|
            Take_Drop_Helpers.take_drop_helper Take_Drop.Take self range

    ## ALIAS remove, skip
       GROUP Standard.Base.Selections
       ICON select_row
       Creates a new Table from the input with the specified range of rows
       removed.

       Arguments:
       - range: The selection of rows from the table to remove.

       For the purposes of the `Index_Sub_Range.While` predicate a single
       "element" of the table is represented by the `Row` type.

       ? Supported Range Types

         Database backends support all range types except `While` and `Sample`

         In-memory tables support all range types.

       > Example
         Drop first 10 rows of the table.

             table.drop (..First 10)

       > Example
         Drop rows from the top of the table as long as their values sum to 10.

             table.drop (While row-> row.to_vector.compute Statistic.Sum == 10)
    @range Index_Sub_Range.default_widget
    drop : (Index_Sub_Range | Range | Integer) -> DB_Table
    drop self range:(Index_Sub_Range | Range | Integer)=..First =
        Feature.Sample.if_supported_else_throw self.connection.dialect "drop" <|
            Take_Drop_Helpers.take_drop_helper Take_Drop.Drop self range

    ## PRIVATE
       Filter out all rows.
    remove_all_rows : DB_Table
    remove_all_rows self =
        Feature.Filter.if_supported_else_throw self.connection.dialect "remove_all_rows" <|
            self.filter (Expression.Value "0==1")

    ## ALIAS add index column, rank, record id
       GROUP Standard.Base.Values
       ICON column_add
       Adds a new column to the table enumerating the rows.

       Arguments:
       - name: The name of the new column. Defaults to "Row".
       - from: The starting value for the enumeration. Defaults to 0.
       - step: The amount to increment the enumeration by. Defaults to 1.
       - group_by: Specifies the columns to group by. The row numbers are
         counted separately for each group. By default, all rows are treated as
         a single group.
       - order_by: Specifies the columns to order by. Defaults to the order of
         the rows in the table. The row numbers are assigned according to the
         specified ordering.

       ? Ordering of rows

         Note that the ordering of rows from the original table is preserved in
         all cases. The grouping and ordering settings affect how the row
         numbers are assigned to each row, but the order of the rows itself is
         not changed by this operation.

       ! Error Conditions

         - If the columns specified in `group_by` or `order_by` are not present
           in the table, a `Missing_Input_Columns` error is raised.
         - If the column with the same name as provided `name` already exists,
           a `Duplicate_Output_Column_Names` problem is reported and the
           existing column is renamed to avoid the clash.
         - If grouping on floating point numbers, a `Floating_Point_Equality`
           problem is reported.
    @name (Widget.Text_Input display=..Always)
    @from (Widget.Numeric_Input display=..Always)
    @group_by (Widget_Helpers.make_column_name_multi_selector display=..When_Modified)
    @order_by (Widget_Helpers.make_order_by_selector display=..When_Modified)
    add_row_number : Text -> Integer -> Integer -> Vector (Text | Integer | Regex) | Text | Integer | Regex -> Vector (Text | Sort_Column) | Text -> Problem_Behavior -> DB_Table
    add_row_number self (name:Text="Row") (from:Integer=0) (step:Integer=1) (group_by:(Vector | Text | Integer | Regex)=[]) (order_by:(Vector | Text)=[]) (on_problems:Problem_Behavior=..Report_Warning) =
        Feature.Add_Row_Number.if_supported_else_throw self.connection.dialect "add_row_number" <|
            problem_builder = Problem_Builder.new error_on_missing_columns=True
            grouping_columns = self.columns_helper.select_columns_helper group_by Case_Sensitivity.Default True problem_builder
            grouping_columns.each column->
                if column.value_type.is_floating_point then
                    problem_builder.report_other_warning (Floating_Point_Equality.Error column.name)
            ordering = Table_Helpers.resolve_order_by self.columns order_by problem_builder
            problem_builder.attach_problems_before on_problems <|
                order_descriptors = case ordering.is_empty of
                    False -> ordering.map element->
                        column = element.column
                        associated_selector = element.associated_selector
                        self.connection.dialect.prepare_order_descriptor column associated_selector.direction text_ordering=Nothing
                    True -> case self.default_ordering of
                        Nothing -> Error.throw (Illegal_Argument.Error "No `order_by` is specified and the table has no existing ordering (e.g. from an `order_by` operation or a primary key). Some ordering is required for `add_row_number` in Database tables.")
                        descriptors -> descriptors
                grouping_expressions = (grouping_columns.map _.as_internal).map .expression

                new_expr = Row_Number_Helpers.make_row_number from step order_descriptors grouping_expressions

                type_mapping = self.connection.dialect.get_type_mapping
                infer_from_database_callback expression =
                    SQL_Type_Reference.new self.connection self.context expression
                new_type_ref = type_mapping.infer_return_type infer_from_database_callback "ROW_NUMBER" [] new_expr

                new_column = Internal_Column.Value name new_type_ref new_expr

                rebuild_table columns =
                    self.updated_columns (columns.map .as_internal)
                renamed_table = Add_Row_Number.rename_columns_if_needed self name on_problems rebuild_table
                updated_table = renamed_table.updated_columns (renamed_table.internal_columns + [new_column])
                updated_table.as_subquery


    ## ALIAS order_by
       GROUP Standard.Base.Selections
       ICON select_row

       Returns a new Table that will include at most `max_rows` rows from the
       original Table.

       Arguments:
       - max_rows: The maximum number of rows to get from the table.

       Since this Table is backed by an SQL database, the Table returned by the
       `limit` method is deterministic only if the Table has been ordered (using
       the `order_by` method).

       Otherwise, no order is imposed, so the returned Table will include at most
       `max_rows` rows, but there are no guarantees on which rows will be
       selected. Moreover, even if the underlying table in the database did not
       change, different sets of rows may be returned each time the returned
       Table is materialized.

       The limit is applied at the very end, so the new Table behaves exactly as
       the old one, just limiting its results when being materialized.
       Specifically, applying further filters will still apply to the whole
       result set and the limit will be taken after applying these filters.

       > Example
         In the call below, assuming that the table of `t1` contains rows for
         numbers 1, 2, ..., 10, will return rows starting from 6 and not an empty
         result as one could expect if the limit was applied before the filters.

             t1 = table.sort [..Name "A"] . limit 5
             t2 = t1.filter 'A' (..Greater than=5)
             t2.read
    limit : Integer -> DB_Table
    limit self max_rows:Integer=1000 =
        new_ctx = self.context.set_limit max_rows
        self.updated_context new_ctx

    ## ALIAS add column, expression, formula, new column, update column
       GROUP Standard.Base.Values
       ICON column_add
       Sets the column value at the given name.

       Arguments:
       - value: The value, expression or column to create column.
       - as: Optional new name for the column.
       - set_mode: Specifies the expected behaviour in regards to existing
         column with the same name.
       - on_problems: Specifies how to handle problems with expression
         evaluation.

       ! Error Conditions

         - If the column name is already present and `set_mode` is `Add`, a
           `Existing_Column` dataflow error is raised.
         - If the column name is not present and `set_mode` is `Update`, a
           `Missing_Column` dataflow error is raised.
         - If a column name referenced from within an expression cannot be
           found, a `No_Such_Column` dataflow error is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - The following problems with expression evaluation may be reported
           according to the `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.

       > Example
         Create a table where the values of the total stock in the inventory is
         doubled.

             import Standard.Examples

             example_set =
                 table = Examples.inventory_table
                 double_inventory = table.at "total_stock" * 2
                 table.set double_inventory as="total_stock"
                 table.set (expr "2 * [total_stock]") as="total_stock_expr"
    @value Simple_Expression.default_widget
    set : DB_Column | Text | Expression | Array | Vector | Range | Date_Range | Constant_Column | Simple_Expression -> Text -> Set_Mode -> Problem_Behavior -> DB_Table ! Existing_Column | Missing_Column | No_Such_Column | Expression_Error
    set self value:(DB_Column | Text | Expression | Array | Vector | Range | Date_Range | Constant_Column | Simple_Expression) (as : Text = "") (set_mode : Set_Mode = ..Add_Or_Update) (on_problems : Problem_Behavior = ..Report_Warning) =
        problem_builder = Problem_Builder.new
        unique = self.column_naming_helper.create_unique_name_strategy
        unique.mark_used self.column_names

        resolved = case value of
            _ : Text -> self.make_constant_column value
            _ : Expression -> self.evaluate_expression value on_problems
            _ : DB_Column ->
                if Helpers.check_integrity self value then value else
                    Error.throw (Integrity_Error.Error "Column "+value.name)
            _ : Constant_Column -> self.make_constant_column value
            _ : Simple_Expression -> value.evaluate self (set_mode==Set_Mode.Update && as=="") on_problems
            _ : Vector -> Error.throw (Unsupported_Database_Operation "`Vector` for `set`")
            _ : Array -> Error.throw (Unsupported_Database_Operation.Error "`Array` for `set`")
            _ : Range -> Error.throw (Unsupported_Database_Operation.Error "`Range` for `set`")
            _ : Date_Range -> Error.throw (Unsupported_Database_Operation.Error "`Date_Range` for `set`")
            _ -> Error.throw (Illegal_Argument.Error "Unsupported type for `DB_Table.set`.")

        ## If `as` was specified, use that. Otherwise, if `value` is a
          `DB_Column`, use its name. In these two cases, do not make it unique.
          Otherwise, make it unique. If set_mode is Update, however, do not
          make it unique.
        new_column_name = if as != "" then as else
            if value.is_a DB_Column || set_mode==Set_Mode.Update || set_mode==Set_Mode.Add_Or_Update then resolved.name else unique.make_unique resolved.name
        renamed = resolved.rename new_column_name
        renamed.if_not_error <| self.column_naming_helper.check_ambiguity self.column_names renamed.name <|
            index = self.internal_columns.index_of (c -> c.name == renamed.name)
            check_add = case set_mode of
                Set_Mode.Add_Or_Update -> True
                Set_Mode.Add -> if index.is_nothing then True else Error.throw (Existing_Column.Error renamed.name)
                Set_Mode.Update -> if index.is_nothing then Error.throw (Missing_Column.Error renamed.name) else True
            new_table = check_add.if_not_error <|
                new_col = renamed.as_internal
                new_cols = if index.is_nothing then self.internal_columns + [new_col] else
                    Vector.new self.column_count i-> if i == index then new_col else self.internal_columns.at i
                self.updated_columns new_cols

            problem_builder.report_unique_name_strategy unique
            problem_builder.attach_problems_after on_problems new_table

    ## PRIVATE
       Given an expression, create a derived column where each value is the
       result of evaluating the expression for the row.

       Arguments:
       - expression: The expression to evaluate.
       - on_problems: Specifies how to handle non-fatal problems, attaching a
         warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.
    evaluate_expression : Text | Expression -> Problem_Behavior -> DB_Column ! No_Such_Column | Invalid_Value_Type | Expression_Error
    evaluate_expression self expression:(Text | Expression) on_problems:Problem_Behavior=..Report_Warning =
        if expression.is_a Text then self.evaluate_expression (Expression.Value expression) on_problems else
            get_column name = self.at name
            make_constant_column value = case value of
                _ : DB_Column -> value
                _ -> self.make_constant_column value
            new_column = Expression.evaluate expression get_column make_constant_column "Standard.Database.DB_Column" "DB_Column" DB_Column.var_args_functions
            problems = Warning.get_all new_column . map .value
            result = new_column.rename (self.connection.base_connection.column_naming_helper.sanitize_name expression.expression)
            on_problems.attach_problems_before problems <|
                Warning.set result []

    ## PRIVATE
       A helper that creates a two-column table from a Dictionary.

       The keys of the `Dictionary` become the first column, with name
       `key_column_name`, and the values become the second column, with name
       `value_column_name`.

       For the in-memory database, the `Dictionary` can be empty. For the
       database backends, it must not be empty.

       Arguments:
       - dict: The `Dictionary` to create the table from.
       - key_column_name: The name to use for the first column.
       - value_column_name: The name to use for the second column.
    make_table_from_dictionary : Dictionary Any Any -> Text -> Text -> Table
    make_table_from_dictionary self dict key_column_name value_column_name =
        Feature.Make_Table_From.if_supported_else_throw self.connection.dialect "make_table_from_dictionary" <|
            total_size = dict.size * 2

            if dict.is_empty then Error.throw (Illegal_Argument.Error "Dictionary cannot be empty") else
                if total_size > MAX_LITERAL_ELEMENT_COUNT then Error.throw (Illegal_Argument.Error "Dictionary is too large ("+dict.size.to_text+" entries): materialize a table into the database instead") else
                    keys_and_values = dict.to_vector
                    self.make_table_from_vectors [keys_and_values.map .first, keys_and_values.map .second] [key_column_name, value_column_name]

    ## PRIVATE
       A helper that creates a literal table from `Vector`s.

       For the in-memory database, the columns can be empty. For the database
       backends, they must not be empty.

       Arguments:
       - column_vectors: A `Vector` of `Vector`s; each inner `Vector` becomes a
         column of the table.
       - column_names: The names of the columns of the new table.
    make_table_from_vectors : Vector (Vector Any) -> Vector Text -> DB_Table
    make_table_from_vectors self column_vectors column_names =
        Feature.Make_Table_From.if_supported_else_throw self.connection.dialect "make_table_from_vectors" <|
            literal_table_name = self.connection.base_connection.table_naming_helper.generate_random_table_name "enso-literal-"
            make_literal_table self.connection column_vectors column_names literal_table_name

    ## PRIVATE

       Create a constant column from a value.
    make_constant_column : Any -> DB_Column ! Illegal_Argument
    make_constant_column self value =
        Feature.Column_Operations.if_supported_else_throw self.connection.dialect "make_constant_column" <|
            if Table_Helpers.is_column value then Error.throw (Illegal_Argument.Error "A constant value may only be created from a scalar, not a DB_Column") else
                type_mapping = self.connection.dialect.get_type_mapping
                argument_value_type = Value_Type_Helpers.find_argument_type value
                sql_type = case argument_value_type of
                    Nothing -> SQL_Type.null
                    _ -> type_mapping.value_type_to_sql argument_value_type Problem_Behavior.Ignore
                expr = SQL_Expression.Constant value
                new_type_ref = SQL_Type_Reference.from_constant sql_type
                base_column = Internal_Column.Value value.pretty new_type_ref expr
                needs_cast = argument_value_type.is_nothing.not && self.connection.dialect.needs_literal_table_cast argument_value_type
                result_internal_column = if needs_cast.not then base_column else
                    infer_type_from_database new_expression =
                        SQL_Type_Reference.new self.connection self.context new_expression
                    self.connection.dialect.make_cast base_column sql_type infer_type_from_database
                self.make_column result_internal_column

    ## PRIVATE
       Create a unique temporary column name.
    make_temp_column_name : Text
    make_temp_column_name self = self.column_naming_helper.make_temp_column_name self.column_names

    ## PRIVATE
       Run a table transformer with a temporary column added.
    with_temporary_column :  DB_Column -> (Text -> DB_Table -> DB_Table) -> DB_Table
    with_temporary_column self new_column:DB_Column f:(Text -> DB_Table -> DB_Table) =
        new_column_name = self.make_temp_column_name
        with_new_column = self.set new_column new_column_name set_mode=Set_Mode.Add
        modified_table = f new_column_name with_new_column
        modified_table.remove_columns new_column_name

    ## PRIVATE
       Filter a table on a boolean column. The column does not have to be part
       of the table, but it must be derived from it and share a context.
    filter_on_predicate_column : DB_Column -> DB_Table
    filter_on_predicate_column self predicate_column =
        self.with_temporary_column predicate_column name-> table->
            table.filter name Filter_Condition.Is_True

    ## ICON convert
       Returns the vector of columns contained in this table.
    columns : Vector DB_Column
    columns self =
        Vector.from_polyglot_array <|
            Array_Proxy.new self.internal_columns.length i->
                self.make_column (self.internal_columns.at i)

    ## GROUP Standard.Base.Metadata
       ICON metadata
       Returns the vector of column names contained in this table.
    column_names : Vector Text
    column_names self = Vector.from_polyglot_array <|
        Array_Proxy.new self.internal_columns.length i->
            self.internal_columns.at i . name

    ## ICON select_row
       Returns a vector of rows contained in this table.

       In the database backend, it first materializes the table to in-memory.

       Arguments:
       - max_rows: specifies the maximum number of rows to read.
    @max_rows Rows_To_Read.default_widget
    rows : Rows_To_Read -> Vector Row
    rows self (max_rows : Rows_To_Read = (..First_With_Warning 1000)) =
        self.read max_rows . rows

    ## GROUP Standard.Base.Selections
       ICON select_row
       Returns the first row of the table.
    first_row : Row ! Index_Out_Of_Bounds
    first_row self =
        self.read (..First 1) . rows . first

    ## GROUP Standard.Base.Selections
       ICON select_row
       Returns the last row of the table.

       In the database backend, this function has to scan through all the
       results of the query.
    last_row : Row ! Index_Out_Of_Bounds
    last_row self =
        if self.internal_columns.is_empty then Error.throw (Illegal_Argument.Error "Cannot create a table with no columns.") else
            sql = self.to_sql
            column_types = self.internal_columns.map .sql_type_reference
            table = self.connection.read_statement sql column_types last_row_only=True
            table.rows.first

    ## ALIAS sort
       GROUP Standard.Base.Selections
       ICON order
       Sorts the rows of the table according to the specified columns and order.

       Arguments:
       - columns: The columns and order to sort the table.
       - text_ordering: The ordering method to use on text values.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If no columns have been selected for ordering,
           a `No_Input_Columns_Selected` is raised as dataflow error regardless
           of any settings.
         - If a column used for ordering contains values that cannot be
           compared, an `Incomparable_Values` error is raised.

       ? Missing Values

         Missing (`Nothing`) values are sorted as less than any other object.

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`.

             table.sort ['Quantity']

       > Example
         Sorting `table` in descending order by the value in column `'Quantity'`.

             table.sort [..Name 'Quantity' ..Descending]

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` for breaking ties.

             table.sort ['Quantity', 'Rating']

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` in descending order for breaking
         ties.

             table.sort [..Name 'Quantity', ..Name 'Rating' ..Descending]

       > Example
         Order the table by the second column in ascending order. In case of any
         ties, break them based on the 7th column from the end of the table in
         descending order.

             table.sort [1, ..Index -7 ..Descending]

       > Example
         Sort the table by columns whose names start with letter `a`.

              table.sort [(..Select_By_Name "a.*".to_regex case_sensitivity=..Insensitive)]
    @columns Widget_Helpers.make_order_by_selector
    sort : Vector (Text | Sort_Column) | Text -> Text_Ordering -> Boolean -> Problem_Behavior -> DB_Table  ! Incomparable_Values | No_Input_Columns_Selected | Missing_Input_Columns
    sort self (columns = ([(Sort_Column.Name (self.columns.at 0 . name))])) text_ordering:Text_Ordering=..Default error_on_missing_columns:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        Feature.Sort.if_supported_else_throw self.connection.dialect "sort" <|
            problem_builder = Problem_Builder.new error_on_missing_columns=error_on_missing_columns types_to_always_throw=[No_Input_Columns_Selected]
            columns_for_ordering = Table_Helpers.prepare_order_by self.columns columns problem_builder
            problem_builder.attach_problems_before on_problems <|
                new_order_descriptors = columns_for_ordering.map selected_column->
                    column = selected_column.column
                    associated_selector = selected_column.associated_selector
                    effective_text_ordering = if column.value_type.is_text then text_ordering else Nothing
                    self.connection.dialect.prepare_order_descriptor column associated_selector.direction effective_text_ordering
                new_ctx = self.context.add_orders new_order_descriptors
                self.updated_context new_ctx

    ## PRIVATE
       GROUP Standard.Base.Selections
       ICON order
       Deprecated - use `Table.sort` instead.
    @columns Widget_Helpers.make_order_by_selector
    order_by : Vector (Text | Sort_Column) | Text -> Text_Ordering -> Boolean -> Problem_Behavior -> DB_Table  ! Incomparable_Values | No_Input_Columns_Selected | Missing_Input_Columns
    order_by self (columns = ([(Sort_Column.Name (self.columns.at 0 . name))])) text_ordering:Text_Ordering=..Default error_on_missing_columns:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        result = self.sort columns text_ordering error_on_missing_columns on_problems
        Warning.attach (Deprecated.Warning "Standard.Database.Table.Table" "order_by" "Deprecated: use `sort` instead.") result

    ## PRIVATE
       Returns the default ordering used for operations like `add_row_number` or
       `take`.

       If the table was recently ordered by operations like `order_by`, that
       will determine the ordering. Otherwise, the primary key is used if
       available.
    default_ordering : Vector Order_Descriptor | Nothing
    default_ordering self =
        explicit_ordering = self.context.orders
        if explicit_ordering.not_empty then explicit_ordering else
            case self.get_primary_key of
                Nothing -> Nothing
                primary_key_column_names : Vector -> case self.context.from_spec of
                    From_Spec.Table _ alias _ ->
                        primary_key_column_names.map column_name->
                            column_expression = SQL_Expression.Column alias column_name
                            Order_Descriptor.Value column_expression Sort_Direction.Ascending
                    _ -> Nothing

    ## PRIVATE
       Returns the primary key defined for the table, if applicable.
    get_primary_key : Vector Text | Nothing
    get_primary_key self = case self.context.from_spec of
        From_Spec.Table table_name _ _ ->
            # The primary key may not be valid anymore after grouping!
            is_primary_key_still_valid = self.context.groups.is_empty
            if is_primary_key_still_valid.not then Nothing else
                result = self.connection.dialect.fetch_primary_key self.connection table_name
                result.catch Any _->Nothing
        # If the key is a result of a join, union or a subquery then it has no notion of primary key.
        _ -> Nothing

    ## ALIAS deduplicate, unique
       GROUP Standard.Base.Selections
       ICON preparation
       Returns the distinct set of rows within the specified columns from the
       input table.

       When multiple rows have the same values within the specified columns, the
       first row of each such set is returned if possible, but in database
       backends any row from each set may be returned (for example if the row
       ordering is unspecified).

       For the in-memory table, the unique rows will be in the order they
       occurred in the input (this is not guaranteed for database operations).

       Arguments:
       - columns: The columns of the table to use for distinguishing the rows.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error.
         - If no valid columns are selected, a `No_Input_Columns_Selected`, is
           reported as a dataflow error regardless of setting.
         - If floating points values are present in the distinct columns, a
           `Floating_Point_Equality` is reported according to the `on_problems`
           setting.
    @columns Widget_Helpers.make_column_name_multi_selector
    distinct : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Case_Sensitivity -> Problem_Behavior -> DB_Table ! No_Output_Columns | Missing_Input_Columns | No_Input_Columns_Selected | Floating_Point_Equality
    distinct self columns=self.column_names case_sensitivity:Case_Sensitivity=..Default on_problems:Problem_Behavior=..Report_Warning =
        Feature.Distinct.if_supported_else_throw self.connection.dialect "distinct" <|
            key_columns = self.columns_helper.select_columns columns Case_Sensitivity.Default reorder=True error_on_missing_columns=True on_problems=on_problems . catch No_Output_Columns _->
                Error.throw No_Input_Columns_Selected
            key_columns.if_not_error <|
                problem_builder = Problem_Builder.new
                new_table = self.connection.dialect.prepare_distinct self key_columns case_sensitivity problem_builder
                problem_builder.attach_problems_before on_problems new_table

    ## GROUP Standard.Base.Selections
       ICON preparation
       Returns the set of rows which are duplicated within the specified columns from the
       input table.

       When multiple rows have the same values within the specified columns all of those rows are 
       returned. Rows which are unique within the specified columns are removed.

       Arguments:
       - columns: The columns of the table to use for distinguishing the rows.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error.
         - If no valid columns are selected, a `No_Input_Columns_Selected`, is
           reported as a dataflow error regardless of setting.
         - If floating points values are present in the distinct columns, a
           `Floating_Point_Equality` is reported according to the `on_problems`
           setting.
    @columns Widget_Helpers.make_column_name_multi_selector
    duplicates : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Case_Sensitivity -> Problem_Behavior -> DB_Table ! No_Output_Columns | Missing_Input_Columns | No_Input_Columns_Selected | Floating_Point_Equality
    duplicates self columns=self.column_names case_sensitivity:Case_Sensitivity=..Default on_problems:Problem_Behavior=..Report_Warning =
        _ = [columns, case_sensitivity, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "duplicates")

    ## GROUP Standard.Base.Calculations
       ICON join
       Joins two tables according to the specified join conditions.

       Arguments:
       - right: The table to join with.
       - join_kind: The `Join_Kind` for the joining the two tables. It defaults
         to `Left_Outer`.
       - on: A single condition or a common column name, or a list thereof, on
         which to correlate rows from the two tables. If multiple conditions
         are supplied, rows are correlated only if all are true.
         If common column names are provided, these columns should be present
         in both tables and an equality condition is added for each of them.
         By default, the join is performed on the first column of the left table
         correlated with a column in the right table with the same name.
       - right_prefix: The prefix added to right table column names in case of
         name conflict.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If a column name cannot be found, a `No_Such_Column` is reported
           and an empty result is reported.
         - If a column index is invalid, an `Index_Out_Of_Bounds` is
           reported and an empty result is reported.
         - If there are column names that are clashing between the two tables, a
           `Duplicate_Output_Column_Names` is reported and the columns from the
           table are renamed as described below.
         - If a join condition correlates columns whose types are not compatible
           (for example comparing numeric types with text), an
           `Invalid_Value_Type` is reported.
         - If decimal columns are joined on equality, a
           `Floating_Point_Equality` is reported.

         In any of the above cases, if a problem occurs, the resulting table
         will have the desired structure, but it will be empty to indicate that
         the join has failed due to an erroneous join condition.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Row Ordering For In-Memory Tables

         This operation requires a well-defined order of rows in the input
         tables. In-memory tables rely on the ordering stemming directly from
         their layout in memory. Database tables may not impose a deterministic
         ordering. If the table defines a primary key, it is used to by default
         to ensure deterministic ordering. That can be overridden by specifying
         a different ordering using `Table.sort`. If no primary key was
         defined nor any ordering was specified explicitly by the user, the
         order of columns is undefined and the operation will fail, reporting a
         `Undefined_Column_Order` problem and returning an empty table.

       ? Row Ordering For Database Tables

         The ordering of rows in the resulting table is not specified.

       ? Joining on equality of columns with the same name

         When performing an Inner join on two columns with the same name and an
         equality condition, only one copy of column will be included in the
         output (as these two columns would have the exact same content, so they
         would be redundant).

       ? Same-name column join shorthand

         As a shorthand, providing a column name or a list of column names
         allows to join the two tables on equality of corresponding columns with
         the same name. So `table.join other on=["A", "B"]` is a shorthand for:
             table.join other on=[Join_Condition.Equals "A" "A", Join_Condition.Equals "B" "B"]
    @join_kind Widget_Helpers.make_join_kind_selector
    @on Widget_Helpers.make_join_condition_selector
    join : DB_Table -> Join_Kind -> Join_Condition | Text | Vector (Join_Condition | Text) -> Text -> Problem_Behavior -> DB_Table
    join self right (join_kind : Join_Kind = ..Left_Outer) (on : Join_Condition | Text | Vector (Join_Condition | Text) = (default_join_condition self join_kind)) (right_prefix:Text="Right ") (on_problems:Problem_Behavior=..Report_Warning) =
        Feature.Join.if_supported_else_throw self.connection.dialect "join" <|
            self.join_or_cross_join right join_kind on right_prefix on_problems

    ## PRIVATE
       Implementation of both `join` and `cross_join`.
    join_or_cross_join : DB_Table -> Join_Kind | Join_Kind_Cross -> Vector (Join_Condition | Text) | Text -> Text -> Problem_Behavior -> DB_Table
    join_or_cross_join self right:DB_Table join_kind on right_prefix on_problems =
        can_proceed = Helpers.ensure_same_connection "table" [self, right] <|
            join_conditions_ok = join_kind != Join_Kind_Cross || on == []
            if join_conditions_ok . not then Error.throw (Illegal_Argument.Error "Cross join does not allow join conditions") else
                True
        can_proceed.if_not_error <|
            left = self
            table_name_deduplicator = self.connection.base_connection.table_naming_helper.create_unique_name_strategy
            table_name_deduplicator.mark_used [left.name, right.name]
            new_table_name = table_name_deduplicator.make_unique <|
                left.name + "_" + right.name

            needed_indicators = case join_kind of
                Join_Kind.Left_Exclusive  -> Pair.new False True
                Join_Kind.Right_Exclusive -> Pair.new True False
                _ -> Pair.new False False
            subquery_setups = Database_Join_Helper.prepare_subqueries self.connection left right needed_indicators.first needed_indicators.second
            left_setup = subquery_setups.first
            right_setup = subquery_setups.second

            problem_builder = Problem_Builder.new
            join_resolution = Database_Join_Helper.make_join_helpers left right left_setup.column_mapping right_setup.column_mapping . resolve on on_problems
            right_columns_to_drop = if join_kind == Join_Kind.Inner then join_resolution.redundant_column_names else []

            column_naming_helper = self.connection.base_connection.column_naming_helper
            result_columns = Database_Join_Helper.select_columns_for_join column_naming_helper join_kind left_setup.new_columns right_setup.new_columns right_columns_to_drop right_prefix problem_builder

            ## TODO proper equality of nulls in join conditions, see:
               https://www.pivotaltracker.com/story/show/184109759
            on_expressions = join_resolution.conditions

            where_expressions = case join_kind of
                Join_Kind.Left_Exclusive  ->
                    is_right_missing = SQL_Expression.Operation "IS_NULL" [right_setup.indicator_column.expression]
                    [is_right_missing]
                Join_Kind.Right_Exclusive ->
                    is_left_missing = SQL_Expression.Operation "IS_NULL" [left_setup.indicator_column.expression]
                    [is_left_missing]
                _ -> []

            sql_join_kind = case join_kind of
                Join_Kind.Inner           -> SQL_Join_Kind.Inner
                Join_Kind.Left_Outer      -> SQL_Join_Kind.Left
                Join_Kind.Right_Outer     -> SQL_Join_Kind.Right
                Join_Kind.Full            -> SQL_Join_Kind.Full
                Join_Kind.Left_Exclusive  -> SQL_Join_Kind.Left
                Join_Kind.Right_Exclusive -> SQL_Join_Kind.Right
                Join_Kind_Cross           -> SQL_Join_Kind.Cross

            problem_builder.attach_problems_before on_problems <|
                new_from = From_Spec.Join sql_join_kind left_setup.subquery right_setup.subquery on_expressions
                new_ctx = Context.for_subquery new_from . set_where_filters where_expressions
                DB_Table.Value new_table_name self.connection result_columns new_ctx

    ## ALIAS append, cartesian join
       GROUP Standard.Base.Calculations
       ICON join
       Joins tables by pairing every row of the left table with every row of the
       right table.

       Arguments:
       - right: The table to join with.
       - right_row_limit: If the number of rows in the right table exceeds this,
         then a `Cross_Join_Row_Limit_Exceeded` problem is raised. The check
         exists to avoid exploding the size of the table by accident. This check
         can be disabled by setting this parameter to `Nothing`.
       - right_prefix: The prefix added to right table column names in case of
         name conflict. See "Column Renaming" below for more information.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If the `right` table has more rows than the `right_row_limit` allows,
           a `Cross_Join_Row_Limit_Exceeded` is reported. In warning/ignore
           mode, the join is still executed.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Row Ordering For In-Memory Tables

         This operation requires a well-defined order of rows in the input
         tables. In-memory tables rely on the ordering stemming directly from
         their layout in memory. Database tables may not impose a deterministic
         ordering. If the table defines a primary key, it is used to by default
         to ensure deterministic ordering. That can be overridden by specifying
         a different ordering using `Table.sort`. If no primary key was
         defined nor any ordering was specified explicitly by the user, the
         order of columns is undefined and the operation will fail, reporting a
         `Undefined_Column_Order` problem and returning an empty table.

       ? Result Ordering For Database Tables

         The ordering of rows in the resulting table is not specified.
    cross_join : DB_Table -> Integer | Nothing -> Text -> Problem_Behavior -> DB_Table
    cross_join self right:DB_Table right_row_limit=100 right_prefix:Text="Right " on_problems:Problem_Behavior=..Report_Warning =
        Feature.Cross_Join.if_supported_else_throw self.connection.dialect "cross_join" <|
            limit_problems = case right_row_limit.is_nothing.not && (right.row_count > right_row_limit) of
                True ->
                    [Cross_Join_Row_Limit_Exceeded.Error right_row_limit right.row_count]
                False -> []
            on_problems.attach_problems_before limit_problems <|
                self.join_or_cross_join right join_kind=Join_Kind_Cross on=[] right_prefix on_problems

    ## ALIAS lookup
       GROUP Standard.Base.Calculations
       ICON join
       Merges this table with a lookup table.
       New values are looked up in the lookup table based on the `key_columns`.
       Columns that exist in the lookup table where a match was found are
       replaced by values from the lookup table. Columns not found are left
       unchanged.
       This operation is similar to `Table.update_rows`, but just returns a new
       `Table` instance, instead of updating the table in-place (which is only
       possible for Database tables).

       Arguments:
       - lookup_table: The table to use for looking up values.
       - key_columns: Specifies the columns to use for correlating rows between
         the two tables. Must identify values uniquely within `lookup_table`.
       - add_new_columns: Specifies if new columns from the lookup table should
         be added to the result. If `False`, an `Unexpected_Extra_Columns`
         problem is reported.
       - allow_unmatched_rows: Specifies how to handle missing rows in the lookup.
         If `False` (the default), an `Unmatched_Rows_In_Lookup` error is raised.
         If `True`, the unmatched rows are left unchanged. Any new columns will
         be filled with `Nothing`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ? Result Ordering

         When operating in-memory, this operation preserves the order of rows
         from this table (unlike `join`).
         In the Database backend, there are no guarantees related to ordering of
         results.

       ! Error Conditions

         - If this table or the lookup table is lacking any of the columns
           specified in `key_columns`, a `Missing_Input_Columns` error is raised.
         - If an empty vector is provided for `key_columns`, a
           `No_Input_Columns_Selected` error is raised.
         - If a single row is matched by multiple entries in the lookup table,
           a `Non_Unique_Key` error is raised.
         - If a column that is being updated from the lookup table has a type
           that is not compatible with the type of the corresponding column in
           this table, a `No_Common_Type` error is raised.
         - If a key column contains `Nothing` values in the lookup table,
           a `Null_Values_In_Key_Columns` error is raised.
         - If `allow_unmatched_rows` is `False` and there are rows in this table
           that do not have a matching row in the lookup table, an
           `Unmatched_Rows_In_Lookup` error is raised.
         - The following problems may be reported according to the `on_problems`
           setting:
           - If any of the `key_columns` is a floating-point type,
             a `Floating_Point_Equality`.
           - If `add_new_columns` is `False` and the lookup table has columns
             that are not present in this table, an `Unexpected_Extra_Columns`.
    @key_columns Widget_Helpers.make_column_name_multi_selector
    merge : DB_Table -> (Vector (Integer | Text | Regex) | Text | Integer | Regex) -> Boolean -> Boolean -> Problem_Behavior -> DB_Table ! Missing_Input_Columns | Non_Unique_Key | Unmatched_Rows_In_Lookup
    merge self lookup_table:DB_Table key_columns:(Vector (Integer | Text | Regex) | Text | Integer | Regex) add_new_columns:Boolean=False allow_unmatched_rows:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        Feature.Merge.if_supported_else_throw self.connection.dialect "merge" <|
            Helpers.ensure_same_connection "table" [self, lookup_table] <|
                Lookup_Query_Helper.build_lookup_query self lookup_table key_columns add_new_columns allow_unmatched_rows on_problems

    ## ALIAS find replace
       GROUP Standard.Base.Text
       ICON column_add
       Replaces values in the columns using `lookup_table` to specify a mapping
       from old to new values.

       Arguments:
       - lookup_table: the table to use as a mapping from old to new values. A
         `Map` can also be used here (in which case passing `from_column` or
         `to_column` is disallowed and will throw an `Illegal_Argument` error.
       - columns: the column or columns within `self` to perform the replace on.
       - from_column: the column within `lookup_table` to match against
         `columns` in `self`.
       - to_column: the column within `lookup_table` to get new values from.
       - allow_unmatched_rows: Specifies how to handle missing rows in the lookup.
         If `False` (the default), an `Unmatched_Rows_In_Lookup` error is raised.
         If `True`, the unmatched rows are left unchanged. Any new columns will
         be filled with `Nothing`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ? Result Ordering

         When operating in-memory, this operation preserves the order of rows
         from this table (unlike `join`).

         In the Database backend, there are no guarantees related to ordering of
         results.

       ! Error Conditions

         - If this table or the lookup table is lacking any of the columns
           specified by `from_column`, `to_column`, or `columns`, a
           `Missing_Input_Columns` error is raised.
         - If a single row is matched by multiple entries in the lookup table,
           a `Non_Unique_Key` error is raised.
         - If a column that is being updated from the lookup table has a type
           that is not compatible with the type of the corresponding column in
           this table, a `No_Common_Type` error is raised.
         - If a key column contains `Nothing` values in the lookup table,
           a `Null_Values_In_Key_Columns` error is raised.
         - If `allow_unmatched_rows` is `False` and there are rows in this table
           that do not have a matching row in the lookup table, an
           `Unmatched_Rows_In_Lookup` error is raised.
         - The following problems may be reported according to the `on_problems`
           setting:
           - If any of the `columns` is a floating-point type,
             a `Floating_Point_Equality` problem is reported.

       > Example
         Replace values in column 'x' using a lookup table.

             table = Table.new [['x', [1, 2, 3, 4]], ['y', ['a', 'b', 'c', 'd']], ['z', ['e', 'f', 'g', 'h']]]
             #      | x | y | z
             #   ---+---+---+---
             #    0 | 1 | a | e
             #    1 | 2 | b | f
             #    2 | 3 | c | g
             #    3 | 4 | d | h

             lookup_table = Table.new [['x', [1, 2, 3, 4]], ['new_x', [10, 20, 30, 40]]]
             #      | old_x | new_x
             #   ---+-------+-------
             #    0 | 1     | 10
             #    1 | 2     | 20
             #    2 | 3     | 30
             #    3 | 4     | 40

             result = table.replace lookup_table 'x'
             #      | x  | y | z
             #   ---+----+---+---
             #    0 | 10 | a | e
             #    1 | 20 | b | f
             #    2 | 30 | c | g
             #    3 | 40 | d | h
    @lookup_table Widget_Helpers.make_replace_selector
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    @from_column Widget.Text_Input
    @to_column Widget.Text_Input
    replace : (DB_Table | Dictionary) -> Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type -> (Text | Integer | Nothing) -> (Text | Integer | Nothing) -> Boolean -> Problem_Behavior -> DB_Table ! Missing_Input_Columns | Non_Unique_Key | Unmatched_Rows_In_Lookup
    replace self lookup_table:(DB_Table | Dictionary) columns:(Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type) from_column:(Text | Integer | Nothing)=Nothing to_column:(Text | Integer | Nothing)=Nothing allow_unmatched_rows:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        Feature.Replace.if_supported_else_throw self.connection.dialect "replace" <|
            Replace_Helpers.replace self lookup_table columns from_column to_column allow_unmatched_rows on_problems

    ## ALIAS join by row position
       GROUP Standard.Base.Calculations
       ICON join2-1
       Joins two tables by zipping rows from both tables table together - the
       first row of the left table is correlated with the first one of the right
       one etc.

       Arguments:
       - right: The table to join with.
       - keep_unmatched: If set to `True`, the result will include as many rows
         as the larger of the two tables - the last rows of the larger table
         will have nulls for columns of the smaller one. If set to `False`, the
         result will have as many rows as the smaller of the two tables - the
         additional rows of the larger table will be discarded. The default
         value is `Report_Unmatched` which means that the user expects that two
         tables should have the same amount of rows; if they do not, the
         behaviour is the same as if it was set to `True` - i.e. the unmatched
         rows are kept with `Nothing` values for the other table, but a
         `Row_Count_Mismatch` problem is also reported.
       - right_prefix: The prefix added to right table column names in case of
         name conflict. See "Column Renaming" below for more information.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If the tables have different number of rows and `keep_unmatched` is
           set to `Report_Unmatched`, the join will report `Row_Count_Mismatch`.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Row Ordering

         This operation requires a well-defined order of rows in the input
         tables. In-memory tables rely on the ordering stemming directly from
         their layout in memory. Database tables may not impose a deterministic
         ordering. If the table defines a primary key, it is used to by default
         to ensure deterministic ordering. That can be overridden by specifying
         a different ordering using `Table.sort`. If no primary key was
         defined nor any ordering was specified explicitly by the user, the
         order of columns is undefined and the operation will fail, reporting a
         `Undefined_Column_Order` problem and returning an empty table.
    @keep_unmatched (make_single_choice [["True", "Boolean.True"], ["False", "Boolean.False"], ["Report", Meta.get_qualified_type_name Report_Unmatched]])
    zip : DB_Table -> Boolean | Report_Unmatched -> Text -> Problem_Behavior -> DB_Table
    zip self right keep_unmatched=Report_Unmatched right_prefix:Text="Right " on_problems:Problem_Behavior=..Report_Warning =
        _ = [right, keep_unmatched, right_prefix, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "zip")

    ## ALIAS append, concat, join
       GROUP Standard.Base.Calculations
       ICON union
       Appends records from other table(s) to this table.

       Arguments:
       - tables: A single table or a vector of tables to append to this one. The
         tables are concatenated in the order they are specified, with `self`
         being the first one.
       - columns_to_keep: Specifies which columns to keep. Defaults to keeping
         columns that are present in any of the tables, reporting a warning for
         columns that are not present in all tables and adding `Nothing` values
         for them.
       - match_columns: Specifies how to match the columns.
         - If `Match_Columns.By_Name` - the columns are matched by name across
           all provided tables.
         - If `Match_Columns.By_Position` - the columns are mapped by position.
           The names of each column come from the first table in which the given
           column appears in.
           The `List` option is not applicable when mapping columns by position.
           Column names are taken from the first table if `In_All` and from the
           first table that has the maximum number of columns if `In_Any`
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ? Unifying Column Types

         Numeric columns are unified by finding the smallest type that can fit
         all of the columns. The biggest integer type will be chosen and if
         integers and decimals are mixed, the decimal type will be chosen.
         If boolean columns are mixed with numeric columns, they will be coerced
         to the numeric type (and converted to 0 and 1).

         Text types will are also unified by finding the smallest type that can
         fit all the values. If constant-length texts of different lengths are
         mixed, they will be coerced to a varying-length type.

         If date and date-time columns are unified, this yields a date-time
         column. In-memory, the date is promoted by adding a time of 00:00 and
         the system time-zone. In other backends that behaviour may differ.

         If one of the matched columns has `Mixed` type, that type will be used
         regardless of types of other columns. Note that the `Mixed` type may
         not be supported by most Database backends.

         Finally, if no common type is found using the rules above, everything
         is converted to text.

       ! Error Conditions

         - If no common type is found and the text conversion fallback is used,
           the `No_Common_Type` problem is reported.
         - The `Float` type may not be able to exactly represent larger
           integers, thus if such large integers are mixed with floats, the
           resulting conversion to `Float` may cause a loss of precision.
           In that case, a `Loss_Of_Integer_Precision` problem is reported.
           This warning is only reported in the in-memory backend. Currently,
           the Database backend proceeds without a warning about precision loss.
         - If a column of dates is unified with a column of date-times, since
           the assumption of using the midnight time-of-day is arbitrary,
           a `Implicit_Date_As_Date_Time_Conversion` problem is reported.
         - If an empty vector of tables is provided, an `Illegal_Argument` error
           is raised.
         - If `columns_to_keep` is set to `In_All` or `List` and an expected
           column is missing in some of the tables, a `Unmatched_Columns`
           problem is reported. If this causes the output to contain no columns,
           a `No_Output_Columns` error is raised.

       ? Ordering of Columns in the result

         When matching columns by name, it is possible that the ordering of
         columns may vary between input tables. The ordering is determined as
         following: columns that are kept from the first table are in the order
         they appear in that table. If there are columns that do not appear in
         the first table, they are appended to the end of the resulting table in
         the order they appear in the input.
    @tables (Widget.Vector_Editor item_editor=Widget.Code_Input item_default='_' display=Display.Always)
    @columns_to_keep Columns_To_Keep.default_widget
    union : (DB_Table | Vector DB_Table) -> Columns_To_Keep -> Match_Columns -> Problem_Behavior -> DB_Table
    union self tables:(DB_Table | Vector) (columns_to_keep : Columns_To_Keep = ..In_Any_Warn_On_Missing) (match_columns : Match_Columns = ..By_Name) (on_problems : Problem_Behavior = ..Report_Warning) =
        Feature.Union.if_supported_else_throw self.connection.dialect "union" <|
            all_tables = case tables of
                v : Vector -> [self] + (v.map t-> DB_Table.from t)
                single_table -> [self, single_table]
            Helpers.ensure_same_connection "table" all_tables <|
                ## We keep separate problem builders, because if we are reporting `No_Output_Columns`,
                  we only want to add a cause coming from unification; matching reports problems that would not fit this error.
                problem_builder_for_matching = Problem_Builder.new
                problem_builder_for_unification = Problem_Builder.new
                matched_column_sets = Match_Columns_Helpers.match_columns all_tables match_columns columns_to_keep problem_builder_for_matching
                dialect = self.connection.dialect
                type_mapping = dialect.get_type_mapping
                merged_columns = matched_column_sets.map column_set->
                    sql_type_from_value_type value_type =
                        type_mapping.value_type_to_sql value_type Problem_Behavior.Report_Error . catch Inexact_Type_Coercion error->
                            Panic.throw <|
                                Illegal_State.Error "Unexpected inexact type coercion in Union. The union logic should only operate in types supported by the given backend. This is a bug in the Database library. The coercion was: "+error.to_display_text cause=error
                    case Table_Helpers.unify_result_type_for_union column_set all_tables problem_builder_for_unification of
                        Union_Result_Type.Common_Type common_type ->
                            [column_set, sql_type_from_value_type common_type, common_type]
                        Union_Result_Type.Fallback_To_Text ->
                            [column_set, sql_type_from_value_type Value_Type.Char, Value_Type.Char]
                        Union_Result_Type.No_Types_To_Unify ->
                            ## If the column is all nulls, we still need to give it some type.
                              For DB `Mixed` is not available, so a portable type to use is `Char`.
                            [column_set, SQL_Type.null, Value_Type.Char]

                problem_builder_for_matching.attach_problems_before on_problems <| problem_builder_for_unification.attach_problems_before on_problems <|
                    if merged_columns.is_empty then problem_builder_for_unification.raise_no_output_columns_with_cause else
                        queries = all_tables.map_with_index i-> t->
                            columns_to_select = merged_columns.map description->
                                column_set  = description.at 0
                                sql_type    = description.at 1
                                result_type = description.at 2
                                column_name = column_set.name
                                ## We assume that the type for this expression will never be queried - it is
                                  just used internally to build the Union operation and never exposed externally.
                                infer_return_type _ = SQL_Type_Reference.null
                                case column_set.column_indices.at i of
                                    corresponding_column_index : Integer ->
                                        column = t.at corresponding_column_index
                                        internal_named_column = column.as_internal.rename column_name
                                        ## We cast if the result type is different.
                                          This is a bit on the safe side. In some cases the cast is not needed
                                          (for example, most databases will allow union of int2 and int4 without casts; or SQLite does not need casts at all).
                                          However, we do this for simplicity as determining the rules when the cast is needed or not is adding a lot of complication.
                                          This is a possible future improvement to make queries lighter, but the benefit is unlikely to be worth it.
                                        needs_cast = column.value_type != result_type
                                        if needs_cast.not then internal_named_column else
                                            dialect.make_cast internal_named_column sql_type infer_return_type
                                    Nothing ->
                                        typ = SQL_Type_Reference.from_constant SQL_Type.null
                                        expr = SQL_Expression.Literal "NULL"
                                        null_column = Internal_Column.Value column_name typ expr
                                        if sql_type == SQL_Type.null then null_column else
                                            dialect.make_cast null_column sql_type infer_return_type
                            pairs = columns_to_select.map c->
                                [c.name, c.expression]
                            Query.Select pairs t.context

                        table_name_deduplicator = self.connection.base_connection.table_naming_helper.create_unique_name_strategy
                        table_name_deduplicator.mark_used (all_tables.map .name)
                        union_alias = table_name_deduplicator.make_unique <|
                            all_tables.map .name . join "_"
                        new_from = From_Spec.Union queries union_alias
                        new_ctx = Context.for_subquery new_from
                        ## TODO [RW] The result type is currently fetched
                          independently for each column, instead we should fetch it
                          for all columns at once.
                          See #6118.
                        infer_return_type expression =
                            SQL_Type_Reference.new self.connection new_ctx expression
                        new_columns = merged_columns.map description->
                            column_set = description.first
                            result_type = description.at 2
                            name = column_set.name
                            expression = SQL_Expression.Column union_alias name
                            input_column = Internal_Column.Value name (infer_return_type expression) expression
                            dialect.adapt_unified_column input_column result_type infer_return_type

                        DB_Table.Value union_alias self.connection new_columns new_ctx

    ## ALIAS group by, summarize, count, count distinct, sum, average, mean, median, percentile, mode, standard deviation, variance, minimum, maximum, first, last, shortest, longest
       GROUP Standard.Base.Calculations
       ICON transform4

       Aggregates the rows in a table using `group_by` columns.
       The columns argument specifies which additional aggregations to perform
       and to return.

       Arguments:
       - group_by: Vector of column identifiers to group by. These will be
         included at the start of the resulting table. If no columns are
         specified a single row will be returned with the aggregate columns.
       - columns: Vector of `Aggregate_Column` specifying the aggregated table.
         Expressions can be used within the aggregate column to perform more
         complicated calculations.
       - error_on_missing_columns: Specifies if a missing columns in aggregates
         should result in an error regardless of the `on_problems` settings.
         Defaults to `False`, meaning that problematic aggregate will not be
         included in the result and the problem reported according to the
         `on_problems` setting.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a given aggregate is not supported by the backend,
           `Unsupported_Database_Operation` is reported.
         - If a column index is out of range, a `Missing_Input_Columns` is
           reported according to the `on_problems` setting, unless
           `error_on_missing_columns` is set to `True`, in which case it is
           raised as an error. Problems resolving `group_by` columns are
           reported as dataflow errors regardless of these settings, as a
           missing grouping will completely change semantics of the query.
         - If a column selector is given as a `Text` and it does not match any
           columns in the input table nor is it a valid expression, an
           `Invalid_Aggregate_Column` error is raised according to the
           `on_problems` settings (unless `error_on_missing_columns` is set to
           `True` in which case it will always be an error). Problems resolving
           `group_by` columns are reported as dataflow errors regardless of
           these settings, as a missing grouping will completely change
           semantics of the query.
         - If an aggregation fails, an `Invalid_Aggregation` dataflow error is
           raised.
         - The following additional problems may be reported according to the
           `on_problems` settings:
           - If there are invalid column names in the output table,
             a `Invalid_Column_Names`.
           - If there are duplicate column names in the output table,
             a `Duplicate_Output_Column_Names`.
           - If grouping on or computing the `Mode` on a floating point number,
             a `Floating_Point_Equality`.
           - If when concatenating values there is an quoted delimited,
             an `Unquoted_Delimiter`
           - If there are more than 10 issues with a single column,
             an `Additional_Warnings`.

       > Example
         Count all the rows

              table.aggregate columns=[Aggregate_Column.Count]

       > Example
         Group by the Key column, count the rows

              table.aggregate ["Key"] [Aggregate_Column.Count]
    @group_by Widget_Helpers.make_column_name_multi_selector
    @columns Widget_Helpers.make_aggregate_column_vector_selector
    aggregate : Vector (Integer | Text | Regex | Aggregate_Column) | Text | Integer | Regex -> Vector Aggregate_Column -> Boolean -> Problem_Behavior -> DB_Table ! No_Output_Columns | Invalid_Aggregate_Column | Invalid_Column_Names | Duplicate_Output_Column_Names | Floating_Point_Equality | Invalid_Aggregation | Unquoted_Delimiter | Additional_Warnings
    aggregate self (group_by : Vector | Text | Integer | Regex = []) (columns : Vector = []) (error_on_missing_columns : Boolean = False) (on_problems : Problem_Behavior = ..Report_Warning) =
        Feature.Aggregate.if_supported_else_throw self.connection.dialect "aggregate" <|
            Aggregate_Helper.aggregate self group_by columns error_on_missing_columns on_problems

    ## ALIAS pivot, unpivot
       GROUP Standard.Base.Calculations
       ICON map_row
       Returns a new table with a chosen subset of columns left unchanged and
       the other columns pivoted to rows with a single name field and a single
       value field.

       Arguments:
       - key_columns: Set of fields to remain as columns. These values will be
         repeated for each data field that is pivoted.
       - attribute_column_name: The name of the field that will contain the
         names of the pivoted fields. If this name is already in use, it will be
         renamed with a numeric suffix.
       - value_column_name: The name of the field that will contain the values
         of the pivoted fields. If this name is already in use, it will be
         renamed with a numeric suffix.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If any column names in the new table are clashing, a
           `Duplicate_Output_Column_Names` is reported according to the
           `on_problems` setting.

       > Example
         Transpose Operation

         Input Table `table`:

            Id | Name    | Country
           ----|---------|---------
            A  | Example | France
            B  | Another | Germany

         Result `table.transpose ['Id'] 'Attribute' 'Value'`:

            Id | Attribute | Value
           ----|-----------|---------
            A  | Name      | Example
            A  | Country   | France
            B  | Name      | Another
            B  | Country   | Germany
    @key_columns Widget_Helpers.make_column_name_multi_selector
    transpose : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Text -> Text -> Boolean -> Problem_Behavior -> DB_Table ! No_Output_Columns | Missing_Input_Columns | Duplicate_Output_Column_Names
    transpose self key_columns=[] (attribute_column_name:Text="Name") (value_column_name:Text="Value") (error_on_missing_columns:Boolean=True) (on_problems:Problem_Behavior=..Report_Warning) =
        ## Avoid unused arguments warning. We cannot rename arguments to `_`,
           because we need to keep the API consistent with the in-memory table.
        _ = [key_columns, attribute_column_name, value_column_name, error_on_missing_columns, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "transpose")

    ## ALIAS pivot, unpivot
       GROUP Standard.Base.Calculations
       ICON column_add
       Returns a new table using a chosen field as the column header and then
       aggregating the rows within each value as specified. Optionally, a set of
       fields can be used to group the rows.

       Arguments:
       - group_by: Set of fields to group by. If not provided, a single row will
         be produced.
       - name_column: The field to use as the column header. If this field is
         not found, then each value will be a single column.
       - values: The aggregation to perform on each set of rows. Can be a single
         aggregation or a vector of aggregations. Expressions can be used within
         the aggregation to perform more complicated calculations.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `group_by` or `name_column` is not in the input table,
           a `Missing_Input_Columns` is raised as a dataflow error.
         - If a column selector in `values` given as a `Text` and it does not
           match any columns in the input table nor is it a valid expression, an
           `Invalid_Aggregate_Column` dataflow error is raised.
         - If a column name generated from the input data is invalid,
           `Invalid_Column_Names` error is raised.
         - If an aggregation fails, an `Invalid_Aggregation` dataflow error is
           raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If grouping on, using as the column name, or computing the `Mode` on
             a floating point number, a `Floating_Point_Equality`.
           - If when concatenating values there is an quoted delimited,
             an `Unquoted_Delimiter`
           - If there are more than 10 issues with a single column,
             an `Additional_Warnings`.

       > Example
         Cross Tab Operation

         Input Table `table`:

            Id | B       | C
           ----|---------|---------
            A  | Name    | Example
            A  | Country | France

         Result `table.cross_tab ['Id'] 'B' (Aggregate_Column.First 'C')`:

            Id | Name    | Country
           ----|---------|---------
            A  | Example | France
    @group_by Widget_Helpers.make_column_name_multi_selector
    @names Widget_Helpers.make_column_name_selector
    @values Widget_Helpers.make_aggregate_column_selector
    cross_tab : Vector (Integer | Text | Regex | Aggregate_Column) | Text | Integer | Regex -> (Text | Integer) -> Aggregate_Column | Vector Aggregate_Column -> Problem_Behavior -> DB_Table ! Missing_Input_Columns | Invalid_Aggregate_Column | Floating_Point_Equality | Invalid_Aggregation | Unquoted_Delimiter | Additional_Warnings | Invalid_Column_Names
    cross_tab self group_by=[] names=self.column_names.first values=..Count (on_problems:Problem_Behavior=..Report_Warning) =
        ## Avoid unused arguments warning. We cannot rename arguments to `_`,
           because we need to keep the API consistent with the in-memory table.
        _ = [group_by, names, values, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "cross_tab")

    ## GROUP Standard.Base.Conversions
       ICON convert
       Parses columns within a Table to a specific value type.
       By default, it looks at all `Text` columns and attempts to deduce the
       type (columns with other types are not affected).

       In the Database backends, the default formatting settings of the
       particular database are used.

       In the in-memory backend, the default parser options only parse values
       where the process is reversible (e.g., 0123 would not be converted to an
       integer as there is a leading 0). However, settings in the
       `Data_Formatter` can control this.

       Arguments:
       - columns: The columns to parse. If not specified, all text columns
         will be parsed.
       - type: The type to parse the columns to. Defaults to `Auto` meaning that
         the type will be inferred from the data. In the Database backends,
         `Auto` is not supported, so a specific type must be selected.
       - format: The formatting settings to use when parsing the columns.
         For `Date`, `Time_Of_Day` and `Date_Time`, a Java date time style
         can be used. For `Boolean`, it should be two values that represent true
         and false, separated by a `|`. Alternatively, a `Data_Formatter` can be
         passed to provide complete customisation of the formatting. If
         `Nothing` is provided, the default formatting settings of the backend
         will be used. `Nothing` is currently the only setting accepted by the
         Database backends.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a column selected for parsing is not a text column, an
           `Invalid_Value_Type` error is raised.
         - If no columns have been selected for parsing,
           a `No_Input_Columns_Selected` error is raised.
         - If custom formatting settings were provided, but the database backend
           does not support customization, an `Unsupported_Database_Operation`
           error is reported.

       > Example
         Parse dates in a column.

             table.parse "birthday" Value_Type.Date
    @type (Widget_Helpers.parse_type_selector include_auto=False)
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True)
    @format (make_format_chooser include_number=False)
    parse : Vector (Text | Integer | Regex) | Text | Integer | Regex -> Value_Type | Auto -> Text | Data_Formatter -> Boolean -> Problem_Behavior -> DB_Table
    parse self columns=(self.columns . filter (c-> c.value_type.is_text) . map .name) type:(Value_Type | Auto) format:(Text | Data_Formatter)='' error_on_missing_columns:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        selected = self.columns_helper.select_columns columns Case_Sensitivity.Default reorder=False error_on_missing_columns=error_on_missing_columns on_problems=on_problems error_on_empty=False . map self.make_column
        selected.fold self table-> column_to_parse->
            new_column = column_to_parse.parse type format on_problems
            table.set new_column as=column_to_parse.name set_mode=Set_Mode.Update

    ## GROUP Standard.Base.Conversions
       ICON convert
       Formats `DB_Column`s within a `Table` using a format string,
       `Date_Time_Formatter`, or `DB_Column` of format strings.

       Arguments:
       - columns: The columns to format. The columns can have different types,
         but all columns must be compatible with any provided `format` value.
       - format: The type-dependent format string to use to format the values.
         If `format` is `""` or `Nothing`, .to_text is used to format the value.
         In case of date/time columns, the format can also be a
         `Date_Time_Formatter`. If `format` is a `DB_Column`, it must be a text
         column.
       - locale: The locale in which the format should be interpreted.
         If a `Date_Time_Formatter` is provided for `format` and the `locale` is
         set to anything else than `Locale.default`, then that locale will
         override the formatters locale.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a provided `format` value is not compatible with all selected
           columns, an Illegal_Argument error will be thrown, or a
           Date_Time_Format_Parse_Error in the case of a badly-formed date/time
           format.
         - If no columns have been selected for formatting, a
           `No_Input_Columns_Selected` error is raised.

       ? Supported Types
         - `Value_Type.Date`
         - `Value_Type.Date_Time`
         - `Value_Type.Time`
         - `Value_Type.Integer`
         - `Value_Type.Float`
         - `Value_Type.Boolean`

       ? `Value_Type.Date`, `Value_Type.Date_Time`, `Value_Type.Time` format strings

          See `Date_Time_Formatter` for more details.

       ? `Value_Type.Integer`, `Value_Type.Float` format strings

         Numeric format strings are specified by the Java DecimalFormat class.
         See https://docs.oracle.com/javase/8/docs/api/java/text/DecimalFormat.html
         for a complete format specification.

       ? `Value_Type.Boolean` format strings

         Format strings for `Boolean` consist of two values that represent true
         and false, separated by a `|`.

       > Example
         Format the first and last boolean columns as 'Yes'/'No'.

             table.format columns=[0, -1] format="Yes|No"

       > Example
         Format dates in a column using the format `yyyyMMdd`.

             table.format "birthday" "yyyyMMdd"

       > Example
         Format all columns in the table using the default formatter.

             table.format
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    @locale Locale.default_widget
    @format (make_format_chooser include_number=True)
    format : Vector (Text | Integer | Regex | By_Type) | Text | Integer | Regex | By_Type -> Text | Date_Time_Formatter | DB_Column -> Locale -> Boolean -> Problem_Behavior -> DB_Table ! Date_Time_Format_Parse_Error | Illegal_Argument
    format self columns:(Vector (Text | Integer | Regex | By_Type) | Text | Integer | Regex | By_Type) format:(Text | Date_Time_Formatter | DB_Column)="" locale:Locale=Locale.default error_on_missing_columns:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        _ = [columns, format, locale, error_on_missing_columns, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "format")

    ## GROUP Standard.Base.Conversions
       ICON split
       Splits a column of text into a set of new columns.
       The original column will be removed from the table.
       The new columns will be named with the name of the input column with a
       incrementing number after.

       Arguments:
       - column: The name or index of the column to split the text of.
       - delimiter: The term or terms used to split the text.
       - column_count: The number of columns to split to.
         If `All_Columns` then columns will be added to fit all data.
       - on_problems: Specifies the behavior when a problem occurs.

       ! Error Conditions
         If the data exceeds the `column_count`, a `Column_Count_Exceeded` will
         be reported according to the `on_problems` behavior.
    @column Widget_Helpers.make_column_name_selector
    @delimiter make_delimiter_selector
    @column_count Columns_To_Add.default_widget
    split_to_columns : Text | Integer -> Text -> Columns_To_Add -> Problem_Behavior -> DB_Table
    split_to_columns self column delimiter="," (column_count : Columns_To_Add = ..All_Columns) on_problems:Problem_Behavior=..Report_Warning =
        _ = [column, delimiter, column_count.columns_to_split, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "split_to_columns")

    ## GROUP Standard.Base.Conversions
       ICON split
       Splits a column of text into a set of new rows.
       The values of other columns are repeated for the new rows.

       Arguments:
       - column: The name or index of the column to split the text of.
       - delimiter: The term or terms used to split the text.
    @column Widget_Helpers.make_column_name_selector
    @delimiter make_delimiter_selector
    split_to_rows : Text | Integer -> Text -> DB_Table
    split_to_rows self column delimiter="," =
        _ = [column, delimiter]
        Error.throw (Unsupported_Database_Operation.Error "split_to_rows")

    ## GROUP Standard.Base.Conversions
       ICON split
       Tokenizes a column of text into a set of new columns using a regular
       expression.
       If the pattern contains marked groups, the values are concatenated
       together; otherwise the whole match is returned.
       The original column will be removed from the table.
       The new columns will be named with the name of the input column with a
       incrementing number after.

       Arguments:
       - column: The name or index of the column to tokenize the text of.
       - pattern: The pattern used to find within the text.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - column_count: The number of columns to split to.
         If `Nothing` then columns will be added to fit all data.
       - on_problems: Specifies the behavior when a problem occurs.

       ! Error Conditions
         If the data exceeds the `column_count`, a `Column_Count_Exceeded` will
         be reported according to the `on_problems` behavior.
    @column Widget_Helpers.make_column_name_selector
    tokenize_to_columns : Text | Integer -> Text -> Case_Sensitivity -> Columns_To_Add -> Problem_Behavior -> DB_Table
    tokenize_to_columns self column pattern="." case_sensitivity:Case_Sensitivity=..Sensitive (column_count : Columns_To_Add = ..All_Columns) (on_problems : Problem_Behavior = ..Report_Warning) =
        _ = [column, pattern, case_sensitivity, column_count, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "tokenize_to_columns")

    ## GROUP Standard.Base.Conversions
       ICON split
       Tokenizes a column of text into a set of new rows using a regular
       expression.
       If the pattern contains marked groups, the values are concatenated
       together; otherwise the whole match is returned.
       The values of other columns are repeated for the new rows.

       Arguments:
       - column: The name or index of the column to tokenize the text of.
       - pattern: The pattern used to find within the text.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - at_least_one_row: If True, a tokenization that returns no values will still
         produce at least one row, with `Nothing` for the output column values.
         Equivalent to converting a tokenization output of [] to [Nothing].
    @column Widget_Helpers.make_column_name_selector
    tokenize_to_rows : Text | Integer -> Text -> Case_Sensitivity -> Boolean -> DB_Table
    tokenize_to_rows self column pattern="." case_sensitivity:Case_Sensitivity=..Sensitive at_least_one_row:Boolean=False =
        _ = [column, pattern, case_sensitivity, at_least_one_row]
        Error.throw (Unsupported_Database_Operation.Error "tokenize_to_rows")

    ## GROUP Standard.Base.Conversions
       ICON split
       Converts a Text column into new columns using a regular expression
       pattern.

       Each match becomes a row in the table.
       The values of other columns are repeated for the new rows.

       If there are no marked groups, a single column with whole content of
       match is added. Otherwise, each group becomes a column (with group name
       if named in Regex).

       Arguments:
       - column: The column to split the text of.
       - pattern: The pattern used to search within the text.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - parse_values: Parse any values using the default value parser.

       ? Column Names

       If no marked group, the new column will have the same name as the input.
       If the marked groups are named, the names will be used otherwise the column
       will be named `<Input Column> <N>` where `N` is the number of the marked group.
       If the new name is already in use it will be renamed following the normal
       suffixing strategy.
    @column Widget_Helpers.make_column_name_selector
    @pattern Widget.Text_Input
    parse_to_columns : Text | Integer -> Text | Regex -> Case_Sensitivity -> Boolean -> Problem_Behavior -> DB_Table
    parse_to_columns self column pattern="." case_sensitivity:Case_Sensitivity=..Sensitive parse_values=True on_problems:Problem_Behavior=..Report_Error =
        _ = [column, pattern, case_sensitivity, parse_values, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "parse_to_columns")

    ## GROUP Standard.Base.Calculations
       ICON split
       Expand a column of objects to a new set of columns.

       Arguments:
       - column: The column to expand.
       - fields: The set fields to expand. If `Nothing` then all fields are added.
       - prefix: Prefix to add to the column names. If `Nothing` then the column
         name is used.
    @column Widget_Helpers.make_column_name_selector
    @fields (Widget.Vector_Editor item_editor=Widget.Text_Input item_default='""')
    expand_column : Text | Integer -> Vector | Nothing -> Text | DB_Table -> DB_Table ! Type_Error
    expand_column self column fields=Nothing prefix=Nothing =
            _ = [column, fields, prefix]
            Error.throw (Unsupported_Database_Operation.Error "expand_column")

    ## GROUP Standard.Base.Calculations
       ICON split
       Expand aggregate values in a column to separate rows.

       For each value in the specified column, if it is an aggregate (`Vector`,
       `Range`, etc.), expand it to multiple rows, duplicating the values in the
       other columns.

       Arguments:
       - column: The column to expand.
       - at_least_one_row: for an empty aggregate value, if `at_least_one_row` is
         true, a single row is output with `Nothing` for the aggregates column; if
         false, no row is output at all.

       The following aggregate values are supported:
       - `Array`
       - `Vector`
       - `List`
       - `Range`
       - `Date_Range`
       - `Pair`
       - `Table`
       - `Column`

       Any other values are treated as non-aggregate values, and their rows are kept
       unchanged.

       In in-memory tables, it is permitted to mix values of different types.

       > Example
         Expand a column of integer `Vectors` to a column of `Integer`

         table = Table.new [["aaa", [1, 2]], ["bbb", [[30, 31], [40, 41]]]]
         # => Table.new [["aaa", [1, 1, 2, 2]], ["bbb", [30, 31, 40, 41]]]
    @column Widget_Helpers.make_column_name_selector
    expand_to_rows : Text | Integer -> Boolean -> DB_Table ! Type_Error | No_Such_Column | Index_Out_Of_Bounds
    expand_to_rows self column at_least_one_row:Boolean=False =
        _ = [column, at_least_one_row]
        Error.throw (Unsupported_Database_Operation.Error "expand_to_rows")

    ## GROUP Standard.Base.Conversions
       ICON convert
       Cast the selected columns to a specific type.

       Returns a new table in which the selected columns are replaced with
       columns having the new types.

       Arguments:
       - columns: The selection of columns to cast.
       - value_type: The `Value_Type` to cast the column to.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       In the Database backend, this will boil down to a CAST operation.
       In the in-memory backend, a conversion will be performed according to
       the following rules:
       - Anything can be cast into the `Mixed` type.
       - Converting to a `Char` type, the elements of the column will be
         converted to text. If it is fixed length, the texts will be trimmed or
         padded on the right with the space character to match the desired
         length.
       - Conversion between numeric types will replace values exceeding the
         range of the target type with `Nothing`.
       - Converting decimal numbers into integers will truncate or round them,
         depending on the backend. If more control is needed, use the various
         rounding functions (such as `round` or `floor`).
       - Booleans may also be converted to numbers, with `True` being converted
         to `1` and `False` to `0`. The reverse is not supported - use `iif`
         instead.
       - A `Date_Time` may be converted into a `Date` or `Time` type - the
         resulting value will be truncated to the desired type.
       - If a `Date` is to be converted to `Date_Time`, it will be set at
         midnight of the default system timezone.
       - For a `Mixed` column being converted into a specific type, each row is
         converted individually.

        If the target type cannot fit some of the values (for example due to too
        small range), a `Conversion_Failure` may be reported according to the
        `on_problems` rules. The Database backends may fail with `SQL_Error`
        instead.

       ? Inexact Target Type

         If the backend does not support the requested target type, the closest
         supported type is chosen and a `Inexact_Type_Coercion` problem is
         reported.

       ! Casting Text values

         The `parse` method should be used to convert text values into other
         types. Due to this, a Mixed column containing values `[2, "3"]` will
         actually be converted into `[2, Nothing]` when casting to Integer type.
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    cast : Vector (Text | Integer | Regex | By_Type) | Text | Integer | Regex | By_Type -> Value_Type -> Boolean -> Problem_Behavior -> DB_Table ! Illegal_Argument | Inexact_Type_Coercion | Conversion_Failure
    cast self columns:(Vector (Text | Integer | Regex | By_Type) | Text | Integer | Regex | By_Type)=[0] value_type:Value_Type error_on_missing_columns:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        selected = self.columns_helper.select_columns columns Case_Sensitivity.Default reorder=False error_on_missing_columns=error_on_missing_columns on_problems=on_problems error_on_empty=False . map self.make_column
        selected.fold self table-> column_to_cast->
            new_column = column_to_cast.cast value_type on_problems
            table.set new_column as=column_to_cast.name set_mode=Set_Mode.Update

    ## GROUP Standard.Base.Conversions
       ICON convert
       Change the value type of table columns to a more specific one, based on
       their contents.

       This operation is currently not available in the Database backend.
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    auto_cast : Vector (Text | Integer | Regex | By_Type) | Text | Integer | Regex | By_Type -> Boolean -> Boolean -> Problem_Behavior -> DB_Table
    auto_cast self columns:(Vector (Text | Integer | Regex | By_Type) | Text | Integer | Regex | By_Type)=self.column_names shrink_types:Boolean=False error_on_missing_columns:Boolean=True on_problems:Problem_Behavior=..Report_Warning =
        _ = [columns, shrink_types, error_on_missing_columns, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "auto_cast")

    ## ALIAS drop_missing_rows, dropna
       GROUP Standard.Base.Selections
       ICON preparation
       Remove rows which are all blank or containing blank values.

       Arguments:
       - when: If Blank_Selector.Any_Cell, then remove any row containing
        any blank values.
         If Blank_Selector.All_Cells, then only remove rows with all blank values.
       - treat_nans_as_blank: If `True`, then `Number.nan` is considered as blank.

       ? Blank values
         Blank values are `Nothing`, `""` and depending on setting `Number.nan`.
    filter_blank_rows : Blank_Selector -> Boolean -> DB_Table
    filter_blank_rows self (when:Blank_Selector=..All_Cells) treat_nans_as_blank:Boolean=False =
        Table_Helpers.filter_blank_rows self when treat_nans_as_blank

    ## ALIAS count
       GROUP Standard.Base.Metadata
       ICON metadata
       Returns the amount of rows in this table.
    row_count : Integer
    row_count self = if self.internal_columns.is_empty then 0 else
        expr = SQL_Expression.Operation "COUNT_ROWS" []
        column_name = "row_count"
        ## We need to keep some column in the subquery which will determine if
           the query is performing regular selection or aggregation. To avoid
           computing too much we do not pass all the columns but only the first
           one.
        setup = self.context.as_subquery self.name [[self.internal_columns.first]]
        new_ctx = Context.for_subquery setup.subquery
        query = Query.Select [[column_name, expr]] new_ctx
        sql = self.connection.dialect.generate_sql query
        table = self.connection.read_statement sql
        table.at column_name . at 0

    ## ALIAS load, import
       GROUP Standard.Base.Input
       ICON data_input
       Returns a materialized dataframe containing rows of this table.

       Arguments:
       - max_rows: specifies the maximum number of rows to read.
    @max_rows Rows_To_Read.default_widget
    read : Rows_To_Read -> Table
    read self (max_rows : Rows_To_Read = ..First_With_Warning 1000) =
        if self.internal_columns.is_empty then Error.throw (Illegal_Argument.Error "Cannot create a table with no columns.") else
            preprocessed = case max_rows of
                Rows_To_Read.All_Rows -> self
                Rows_To_Read.First n -> self.limit n
                Rows_To_Read.First_With_Warning n -> self.limit n+1

            sql = preprocessed.to_sql
            column_types = preprocessed.internal_columns.map .sql_type_reference
            materialized_table = self.connection.read_statement sql column_types . catch SQL_Error sql_error->
                Error.throw (self.connection.dialect.get_error_mapper.transform_custom_errors sql_error)

            warnings_builder = Builder.new
            expected_types = self.columns.map .value_type
            actual_types = materialized_table.columns.map .value_type
            expected_types.zip actual_types expected_type-> actual_type->
                if expected_type == actual_type then Nothing else
                    if self.connection.dialect.get_type_mapping.should_warn_on_materialize expected_type actual_type then
                        warnings_builder.append (Inexact_Type_Coercion.Warning expected_type actual_type)

            result = max_rows.attach_warning materialized_table
            Problem_Behavior.Report_Warning.attach_problems_before warnings_builder.to_vector result

    ## PRIVATE
       Creates a query corresponding to this table.
    to_select_query : Query
    to_select_query self =
        cols = self.internal_columns.map (c -> [c.name, c.expression])
        assert cols.not_empty
        Query.Select cols self.context

    ## ICON convert
       Returns an SQL statement that will be used for materializing this table.
    to_sql : SQL_Statement
    to_sql self = self.connection.dialect.generate_sql self.to_select_query

    ## ALIAS column types, field info, metadata
       GROUP Standard.Base.Metadata
       ICON metadata
       Returns a Table describing this table's contents.

       The table lists all columns, counts of non-null items and value types of
       each column.
    column_info : Table
    column_info self =
        cols = self.internal_columns
        count_query =
            ## Performing a subquery is the most robust way to handle both
               regular columns and aggregates.
               Naively wrapping each column in a `COUNT(...)` will not
               always work as aggregates cannot be nested.
            setup = self.context.as_subquery self.name [self.internal_columns]
            new_ctx = Context.for_subquery setup.subquery
            new_columns = setup.new_columns.first.map column->
                [column.name, SQL_Expression.Operation "COUNT" [column.expression]]
            query = Query.Select new_columns new_ctx
            self.connection.dialect.generate_sql query
        count_table = self.connection.read_statement count_query
        counts = if cols.is_empty then [] else count_table.columns.map c-> c.at 0
        type_mapping = self.connection.dialect.get_type_mapping
        types = cols.map col->
            type_mapping.sql_type_to_value_type col.sql_type_reference.get
        Table.new [["Column", cols.map .name], ["Items Count", counts], ["Value Type", types]]

    ## PRIVATE

       Helper to create columns from internal columns.

       Arguments:
       - internal: The internal column to use for creating a column.
    make_column : Internal_Column -> DB_Column
    make_column self internal =
        DB_Column.Value internal.name self.connection internal.sql_type_reference internal.expression self.context

    ## PRIVATE
    columns_helper : Table_Column_Helper
    columns_helper self =
        Table_Helpers.Table_Column_Helper.Value self.columns self.internal_columns self.make_column self .read

    ## PRIVATE
    column_naming_helper : Column_Naming_Helper
    column_naming_helper self = self.connection.base_connection.column_naming_helper

    ## PRIVATE

       Returns a copy of this table with updated internal columns.

       Arguments:
       - columns: The columns with which to update this table.
    updated_columns : Vector Internal_Column -> DB_Table
    updated_columns self internal_columns = DB_Table.Value self.name self.connection internal_columns self.context

    ## PRIVATE

       Returns a copy of this table with updated context.

       Arguments:
       - ctx: The new context for this table.
    updated_context : Context -> DB_Table
    updated_context self ctx = DB_Table.Value self.name self.connection self.internal_columns ctx

    ## PRIVATE

       Returns a copy of this table with updated context and columns.

       Arguments:
       - ctx: The new context for this table.
       - internal_columns: The new columns to include in the table.
       - subquery: A boolean indicating whether the operation should be wrapped
         in a subquery. This is a simple workaround for operations which may be
         affected by further operations if not wrapped. For example, a group-by
         may need to be wrapped in this way if a filter is to be performed on it
         later on. Ideally, this should be done only on demand, if the
         subsequent operation needs it and operations like join should try to
         avoid nesting subqueries without necessity. However, for now, for
         simplicity, we are always wrapping brittle operations. This may be
         revised in the future, to generate better and more concise SQL code.
    updated_context_and_columns : Context -> Vector Internal_Column -> Boolean -> DB_Table
    updated_context_and_columns self ctx internal_columns subquery=False = case subquery of
        True ->
            setup = ctx.as_subquery self.name [internal_columns]
            new_ctx = Context.for_subquery setup.subquery
            new_columns = setup.new_columns.first
            DB_Table.Value self.name self.connection new_columns new_ctx
        False ->
            DB_Table.Value self.name self.connection internal_columns ctx

    ## PRIVATE
       Nests a table as a subquery, using `updated_context_and_columns`, which
       causes its columns to be referenced as names rather than expressions.
    as_subquery : DB_Table
    as_subquery self = self.updated_context_and_columns self.context self.internal_columns subquery=True

    ## PRIVATE
       Checks if this table is a 'trivial query'.

       A trivial query is a result of `connection.query` that has not been
       further processed. If there are any columns that are added or removed, or
       any other operations like join or aggregate are performed, the resulting
       table is no longer trivial.

       Some operations, like writing to tables, require their target to be a
       trivial query.

       Arguments:
       - fail_if_not_found: If `True`, a `Table_Not_Found` error is raised if the
         table does not exist in the database. Otherwise, `False` is returned.
    is_trivial_query self (fail_if_not_found : Boolean = True) -> Boolean ! Table_Not_Found =
        case self.context.from_spec of
            From_Spec.Table internal_table_name _ _ ->
                if self.name != internal_table_name then False else
                    trivial_counterpart = self.connection.query (SQL_Query.Table_Name self.name)
                    # If the table spec seems trivial, but the underlying table does not exist, we propagate the Table_Not_Found error.
                    check_context_and_columns =
                        if self.context != trivial_counterpart.context then False else
                           column_descriptor internal_column = [internal_column.name, internal_column.expression]
                           my_columns = self.internal_columns.map column_descriptor
                           trivial_columns = trivial_counterpart.internal_columns.map column_descriptor
                           my_columns == trivial_columns
                    if fail_if_not_found then trivial_counterpart.if_not_error check_context_and_columns else
                        if trivial_counterpart.is_error then False else check_context_and_columns
            _ -> False

    ## PRIVATE
       Provides a simplified text representation for display in the REPL and errors.
    to_text : Text
    to_text self = "(Database Table "+self.name.to_text+")"

    ## ALIAS export, save, output, to_file
       GROUP Standard.Base.Output
       ICON data_output
       This function writes the table into a file.

       The specific behavior of the various `File_Format`s is specified below.

       Arguments:
       - path: The path to the output file.
       - format: The format of the file.
         If `Auto_Detect` is specified; the provided file determines the
         specific type and configures it appropriately. Details of this type are
         below.
       - on_existing_file: Specified how to handle if the file already exists.
       - match_columns: Specifies how to match columns against an existing file.
         If `Match_Columns.By_Name` - the columns are mapped by name against an
         existing file. If there is a mismatch, then a `Column_Name_Mismatch`
         error is raised.
         If `Match_Columns.By_Position` - the columns are mapped by position
         against an existing file. If there is a mismatch, then a
         `Column_Count_Mismatch` error is raised.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default. The specific issues depend on the `File_Format`
         argument.

       Returns:
       - If an unsupported `File_Format` is specified, an
         `Illegal_Argument` is raised.
       - If the path to the parent location cannot be found or the filename is
         invalid, a `File_Error.Not_Found` is raised.
       - If another IO error occurs, such as access denied, an
         `File_Error.IO_Error` is raised.
       - If appending and the columns do not match, a `Column_Count_Mismatch` is
         raised.
       - Other specific errors or warnings that can be raised depend on the
         format argument.
       - Otherwise, the file is loaded following the rules of the format
         parameter.

       ? `File_Format` write behaviors

         - `Auto_Detect`: The file format is determined by the provided file.
         - `Bytes` and `Plain_Text`: The Table does not support these types in
            the `write` function. If passed as format, an
            `Illegal_Argument` is raised. To write out the table as plain
            text, the user needs to call the `Text.from Table` method and then
            use the `Text.write` function.

       > Example
         Write a database table to a CSV file.

             import Standard.Examples
             from Standard.Database import all

             example_to_csv =
                 connection = Database.connect (SQLite.From_File (File.new "db.sqlite"))
                 table = connection.query (SQL_Query.Table_Name "Table")
                 table.write (enso_project.data / "example_csv_output.csv")
    @path (Widget.Text_Input display=Display.Always)
    @format Widget_Helpers.write_table_selector
    write : Writable_File -> File_Format -> Existing_File_Behavior -> Match_Columns -> Problem_Behavior -> Nothing ! Column_Count_Mismatch | Illegal_Argument | File_Error
    write self path:Writable_File format=Auto_Detect on_existing_file:Existing_File_Behavior=..Backup match_columns:Match_Columns=..By_Name on_problems:Problem_Behavior=..Report_Warning =
        # TODO This should ideally be done in a streaming manner, or at least respect the row limits.
        self.read.write path format on_existing_file match_columns on_problems


    ## GROUP Standard.Base.Output
       ICON data_output
       Creates a Data Link that will act as a view into the query represented by
       this table.
    @on_existing_file (Existing_File_Behavior.widget include_backup=False include_append=False)
    save_as_data_link self destination (on_existing_file:Existing_File_Behavior = ..Error) =
        DB_Data_Link_Helpers.save_table_as_data_link self destination on_existing_file

    ## ALIAS fill missing, if_nothing
       GROUP Standard.Base.Values
       ICON table_clean

       Returns a new table where missing values in the specified columns have
       been replaced with the provided default(s).

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - default: The value to replace missing values with. If this argument
         is a column, the value from `default` at the corresponding position
         will be used. If this argument is `Previous_Value`, the missing values
         will be replaced with the previous value in the column. Note that the
         first rows may stay `Nothing` if they do not have a previous value to
         use.

       > Example
         Fill missing values in two columns with the value 20.5.

             fill_nothing = table.fill_nothing ["col0", "col1"] 20.5
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    @default make_fill_nothing_default_widget
    fill_nothing : Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type -> DB_Column | Column_Ref | Expression | Previous_Value | Any -> DB_Table
    fill_nothing self (columns : Vector | Text | Integer | Regex | By_Type) default =
        resolved_default = (self:Table_Ref).resolve default
        transformer col = col.fill_nothing resolved_default
        Table_Helpers.replace_columns_with_transformed_columns self columns transformer

    ## ALIAS fill empty, if_empty
       GROUP Standard.Base.Values
       ICON table_clean

       Returns a new column where empty Text values have been replaced with the
       provided default.

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - default: The value to replace empty values with. If this argument
         is a column, the value from `default` at the corresponding position
         will be used. If this argument is `Previous_Value`, the empty values
         will be replaced with the previous value in the column. Note that the
         first rows may stay empty if they do not have a previous value to use.

       > Example
         Fill empty values in two columns with the value "hello".

             fill_empty = table.fill_empty ["col0", "col1"] "hello"
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    @default (self-> Widget_Helpers.make_fill_default_value_selector (self.select_columns (..By_Type ..Char)) value_types=Value_Type.Char add_nothing=True)
    fill_empty : Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type -> DB_Column | Column_Ref | Expression | Previous_Value | Any -> DB_Table
    fill_empty self (columns : Vector | Text | Integer | Regex | By_Type) default =
        resolved_default = (self:Table_Ref).resolve default
        transformer col = col.fill_empty resolved_default
        Table_Helpers.replace_columns_with_transformed_columns self columns transformer

    ## GROUP Standard.Base.Text
       ICON column_add
       Replaces the first, or all occurrences of `term` with `new_text` in each
       row of the specified column. If `term` is empty, the function returns the
       table unchanged.

       This method follows the exact replacement semantics of `Text.replace`.

       If regex is used the replacement string can contain references to groups
       matched. The following syntaxes are supported:
           $0: the entire match string
           $&: the entire match string
           $n: the nth group
           $&lt;foo&gt;: Named group `foo`

       The exact syntax of the regular expression is dependent on the database
       engine.

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - term: The term to find. Can be `Text`, `Regex`, or a `Column` of
         strings.
       - replacement: The text to replace matches with.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - only_first: If True, only replace the first match.

       > Example
         Replace dashes with underscores.

             table.text_replace ["Input"] "-" "_"

       > Example
         Remove leading and trailing spaces from cells.

             table.text_replace ["Input"] "^\s*(.*?)\s*$".to_regex "$1"

       > Example
         Replace texts in quotes with parentheses.

             table.text_replace ["Input"] '"(.*?)"'.to_regex '($1)'
    @columns (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    @term (Widget_Helpers.make_column_ref_by_name_selector add_regex=True add_text=True add_named_pattern=True)
    @new_text (Widget_Helpers.make_column_ref_by_name_selector add_text=True)
    text_replace : Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type -> Text | DB_Column | Column_Ref | Expression | Regex -> Text | DB_Column | Column_Ref | Expression -> Case_Sensitivity -> Boolean -> DB_Column
    text_replace self columns:(Vector (Integer | Text | Regex | By_Type) | Text | Integer | Regex | By_Type) (term : Text | DB_Column | Column_Ref | Expression | Regex = "") (new_text : Text | DB_Column | Column_Ref | Expression = "") case_sensitivity:Case_Sensitivity=..Sensitive only_first:Boolean=False =
        table_ref = Table_Ref.from self
        resolved_term = table_ref.resolve term
        resolved_new_text = table_ref.resolve new_text
        transformer col = col.text_replace resolved_term resolved_new_text case_sensitivity only_first
        Table_Helpers.replace_columns_with_transformed_columns self columns transformer

    ## GROUP Standard.Base.Text
       ICON column_add
       Applies the specified cleansings to the text in each row of the specified columns

       Arguments:
       - from: The column(s) to cleanse.
       - remove: A vector of the text cleanings to remove from the text. The text cleansings are
           applied in the order they are provided. The same text cleansing can be used multiple
           times. The text cleansings are:
             - ..Leading_Whitespace: Removes all whitespace from the start of the string.
             - ..Trailing_Whitespace: Removes all whitespace from the end of the string.
             - ..Duplicate_Whitespace: Removes all duplicate whitespace from the string replacing it with the first whitespace character of the duplicated block.
             - ..All_Whitespace: Removes all whitespace from the string.
             - ..Newlines: Removes all newline characters from the string. Line Feed and Carriage Return characters are considered newlines.
             - ..Leading_Numbers: Removes all numbers from the start of the string.
             - ..Trailing_Numbers: Removes all numbers from the end of the string.
             - ..Non_ASCII: Removes all non-ascii characters from the string.
             - ..Tabs: Removes all tab characters from the string.
             - ..Letters: Removes all letters from the string.
             - ..Numbers: Removes all numbers characters from the string.
             - ..Punctuation: Removes all characters in the set ,.!?():;'" from the string.
             - ..Symbols: Removes anything that isn't letters, numbers or whitespace from the string.

       > Example
         Remove leading and trailing spaces from cells.

             table.text_cleanse ["Input"] [..Leading_Whitespace, ..Trailing_Whitespace]
    @from (Widget_Helpers.make_column_name_multi_selector add_regex=True add_by_type=True)
    @remove make_data_cleanse_vector_selector
    text_cleanse : Vector (Integer | Text | Regex | By_Type) -> Vector Named_Pattern -> DB_Table
    text_cleanse self from:(Vector (Integer | Text | Regex | By_Type)) remove =
        Feature.Text_Cleanse.if_supported_else_throw self.connection.dialect "text_cleanse" <|
            transformer col = col.text_cleanse remove
            Table_Helpers.replace_columns_with_transformed_columns self from transformer

    ## ALIAS cumulative, count, sum, total, minimum, maximum, sum, mean, product, variance, standard deviation
       GROUP Standard.Base.Values
       ICON data_input
       Adds a new column to the table with a running calculation.

       Arguments:
       - statistic: The running statistic to calculate.
       - of: The existing column to run the statistic over.
       - as: The name of the new column.
       - set_mode: Specifies the expected behaviour in regards to existing
         column with the same name.
       - group_by: Specifies the columns to group by. The running statistic is
         calculated separately for each group. By default, all rows are treated as
         a single group.
       - order_by: Specifies the columns to order by. Defaults to the order of
         the rows in the table. The running statistic is calculated according to the
         specified ordering.

       ? Ordering of rows

         Note that the ordering of rows from the original table is preserved in
         all cases. The grouping and ordering settings affect how the running statistic is
         calculated for each row, but the order of the rows itself is
         not changed by this operation.

       ! Error Conditions

         - If the columns specified in `group_by` or `order_by` are not present
           in the table, a `Missing_Input_Columns` error is raised.
         - If the column with the same name as provided by `as` already exists,
           a `Duplicate_Output_Column_Names` problem is reported and the
           existing column is renamed to avoid the clash.
         - If grouping on floating point numbers, a `Floating_Point_Equality`
           problem is reported.
    @group_by Widget_Helpers.make_column_name_multi_selector
    @order_by Widget_Helpers.make_order_by_selector
    @of Widget_Helpers.make_column_name_selector
    running : Statistic -> (Text | Integer) -> Text -> Set_Mode -> Vector (Text | Integer | Regex) | Text | Integer | Regex -> Vector (Text | Sort_Column) | Text -> Problem_Behavior -> Table
    running self (statistic:Statistic=..Count) (of:(Text | Integer)=0) (as:Text='') (set_mode:Set_Mode=..Add) (group_by:(Vector | Text | Integer | Regex)=[]) (order_by:(Vector | Text)=[]) (on_problems:Problem_Behavior=..Report_Warning) =
        _ = [statistic, of, as, set_mode, group_by, order_by, on_problems]
        Error.throw (Unsupported_Database_Operation.Error "running")


## PRIVATE

   Creates a Table out of a connection, name and list of column names.

   Arguments:
   - connection: The connection to a database.
   - table_name: The name of the table to get.
   - columns: List of columns to fetch. Each column is represented by a pair of
     column name and its expected SQL Type.
   - ctx: The context to use for the table.
   - on_problems: The behavior to use when problems are encountered.
make_table : Connection -> Text -> Vector -> Context -> Problem_Behavior -> DB_Table
make_table connection table_name columns ctx on_problems =
    if columns.is_empty then Error.throw (Illegal_State.Error "Unexpectedly attempting to create a Database Table with no columns. This is a bug in the Database library.") else
        problem_builder = Problem_Builder.new
        column_names_validator = connection.base_connection.column_naming_helper.create_unique_name_strategy
        cols = columns.map p->
            raw_name = p.first
            sql_type = p.second
            # We ensure that the name used in the Enso table is a valid name for Enso column and is unique, possibly changing the input name slightly.
            enso_name = column_names_validator.make_unique raw_name
            # The expression keeps the original 'raw' name coming from the database.
            expression = SQL_Expression.Column table_name raw_name
            Internal_Column.Value enso_name (SQL_Type_Reference.from_constant sql_type) expression
        problem_builder.report_unique_name_strategy column_names_validator
        # We do not want to stop the table from being fetched, so we report the issues as warnings.
        problem_builder.attach_problems_before on_problems <|
            DB_Table.Value table_name connection cols ctx

## PRIVATE
   By default, join on the first column, unless it's a cross join, in which
   case there are no join conditions.
default_join_condition : DB_Table -> Join_Kind | Join_Kind_Cross -> Join_Condition
default_join_condition table join_kind = case join_kind of
    Join_Kind_Cross -> []
    _ -> [Join_Condition.Equals table.column_names.first]

## PRIVATE
Table.from (that:DB_Table) =
    _ = [that]
    Error.throw (Illegal_Argument.Error "This operation requires the data to be in-memory, materialize the table using `.read`.")

## PRIVATE
DB_Table.from (that:Table) =
    _ = [that]
    Error.throw (Illegal_Argument.Error "Currently cross-backend operations are not supported. Either materialize the other table using `.read` or upload the table into the database using `.select_into_database_table`.")

## PRIVATE
Table_Ref.from (that:DB_Table) = Table_Ref.Value that

## PRIVATE
    The largest dataset that can be used to make a literal table, expressed in number of elements.
MAX_LITERAL_ELEMENT_COUNT = 256

## PRIVATE
make_literal_table connection column_vectors column_names alias =
    Runtime.assert (column_vectors.length == column_names.length) "column_vectors and column_names must have the same length"

    # Assume the columns are all the same length; if not, it will be an error anyway.
    total_size = if column_vectors.is_empty || column_vectors.at 0 . is_empty then 0 else
        column_vectors.length * (column_vectors.at 0 . length)

    if total_size == 0 then Error.throw (Illegal_Argument.Error "Vectors cannot be empty") else
        if total_size > MAX_LITERAL_ELEMENT_COUNT then Error.throw (Illegal_Argument.Error "Too many elements for table literal ("+total_size.to_text+"): materialize a table into the database instead") else
            type_mapping = connection.dialect.get_type_mapping
            from_spec = From_Spec.Literal_Values column_vectors column_names alias
            context = Context.for_subquery from_spec

            infer_type_from_database new_expression =
                SQL_Type_Reference.new connection context new_expression

            internal_columns = 0.up_to column_vectors.length . map i->
                column_vector = column_vectors.at i
                column_name = column_names.at i

                value_type = Value_Type_Helpers.find_common_type_for_arguments column_vector.to_vector
                sql_type = case value_type of
                   Nothing -> SQL_Type.null
                   _ -> type_mapping.value_type_to_sql value_type Problem_Behavior.Ignore
                type_ref = SQL_Type_Reference.from_constant sql_type
                sql_expression = SQL_Expression.Column alias column_name
                base_column = Internal_Column.Value column_name type_ref sql_expression

                needs_cast = value_type.is_nothing.not && connection.dialect.needs_literal_table_cast value_type
                if needs_cast.not then base_column else
                    connection.dialect.make_cast base_column sql_type infer_type_from_database

            DB_Table.Value alias connection internal_columns context
