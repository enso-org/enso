from Standard.Base import all
import Standard.Base.Errors.Common.No_Such_Method
import Standard.Base.Errors.Deprecated.Deprecated
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

import Standard.Table.Internal.Aggregate_Column_Helper
import Standard.Table.Internal.Aggregate_Column_Helper.Internal_Order_By_Column_Reference
import Standard.Table.Internal.Problem_Builder.Problem_Builder
from Standard.Table import Aggregate_Column
from Standard.Table.Aggregate_Column.Aggregate_Column import all
from Standard.Table.Errors import Floating_Point_Equality, No_Output_Columns

import project.DB_Table.DB_Table
import project.Dialect.Dialect
import project.Internal.Common.Row_Number_Helpers
import project.Internal.DB_Wrapped_Error.DB_Wrapped_Error
import project.Internal.IR.Context.Context
import project.Internal.IR.Internal_Column.Internal_Column
import project.Internal.IR.SQL_Expression.SQL_Expression
import project.Internal.SQL_Type_Reference.SQL_Type_Reference
from project.Errors import Unsupported_Database_Operation

## PRIVATE
   Creates an `Internal_Column` that will represent the computed aggregate.

   Arguments:
   - table: The table owning the columns used in the aggregation.
   - aggregate: The description of the aggregation to compute.
   - as: The name for the created column.
   - dialect: The dialect of the database to generate the SQL for.
   - infer_return_type: A function that takes 3 arguments (name of the
     operation, list of input columns and a raw SQL IR Expression) and returns
     the inferred type for the aggregation.
   - problem_builder: A `Problem_Builder` instance used for reporting warnings.
make_aggregate_column : DB_Table -> Aggregate_Column -> Text -> Dialect -> (Text -> Vector -> SQL_Expression -> SQL_Type_Reference) -> Problem_Builder -> Internal_Column
make_aggregate_column table aggregate as dialect infer_return_type problem_builder -> Internal_Column =
    simple_aggregate op_kind columns =
        expression = dialect.cast_op_type op_kind columns (SQL_Expression.Operation op_kind (columns.map c->c.expression))
        sql_type_ref = infer_return_type op_kind columns expression
        Internal_Column.Value as sql_type_ref expression

    aggregate_with_order_by op_kind column order_by =
        order_bys = order_by.map sc->
            effective_ordering = if sc.column.value_type.is_text then Text_Ordering.Default else Nothing
            dialect.prepare_order_descriptor sc.column.as_internal sc.direction effective_ordering
        expression = SQL_Expression.Operation op_kind [column.expression]+order_bys
        sql_type_ref = infer_return_type op_kind [column] expression
        Internal_Column.Value as sql_type_ref expression

    dialect.check_aggregate_support aggregate . if_not_error <| case aggregate of
        Aggregate_Column.Group_By c _ ->
            Internal_Column.Value as c.sql_type_reference c.expression
        Aggregate_Column.Count _ -> simple_aggregate "COUNT_ROWS" []
        Aggregate_Column.Count_Distinct columns _ ignore_nothing -> if columns.is_empty then Error.throw (Illegal_Argument.Error "Count_Distinct must have at least one column.") else
            case ignore_nothing of
                True -> simple_aggregate "COUNT_DISTINCT" columns
                False -> simple_aggregate "COUNT_DISTINCT_INCLUDE_NULL" columns
        Aggregate_Column.Count_Not_Nothing c _ -> simple_aggregate "COUNT" [c]
        Aggregate_Column.Count_Nothing c _ -> simple_aggregate "COUNT_IS_NULL" [c]
        Aggregate_Column.Count_Not_Empty c _ -> simple_aggregate "COUNT_NOT_EMPTY" [c]
        Aggregate_Column.Count_Empty c _ -> simple_aggregate "COUNT_EMPTY" [c]
        Aggregate_Column.Percentile p c _ ->
            op_kind = "PERCENTILE"
            expression = SQL_Expression.Operation op_kind [SQL_Expression.Literal p.to_text, c.expression]
            sql_type_ref = infer_return_type op_kind [c] expression
            Internal_Column.Value as sql_type_ref expression
        Aggregate_Column.Mode c _ ->
            col = table.make_column c
            if col.value_type.is_floating_point then
                problem_builder.report_other_warning (Floating_Point_Equality.Error as)
            simple_aggregate "MODE" [c]
        Aggregate_Column.First c _ ignore_nothing order_by -> case is_non_empty_selector order_by of
            False -> throw_ordering_required "First"
            True ->
                op = case ignore_nothing of
                    False -> "FIRST"
                    True -> "FIRST_NOT_NULL"
                aggregate_with_order_by op c order_by
        Aggregate_Column.Last c _ ignore_nothing order_by -> case is_non_empty_selector order_by of
            False -> throw_ordering_required "Last"
            True ->
                op = case ignore_nothing of
                    False -> "LAST"
                    True -> "LAST_NOT_NULL"
                aggregate_with_order_by op c order_by
        Aggregate_Column.Maximum c _ -> simple_aggregate "MAX" [c]
        Aggregate_Column.Minimum c _ -> simple_aggregate "MIN" [c]
        Aggregate_Column.Shortest c _ -> simple_aggregate "SHORTEST" [c]
        Aggregate_Column.Longest c _ -> simple_aggregate "LONGEST" [c]
        Aggregate_Column.Standard_Deviation c _ population -> case population of
            True -> simple_aggregate "STDDEV_POP" [c]
            False -> simple_aggregate "STDDEV_SAMP" [c]
        Aggregate_Column.Concatenate c _ separator prefix suffix quote_char ->
            base_args = [c.expression, SQL_Expression.Constant separator, SQL_Expression.Constant prefix, SQL_Expression.Constant suffix]
            op_kind = case quote_char.is_empty of
                True -> "CONCAT"
                False -> "CONCAT_QUOTE_IF_NEEDED"
            effective_args = case op_kind of
                "CONCAT_QUOTE_IF_NEEDED" ->
                    base_args+[SQL_Expression.Constant quote_char]
                "CONCAT" -> base_args
            expression = SQL_Expression.Operation op_kind effective_args
            sql_type_ref = infer_return_type op_kind [c] expression
            Internal_Column.Value as sql_type_ref expression
        Aggregate_Column.Sum c _ -> simple_aggregate "SUM" [c]
        Aggregate_Column.Average c _ -> simple_aggregate "AVG" [c]
        Aggregate_Column.Median c _ -> simple_aggregate "MEDIAN" [c]

## PRIVATE
   Implementation for the `DB_Table.aggregate` method.
aggregate table:DB_Table group_by:(Vector | Text | Integer | Regex) columns:Vector error_on_missing_columns:Boolean on_problems:Problem_Behavior =
    normalized_group_by = Vector.unify_vector_or_element group_by
    if normalized_group_by.is_empty && columns.is_empty then Error.throw (No_Output_Columns.Error "No columns specified in aggregate.") else
        ## This is a fix for #10321 - if the source query contains an ORDER BY,
           we need to push it into a subquery to not interfere with aggregations.
        base_table = if table.context.orders.not_empty then table.as_subquery else table

        validated = Aggregate_Column_Helper.prepare_aggregate_columns base_table.column_naming_helper normalized_group_by columns base_table error_on_missing_columns=error_on_missing_columns

        key_columns = validated.key_columns
        key_problems = key_columns.flat_map internal_column->
            column = base_table.make_column internal_column
            case column.value_type.is_floating_point of
                True -> [Floating_Point_Equality.Error column.name]
                False -> []
        on_problems.attach_problems_before validated.problems+key_problems <|
            resolved_aggregates = validated.valid_columns
            dialect = base_table.connection.dialect

            problem_builder = Problem_Builder.new
            # If the dialect defines `custom_build_aggregate` we will use it, falling back to the default implementation if not defined.
            aggregate_builder = Panic.catch No_Such_Method (dialect.custom_build_aggregate) _->
                default_build_aggregate make_aggregate_column dialect
            result = aggregate_builder base_table key_columns resolved_aggregates problem_builder
            new_ctx = result.first
            built_aggregates = result.second
            partitioned = built_aggregates.partition (_.is_a DB_Wrapped_Error)

            new_columns = partitioned.second
            problem_builder.attach_problems_before on_problems <|
                problems = partitioned.first.map .value
                on_problems.attach_problems_before problems <|
                    handle_no_output_columns =
                        first_problem = if problems.is_empty then Nothing else problems.first
                        Error.throw (No_Output_Columns.Error first_problem)
                    if new_columns.is_empty then handle_no_output_columns else
                        ## Subquery is needed to avoid unexpected interactions with future transformations of the Table.
                           We could design optimizations that will be able to elide it.
                        result = base_table.updated_context_and_columns new_ctx new_columns subquery=True
                        if validated.old_style.not then result else
                            Warning.attach (Deprecated.Warning "Standard.Table.Aggregate_Column.Aggregate_Column" "Group_By" "Deprecated: `Group_By` constructor has been deprecated, use the `group_by` argument instead.") result

## PRIVATE
default_build_aggregate build_aggregate dialect base_table key_columns resolved_aggregates problem_builder =
    key_expressions = key_columns.map .expression
    new_ctx = base_table.context.set_groups key_expressions
    infer_return_type = make_infer_return_type dialect base_table.connection new_ctx
    results = resolved_aggregates.map p->
        agg = p.second
        as = p.first
        result = build_aggregate base_table agg as dialect infer_return_type problem_builder
        ## If the `result` did contain an error, we catch it to be
           able to store it in a vector and then we will partition the
           created columns and failures.
        result.catch Any error->(DB_Wrapped_Error.Value error)
    Pair.new new_ctx results

## PRIVATE
make_infer_return_type dialect connection context =
    ## TODO [RW] here we will perform as many fetches as there are
       aggregate columns, but technically we could perform just one
       fetch fetching all column types - TODO we should do that. We can
       do it here by creating a builder that will gather all requests
       from the executed callbacks and create Lazy references that all
       point to a single query.
       See #6118.
    infer_from_database_callback expression =
        SQL_Type_Reference.new connection context expression
    type_mapping = dialect.get_type_mapping
    infer_return_type op_kind columns expression =
        type_mapping.infer_return_type infer_from_database_callback op_kind columns expression
    infer_return_type

## PRIVATE
   Setup for building aggregates that may require additional helper expressions.
   The expressions are evaluated in the context of the base query, for each row
   - so things like row number can be used. Then the actual aggregates are built
   in the context of a subquery that can access these additional expressions as
   fields of the parent query.

   The `create_helper_expressions` method takes one aggregate and the vector of
   key columns, and it should return a vector of expressions
   needed for a specific query, along with their name hints - these hints are
   used for generating the temporary column names - to make queries a bit easier
   to debug. Then, expressions corresponding to the requested ones (but
   transformed to refer to the subquery) are passed to `build_aggregate` as the
   third argument.

   The expressions are deduplicated - if multiple aggregations rely on the same
   expression, only one will be added for 'efficiency'.

   If no aggregation requires additional expressions, no additional subquery is
   created.
type Aggregate_With_Helper_Expressions
    ## PRIVATE
    Value (create_helper_expressions : Aggregate_Column -> Vector Internal_Column -> Vector (Pair Text SQL_Expression)) (make_aggregate : Aggregate_Column -> Text -> Vector Internal_Column -> DB_Table -> (Text -> Vector -> SQL_Expression -> SQL_Type_Reference) -> Problem_Builder -> Internal_Column)

    ## PRIVATE
       This method should be declared as result of `dialect.custom_build_aggregate` to use this setup.
    build self dialect base_table key_columns resolved_aggregates problem_builder =
        helper_expressions_for_aggregates = resolved_aggregates.map p-> self.create_helper_expressions p.second key_columns
        needed_expressions = helper_expressions_for_aggregates.flatten.distinct
        case needed_expressions.is_empty of
            # If no special expressions needed, we fallback to the `default_build_aggregate` but still use any overrides from `make_aggregate` method.
            True ->
                adapted_make_aggregate base_table aggregate as _ infer_return_type problem_builder =
                    self.make_aggregate aggregate as [] base_table infer_return_type problem_builder
                default_build_aggregate adapted_make_aggregate dialect base_table key_columns resolved_aggregates problem_builder
            False ->
                name_generator = base_table.column_naming_helper.create_unique_name_strategy
                name_generator.mark_used base_table.column_names
                helper_columns = needed_expressions.map p->
                    name = name_generator.make_unique p.first
                    Internal_Column.Value name SQL_Type_Reference.null p.second

                subquery_setup = base_table.context.as_subquery base_table.name [base_table.internal_columns, helper_columns]
                remapped_key_expressions = key_columns.map key_column->
                    subquery_setup.remap_column key_column . expression
                new_ctx = (Context.for_subquery subquery_setup.subquery).set_groups remapped_key_expressions

                # Mapping from a requested expression represented by (Pair Text SQL_Expression) to the column generated for that expression, in the subquery.
                helper_columns_mapping = Dictionary.from_vector <| needed_expressions.zip subquery_setup.new_columns.second

                # For each aggregate, we map the requested expressions to the columns generated in the subquery.
                helper_columns_for_aggregates = helper_expressions_for_aggregates.map requested_expressions->
                    requested_expressions.map helper_columns_mapping.at

                infer_return_type_in_new_context = make_infer_return_type dialect base_table.connection new_ctx
                results = resolved_aggregates.zip helper_columns_for_aggregates p-> helper_columns->
                    original_aggregate = p.second
                    as = p.first
                    updated_aggregate = map_column_inputs subquery_setup.remap_column original_aggregate
                    result = self.make_aggregate updated_aggregate as helper_columns dialect infer_return_type_in_new_context problem_builder
                    result.catch Any error->(DB_Wrapped_Error.Value error)
                Pair.new new_ctx results

## PRIVATE
   Applies a mapping to column inputs of the aggregate.
map_column_inputs f:Function aggregate_column:Aggregate_Column -> Aggregate_Column =
    update_order_by order_by = if order_by.is_nothing then Nothing else
        order_by.map x-> case x of
            Internal_Order_By_Column_Reference.Value c direction -> Internal_Order_By_Column_Reference.Value (f c) direction

    case aggregate_column of
        Group_By c as -> Group_By (f c) as
        Count as -> Count as
        Count_Distinct c as ignore_nothing ->
            Count_Distinct ((c:Vector).map f) as ignore_nothing
        Count_Not_Nothing c as -> Count_Not_Nothing (f c) as
        Count_Nothing c as -> Count_Nothing (f c) as
        Count_Not_Empty c as -> Count_Not_Empty (f c) as
        Count_Empty c as ->  Count_Empty (f c) as
        Sum c as -> Sum (f c) as
        Average c as -> Average (f c) as
        Median c as -> Median (f c) as
        Percentile p c as -> Percentile p (f c) as
        Mode c as -> Mode (f c) as
        Standard_Deviation c as population -> Standard_Deviation (f c) as population
        Concatenate c as separator prefix suffix quote_char -> Concatenate (f c) as separator prefix suffix quote_char
        First c as ignore_nothing order_by -> First (f c) as ignore_nothing (update_order_by order_by)
        Last c as ignore_nothing order_by -> Last (f c) as ignore_nothing (update_order_by order_by)
        Maximum c as -> Maximum (f c) as
        Minimum c as -> Minimum (f c) as
        Shortest c as -> Shortest (f c) as
        Longest c as -> Longest (f c) as

## PRIVATE
is_non_empty_selector v = v.is_nothing.not && v.not_empty

## PRIVATE
throw_ordering_required op_name = Error.throw (Unsupported_Database_Operation.Error ("`" + op_name + "` aggregation requires at least one `order_by` column."))
