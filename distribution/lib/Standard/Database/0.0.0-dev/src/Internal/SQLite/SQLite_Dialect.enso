from Standard.Base import all
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument
import Standard.Base.Errors.Illegal_State.Illegal_State
import Standard.Base.Runtime.Ref.Ref

import Standard.Table.Internal.Problem_Builder.Problem_Builder
from Standard.Table import Aggregate_Column, Value_Type
from Standard.Table.Aggregate_Column.Aggregate_Column import all

import project.Connection.Connection.Connection
import project.DB_Column.DB_Column
import project.DB_Table.DB_Table
import project.Dialect
import project.Internal.Aggregate_Helper
import project.Internal.Aggregate_Helper.Aggregate_With_Helper_Expressions
import project.Internal.Base_Generator
import project.Internal.Common.Database_Distinct_Helper
import project.Internal.Common.Database_Join_Helper
import project.Internal.Common.Row_Number_Helpers
import project.Internal.Error_Mapper.Error_Mapper
import project.Internal.IR.Context.Context
import project.Internal.IR.From_Spec.From_Spec
import project.Internal.IR.Internal_Column.Internal_Column
import project.Internal.IR.Order_Descriptor.Order_Descriptor
import project.Internal.IR.Query.Query
import project.Internal.IR.SQL_Expression.SQL_Expression
import project.Internal.IR.SQL_Join_Kind.SQL_Join_Kind
import project.Internal.Replace_Params.Replace_Params
import project.Internal.SQL_Type_Mapping.SQL_Type_Mapping
import project.Internal.SQL_Type_Reference.SQL_Type_Reference
import project.Internal.SQLite.SQLite_Error_Mapper.SQLite_Error_Mapper
import project.Internal.SQLite.SQLite_Type_Mapping.SQLite_Type_Mapping
import project.Internal.Statement_Setter.Statement_Setter
import project.Dialect_Flag.Dialect_Flag
import project.SQL.SQL_Builder
import project.SQL_Statement.SQL_Statement
import project.SQL_Type.SQL_Type
from project.Dialect import Temp_Table_Style
from project.Errors import SQL_Error, Unsupported_Database_Operation
from project.Feature import Feature
from project.Internal.JDBC_Connection import JDBC_Connection

## PRIVATE

   The dialect of SQLite databases.
sqlite : SQLite_Dialect
sqlite =
    SQLite_Dialect.Value make_dialect_operations

## PRIVATE

   The dialect of SQLite databases.
type SQLite_Dialect
    ## PRIVATE

       The dialect of SQLite databases.
    Value dialect_operations

    ## PRIVATE
       Name of the dialect.
    name : Text
    name self = "SQLite"

    ## PRIVATE
    to_text self = "SQLite_Dialect"

    ## PRIVATE
       A function which generates SQL code from the internal representation
       according to the specific dialect.
    generate_sql : Query -> SQL_Statement
    generate_sql self query =
        Base_Generator.generate_query self query . build

    ## PRIVATE
       Generates SQL to truncate a table.
    generate_truncate_table_sql : Text -> SQL_Builder
    generate_truncate_table_sql self table_name =
        Base_Generator.truncate_table_delete_from_style self table_name

    ## PRIVATE
       Generates SQL modifier for limiting the number of rows and its position in the query
    get_limit_sql_modifier : Integer -> Any
    get_limit_sql_modifier self limit =
        [700, SQL_Builder.code (" LIMIT " + limit.to_text)]

    ## PRIVATE
       Wraps and possibly escapes the identifier so that it can be used in a
       generated query regardless of what characters it contains.
       The quotes used will depend on the dialect.
    wrap_identifier : Text -> SQL_Builder
    wrap_identifier self identifier =
        Base_Generator.wrap_in_quotes identifier

    ## PRIVATE
       Generates a SQL expression for a table literal.
    make_table_literal : Vector (Vector Text) -> Vector Text -> Text -> SQL_Builder
    make_table_literal self vecs column_names as_name =
        values = SQL_Builder.join ", " (vecs.transpose.map (vec-> SQL_Builder.join ", " (vec.map SQL_Builder.interpolation) . paren))
        wrapped_name = self.wrap_identifier as_name
        structure = wrapped_name ++ (SQL_Builder.join ", " (column_names.map self.wrap_identifier) . paren)
        SQL_Builder.code "(WITH " ++ structure ++ " AS (VALUES " ++ values ++ ") SELECT * FROM " ++ wrapped_name ++ ") AS " ++ wrapped_name

    ## PRIVATE
       Prepares an ordering descriptor.

       One of the purposes of this method is to verify if the expected ordering
       settings are supported by the given database backend.

       Arguments:
       - internal_column: the column to order by.
       - sort_direction: the direction of the ordering.
       - text_ordering: If provided, specifies that the column should be treated
         as text values according to the provided ordering. For non-text types,
         it should be set to `Nothing`.
    prepare_order_descriptor : Internal_Column -> Sort_Direction -> Nothing | Text_Ordering -> Order_Descriptor
    prepare_order_descriptor self internal_column sort_direction text_ordering = case text_ordering of
        Nothing ->
            Order_Descriptor.Value internal_column.expression sort_direction collation=Nothing
        _ ->
            if text_ordering.sort_digits_as_numbers then Error.throw (Unsupported_Database_Operation.Error "Natural ordering") else
                case text_ordering.case_sensitivity of
                    Case_Sensitivity.Default ->
                        Order_Descriptor.Value internal_column.expression sort_direction collation=Nothing
                    Case_Sensitivity.Sensitive ->
                        Order_Descriptor.Value internal_column.expression sort_direction collation="BINARY"
                    Case_Sensitivity.Insensitive locale -> case locale == Locale.default of
                        False ->
                            Error.throw (Unsupported_Database_Operation.Error "Case insensitive ordering with custom locale")
                        True ->
                            Order_Descriptor.Value internal_column.expression sort_direction collation="NOCASE"

    ## PRIVATE
       Prepares a distinct operation.
    prepare_distinct : DB_Table -> Vector -> Case_Sensitivity -> Problem_Builder -> DB_Table
    prepare_distinct self table key_columns case_sensitivity problem_builder =
        table_name_deduplicator = table.connection.base_connection.table_naming_helper.create_unique_name_strategy
        table_name_deduplicator.mark_used table.name
        inner_table_alias = table_name_deduplicator.make_unique table.name+"_inner"
        setup = table.context.as_subquery inner_table_alias [table.internal_columns]
        new_columns = setup.new_columns.first
        column_mapping = Dictionary.from_vector <| new_columns.map c-> [c.name, c]
        new_key_columns = key_columns.map c-> column_mapping.at c.name
        type_mapping = self.get_type_mapping
        distinct_expressions = new_key_columns.map column->
            value_type = type_mapping.sql_type_to_value_type column.sql_type_reference.get
            Database_Distinct_Helper.make_distinct_expression case_sensitivity problem_builder column value_type
        new_context = Context.for_subquery setup.subquery . set_groups distinct_expressions
        table.updated_context_and_columns new_context new_columns subquery=True

    ## PRIVATE
       Returns the mapping between SQL types of this dialect and Enso
       `Value_Type`.
    get_type_mapping : SQL_Type_Mapping
    get_type_mapping self = SQLite_Type_Mapping

    ## PRIVATE
    get_statement_setter : Statement_Setter
    get_statement_setter self = Statement_Setter.default

    ## PRIVATE
    make_cast : Internal_Column -> SQL_Type -> (SQL_Expression -> SQL_Type_Reference) -> Internal_Column
    make_cast self (column : Internal_Column) (target_type : SQL_Type) (infer_result_type_from_database_callback : SQL_Expression -> SQL_Type_Reference) =
        _ = [infer_result_type_from_database_callback]
        mapping = self.get_type_mapping
        target_value_type = mapping.sql_type_to_value_type target_type
        custom_cast = make_custom_cast column target_value_type mapping
        new_expression = custom_cast.if_nothing <|
            self.make_cast_expression column target_type
        new_sql_type_reference = SQL_Type_Reference.from_constant target_type
        Internal_Column.Value column.name new_sql_type_reference new_expression

    ## PRIVATE
    make_cast_expression self column target_type =
        mapping = self.get_type_mapping
        sql_type_text = mapping.sql_type_to_text target_type
        SQL_Expression.Operation "CAST" [column.expression, SQL_Expression.Literal sql_type_text]

    ## PRIVATE
    needs_execute_query_for_type_inference : Text | SQL_Statement -> Boolean
    needs_execute_query_for_type_inference self statement =
        _ = statement
        True

    ## PRIVATE
       Specifies how the database creates temp tables.
    temp_table_style : Temp_Table_Style
    temp_table_style self = Temp_Table_Style.Temporary_Table

    ## PRIVATE
       SQLite allows mixed type columns, but we want our columns to be uniform.
       So after unifying columns with mixed types, we add a cast to ensure that.
    adapt_unified_column : Internal_Column -> Value_Type -> (SQL_Expression -> SQL_Type_Reference) -> Internal_Column
    adapt_unified_column self column approximate_result_type infer_result_type_from_database_callback =
        _ = infer_result_type_from_database_callback
        # TODO [RW] This may be revisited with #6281.
        case approximate_result_type of
            Nothing -> column
            _ ->
                sql_type = self.get_type_mapping.value_type_to_sql approximate_result_type Problem_Behavior.Ignore
                new_expression = self.make_cast_expression column sql_type
                new_sql_type_reference = SQL_Type_Reference.from_constant sql_type
                Internal_Column.Value column.name new_sql_type_reference new_expression

    ## PRIVATE
       Add an extra cast to adjust the output type of certain operations with
       certain arguments.

       It is used when the normal type inference provided by the database engine
       needs to be adjusted.

       In most cases this method will just return the expression unchanged, it
       is used only to override the type in cases where the default one that the
       database uses is not what we want.
    cast_op_type self (op_kind:Text) (args:(Vector Internal_Column)) (expression:SQL_Expression) =
        _ = [op_kind, args]
        expression

    ## PRIVATE
    prepare_fetch_types_query : SQL_Expression -> Context -> SQL_Statement
    prepare_fetch_types_query self expression context =
        _ = [expression, context]
        Panic.throw (Illegal_State.Error "Type inference by asking the Database for the expected types is not supported in SQLite since it tended to give wrong results. This should have never been called - if it was - that is a bug in the Database library.")

    ## PRIVATE
    check_aggregate_support : Aggregate_Column -> Boolean ! Unsupported_Database_Operation
    check_aggregate_support self aggregate = case aggregate of
        Group_By _ _ -> True
        Count _ -> True
        Count_Distinct columns _ _ ->
            if columns.length == 1 then True else
                unsupported "Count_Distinct on multiple columns"
        Count_Not_Nothing _ _ -> True
        Count_Nothing _ _ -> True
        Count_Not_Empty _ _ -> True
        Count_Empty _ _ -> True
        Percentile _ _ _ -> unsupported "Percentile"
        Mode _ _ -> unsupported "Mode"
        First _ _ ignore_nothing order_by ->
            if ignore_nothing then unsupported "First with ignore_nothing=True" else
                if Aggregate_Helper.is_non_empty_selector order_by . not then Aggregate_Helper.throw_ordering_required "First" else
                    True
        Last _ _ ignore_nothing order_by ->
            if ignore_nothing then unsupported "Last with ignore_nothing=True" else
                if Aggregate_Helper.is_non_empty_selector order_by . not then Aggregate_Helper.throw_ordering_required "Last" else
                    True
        Maximum _ _ -> True
        Minimum _ _ -> True
        Shortest _ _ -> unsupported "Shortest"
        Longest _ _ -> unsupported "Longest"
        Standard_Deviation _ _ _ -> True
        Concatenate _ _ _ _ _ _ -> True
        Sum _ _ -> True
        Average _ _ -> True
        Median _ _ -> unsupported "Median"

    ## PRIVATE
       Checks if an operation is supported by the dialect.
    is_operation_supported self operation:Text -> Boolean =
        self.dialect_operations.is_operation_supported operation

    ## PRIVATE
       Checks if a feature is supported by the dialect.
    is_feature_supported self feature:Feature -> Boolean =
        _ = feature
        True

    ## PRIVATE
       Checks a dialect flag
    flagged self flag:Dialect_Flag -> Boolean =
        case flag of
            Dialect_Flag.Supports_Negative_Decimal_Places -> False
            Dialect_Flag.Supports_Float_Decimal_Places -> True
            Dialect_Flag.Use_Builtin_Bankers -> False
            Dialect_Flag.Primary_Key_Allows_Nulls -> True
            Dialect_Flag.Supports_Separate_NaN -> False
            Dialect_Flag.Supports_Nested_With_Clause -> True
            Dialect_Flag.Supports_Case_Sensitive_Columns -> False

    ## PRIVATE
       The default table types to use when listing tables.
    default_table_types : Vector Text
    default_table_types self =
        ["TABLE", "VIEW", "GLOBAL TEMPORARY"]

    ## PRIVATE
    get_error_mapper : Error_Mapper
    get_error_mapper self = SQLite_Error_Mapper

    ## PRIVATE
       The dialect-dependent strategy to get the Primary Key for a given table.

       Returns `Nothing` if the key is not defined.

       Custom handling is required, because the default DatabaseMetaData
       implementation does not correctly handle temporary tables.
    fetch_primary_key : Connection -> Text -> Vector Text ! Nothing
    fetch_primary_key self connection table_name =
        wrapped_name = self.wrap_identifier table_name
        query = SQL_Builder.code "pragma table_info(" ++ wrapped_name ++ ")"
        info_table = connection.read_statement query.build
        ## The `pk` field is non-zero if the columns is part of the primary key.
           The column value indicates the position in the key.
           See: https://www.sqlite.org/pragma.html#pragma_table_info
        v = info_table.filter "pk" (>0) . sort "pk" . at "name" . to_vector
        if v.is_empty then Nothing else v

    ## PRIVATE
       Prepares metadata for an operation taking a date/time period and checks
       if the given period is supported.
    prepare_metadata_for_period : Date_Period | Time_Period -> Value_Type -> Any
    prepare_metadata_for_period self period operation_input_type =
        _ = [period, operation_input_type]
        Error.throw (Unsupported_Database_Operation.Error "Date/time operations.")

    ## PRIVATE
       Returns true if the `replace` parameters are suppoerted by this backend.
    if_replace_params_supports : Replace_Params -> Any -> Any
    if_replace_params_supports self replace_params ~action =
        if supported_replace_params.contains replace_params then action else replace_params.throw_unsupported "SQLite"

    ## PRIVATE
    value_type_for_upload_of_existing_column : DB_Column -> Value_Type
    value_type_for_upload_of_existing_column self column = column.value_type

    ## PRIVATE
    needs_literal_table_cast : Value_Type -> Boolean
    needs_literal_table_cast self value_type =
        _ = value_type
        False

    ## PRIVATE
    generate_column_for_select self base_gen expr:(SQL_Expression | Order_Descriptor | Query) name:Text -> SQL_Builder =
        base_gen.default_generate_column self expr name

    ## PRIVATE
    ensure_query_has_no_holes : JDBC_Connection -> Text -> Nothing ! Illegal_Argument
    ensure_query_has_no_holes self jdbc:JDBC_Connection raw_sql:Text =
        jdbc.ensure_query_has_no_holes raw_sql

    ## PRIVATE
       We need custom handling for First and Last, as SQLite does not support
       such aggregation functions out of the box, so instead we create a row
       number column in a subquery and compute the result based on that.
    custom_build_aggregate self =
        create_row_number_for orderings key_columns =
            order_descriptors = orderings.map o-> self.prepare_order_descriptor o.column o.direction text_ordering=Nothing
            key_expressions_for_orderings = key_columns.map .expression
            expression = Row_Number_Helpers.make_row_number 1 1 order_descriptors key_expressions_for_orderings
            Pair.new "row-number" expression

        create_count_for key_columns =
            key_expressions_for_orderings = key_columns.map .expression
            ## Even if key_expressions_for_orderings is empty, we still use COUNT_OVER_PARTITION to make it a window
               function and not an aggregate (we want to return all rows, not a single aggregated one).
            expression = SQL_Expression.Operation "COUNT_OVER_PARTITION" key_expressions_for_orderings
            Pair.new "group-count" expression

        create_helper_expressions aggregate_column key_columns =
            case aggregate_column of
                Aggregate_Column.First _ _ _ order_by ->
                    if self.check_aggregate_support aggregate_column . is_error then [] else
                        [create_row_number_for order_by key_columns]
                Aggregate_Column.Last _ _ _ order_by ->
                    if self.check_aggregate_support aggregate_column . is_error then [] else
                        [create_row_number_for order_by key_columns, create_count_for key_columns]
                _ -> []

        make_aggregate aggregate_column as helper_expressions base_table infer_return_type problem_builder =
            case aggregate_column of
                Aggregate_Column.First _ _ _ _ -> self.check_aggregate_support aggregate_column . if_not_error <|
                    Runtime.assert (Aggregate_Helper.is_non_empty_selector aggregate_column.order_by)
                    Runtime.assert (helper_expressions.length == 1)
                    row_number = helper_expressions.first
                    op = case aggregate_column.ignore_nothing of
                        False -> "FIRST"
                        True  -> Panic.throw (Illegal_State.Error "First with ignore_nothing=True is not supported by SQLite.")
                    # We just inherit the type of the source column, as the FIRST/LAST element of a column should have the same type.
                    sql_type_reference = aggregate_column.column.sql_type_reference
                    Internal_Column.Value as sql_type_reference (SQL_Expression.Operation op [aggregate_column.column.expression, row_number.expression])
                Aggregate_Column.Last _ _ _ _ -> self.check_aggregate_support aggregate_column . if_not_error <|
                    Runtime.assert (Aggregate_Helper.is_non_empty_selector aggregate_column.order_by)
                    Runtime.assert (helper_expressions.length == 2)
                    row_number = helper_expressions.first
                    count = helper_expressions.second
                    op = case aggregate_column.ignore_nothing of
                        False -> "LAST"
                        True  -> Panic.throw (Illegal_State.Error "Last with ignore_nothing=True is not supported by SQLite.")
                    # We just inherit the type of the source column, as the FIRST/LAST element of a column should have the same type.
                    sql_type_reference = aggregate_column.column.sql_type_reference
                    Internal_Column.Value as sql_type_reference (SQL_Expression.Operation op [aggregate_column.column.expression, row_number.expression, count.expression])
                _ -> Aggregate_Helper.make_aggregate_column base_table aggregate_column as self infer_return_type problem_builder

        setup = Aggregate_With_Helper_Expressions.Value create_helper_expressions make_aggregate
        setup.build self


## PRIVATE
make_dialect_operations =
    text = [starts_with, contains, ends_with, make_case_sensitive, ["REPLACE", replace], left, right]+concat_ops+trim_ops
    counts = [agg_count_is_null, agg_count_empty, agg_count_not_empty, ["COUNT_DISTINCT", agg_count_distinct], ["COUNT_DISTINCT_INCLUDE_NULL", agg_count_distinct_include_null]]
    stats = [agg_stddev_pop, agg_stddev_samp]
    arith_extensions = [is_inf, is_finite, floating_point_div, mod_op]
    other = [["RUNTIME_ERROR", make_runtime_error_op]]

    bool = [bool_or]
    my_mappings = text + counts + stats + arith_extensions + bool + other + first_last_aggregators
    Base_Generator.base_dialect_operations . extend_with my_mappings

## PRIVATE
unsupported name =
    Error.throw (Unsupported_Database_Operation.Error name)

## PRIVATE
agg_count_is_null = Base_Generator.lift_unary_op "COUNT_IS_NULL" arg->
    SQL_Builder.code "COALESCE(SUM(" ++ arg.paren ++ " IS NULL), 0)"

## PRIVATE
agg_count_empty = Base_Generator.lift_unary_op "COUNT_EMPTY" arg->
    SQL_Builder.code "COALESCE(SUM((" ++ arg.paren ++ " IS NULL) OR (" ++ arg.paren ++ " == '')), 0)"

## PRIVATE
agg_count_not_empty = Base_Generator.lift_unary_op "COUNT_NOT_EMPTY" arg->
    SQL_Builder.code "COALESCE(SUM((" ++ arg.paren ++ " IS NOT NULL) AND (" ++ arg.paren ++ " != '')), 0)"

## PRIVATE
agg_stddev_pop = Base_Generator.lift_unary_op "STDDEV_POP" arg->
    sum_of_squares = SQL_Builder.code "SUM(" ++ arg.paren ++ "*" ++ arg.paren ++ ")"
    square_of_sums = SQL_Builder.code "SUM(" ++ arg ++ ") * SUM(" ++ arg ++ ")"
    n = SQL_Builder.code "CAST(COUNT(" ++ arg ++ ") AS REAL)"
    var = SQL_Builder.code "(" ++ sum_of_squares ++ " - (" ++ square_of_sums ++ " / " ++ n ++ ")) / " ++ n
    SQL_Builder.code "SQRT(" ++ var ++ ")"

## PRIVATE
agg_stddev_samp = Base_Generator.lift_unary_op "STDDEV_SAMP" arg->
    sum_of_squares = SQL_Builder.code "SUM(" ++ arg.paren ++ "*" ++ arg.paren ++ ")"
    square_of_sums = SQL_Builder.code "SUM(" ++ arg ++ ") * SUM(" ++ arg ++ ")"
    n = SQL_Builder.code "CAST(COUNT(" ++ arg ++ ") AS REAL)"
    var = SQL_Builder.code "(" ++ sum_of_squares ++ " - (" ++ square_of_sums ++ " / " ++ n ++ ")) / (" ++ n ++ " - 1)"
    SQL_Builder.code "SQRT(" ++ var ++ ")"

## PRIVATE
   This is a prototype that doesn't work correctly. Left for reference for
   future implementation.
first_last_aggregators =
    count_over_partition args =
        partition = if args.is_empty then SQL_Builder.code "" else
            SQL_Builder.code "PARTITION BY " ++ SQL_Builder.join ", " args
        SQL_Builder.code "COUNT(*) OVER (" ++ partition ++ ")"

    first_agg args =
        if args.length != 2 then
            Panic.throw (Illegal_Argument.Error "FIRST requires exactly 2 arguments.")
        column = args.first
        row_number = args.second
        # The MAX here is only used as an aggregating variant of COALESCE - it will select the single non-null value.
        SQL_Builder.code "MAX(CASE WHEN " ++ row_number ++ " == 1 THEN " ++ column ++ " END)"

    last_agg args =
        if args.length != 3 then
            Panic.throw (Illegal_Argument.Error "LAST requires exactly 3 arguments.")
        column = args.at 0
        row_number = args.at 1
        count = args.at 2
        # The MAX here is only used as an aggregating variant of COALESCE - it will select the single non-null value.
        SQL_Builder.code "MAX(CASE WHEN " ++ row_number ++ " == " ++ count ++ " THEN " ++ column ++ " END)"

    # FIRST_NOT_NULL and LAST_NOT_NULL are currently not implemented.
    [["COUNT_OVER_PARTITION", count_over_partition], ["FIRST", first_agg], ["LAST", last_agg]]

## PRIVATE
concat_ops =
    make_raw_concat_expr expr separator =
        SQL_Builder.code "group_concat(" ++ expr ++ ", " ++ separator ++ ")"
    concat = Base_Generator.make_concat make_raw_concat_expr make_contains_expr
    [["CONCAT", concat (has_quote=False)], ["CONCAT_QUOTE_IF_NEEDED", concat (has_quote=True)]]

## PRIVATE
trim_ops =
    whitespace = "' ' || CHAR(9) || CHAR(10) || CHAR(13)"
    make_fn fn_name = Base_Generator.lift_binary_op fn_name input-> chars-> case chars of
            Nothing -> SQL_Builder.code fn_name+"(" ++ input ++ ", " ++ whitespace ++ ")"
            _ ->
                case chars.is_constant of
                    True ->
                        const = chars.fragments.vec.first.object
                        if const.is_nothing || const.is_empty then SQL_Builder.code fn_name+"(" ++ input ++ ", " ++ whitespace ++ ")" else
                            SQL_Builder.code fn_name+"(" ++ input ++ ", " ++ chars ++ ")"
                    False ->
                        SQL_Builder.code "CASE WHEN " ++ chars ++ " IS NULL OR " ++ chars ++ " == '' THEN " ++ fn_name ++ "(" ++ input ++ ") ELSE " ++ fn_name ++ "(" ++ input ++ ", " ++ chars ++ ") END"
    [make_fn "TRIM", make_fn "LTRIM", make_fn "RTRIM"]


## PRIVATE
is_inf = Base_Generator.lift_unary_op "IS_INF" arg->
    (arg ++ " in (9e999, -9e999)").paren

## PRIVATE
is_finite = Base_Generator.lift_unary_op "IS_FINITE" arg->
    (arg ++ " not in (9e999, -9e999)").paren

## PRIVATE
agg_count_distinct args = case args.length == 1 of
    True -> SQL_Builder.code "COUNT(DISTINCT (" ++ args.first ++ "))"
    False -> Error.throw (Illegal_Argument.Error "COUNT_DISTINCT supports only single arguments in SQLite.")

## PRIVATE
agg_count_distinct_include_null args = case args.length == 1 of
    True ->
        arg = args.first
        count = SQL_Builder.code "COUNT(DISTINCT " ++ arg ++ ")"
        all_nulls_case = SQL_Builder.code "CASE WHEN COUNT(CASE WHEN " ++ arg ++ "IS NULL THEN 1 END) > 0 THEN 1 ELSE 0 END"
        count ++ " + " ++ all_nulls_case
    False -> Error.throw (Illegal_Argument.Error "COUNT_DISTINCT supports only single arguments in SQLite.")

## PRIVATE
starts_with = Base_Generator.lift_binary_op "STARTS_WITH" str-> sub->
    res = str ++ " GLOB (" ++ sub ++ " || '*')"
    res.paren

## PRIVATE
ends_with = Base_Generator.lift_binary_op "ENDS_WITH" str-> sub->
    res = str ++ " GLOB ('*' || " ++ sub ++ ")"
    res.paren

## PRIVATE
make_case_sensitive = Base_Generator.lift_unary_op "MAKE_CASE_SENSITIVE" arg->
    SQL_Builder.code "((" ++ arg ++ ") COLLATE BINARY)"

## PRIVATE
make_contains_expr expr substring =
    SQL_Builder.code "instr(" ++ expr ++ ", " ++ substring ++ ") > 0"

## PRIVATE
contains = Base_Generator.lift_binary_op "CONTAINS" make_contains_expr

## PRIVATE
left = Base_Generator.lift_binary_op "LEFT" str-> n->
    SQL_Builder.code "substr(" ++ str ++ ", 0, " ++ n ++ " + 1)"

## PRIVATE
right = Base_Generator.lift_binary_op "RIGHT" str-> n->
    SQL_Builder.code "substr(" ++ str ++ ", -" ++ n ++ ", " ++ n ++ ")"

## PRIVATE
bool_or = Base_Generator.lift_unary_op "BOOL_OR" arg->
    SQL_Builder.code "max(" ++ arg ++ ")"

## PRIVATE
floating_point_div = Base_Generator.lift_binary_op "/" x-> y->
    SQL_Builder.code "CAST(" ++ x ++ " AS REAL) / CAST(" ++ y ++ " AS REAL)"

## PRIVATE
mod_op = Base_Generator.lift_binary_op "MOD" x-> y->
    x ++ " - FLOOR(CAST(" ++ x ++ " AS REAL) / CAST(" ++ y ++ " AS REAL)) * " ++ y

## PRIVATE
supported_replace_params : Hashset Replace_Params
supported_replace_params =
    e = [Replace_Params.Value Text Case_Sensitivity.Default False, Replace_Params.Value Text Case_Sensitivity.Sensitive False, Replace_Params.Value Text Case_Sensitivity.Default True, Replace_Params.Value Text Case_Sensitivity.Sensitive True, Replace_Params.Value Text Case_Sensitivity.Insensitive True]
    Hashset.from_vector e

## PRIVATE
replace : Vector SQL_Builder -> Any -> SQL_Builder
replace args metadata =
    input = args.at 0
    pattern = args.at 1
    replacement = args.at 2

    replace_params = metadata.at 1

    expression = case replace_params.input_type == Text || replace_params.input_type == DB_Column of
        True ->
            ## To use REGEXP_REPLACE on a non-regex, we have to escape it.
            case replace_params.only_first of
                False -> case replace_params.case_sensitivity of
                    Case_Sensitivity.Insensitive _ -> Nothing
                    _ ->
                        SQL_Builder.code "REPLACE(" ++ input ++ ", " ++ pattern ++ ", " ++ replacement ++ ")"
                True -> case replace_params.case_sensitivity of
                    Case_Sensitivity.Insensitive _ ->
                        replace_only_first False input pattern replacement
                    _ ->
                        replace_only_first True input pattern replacement
        False -> Nothing
    case expression of
        Nothing -> replace_params.throw_unsupported "SQLite"
        _ -> expression

## PRIVATE
replace_only_first case_sensitive t p r =
    search_string = if case_sensitive then t else
        SQL_Builder.code "LOWER(" ++ t ++ ")"
    instr = SQL_Builder.code "INSTR(" ++ search_string ++ ", " ++ p ++ ")"
    prefix = SQL_Builder.code "SUBSTR(" ++ t ++ ", 1," ++ instr ++ "-1)"
    suffix = SQL_Builder.code "SUBSTR(" ++ t ++ "," ++ instr ++ "+LENGTH(" ++ p ++ "))"
    concatenation = prefix ++ " || " ++ r ++ " || " ++ suffix
    SQL_Builder.code "CASE WHEN " ++ instr ++ "= 0 THEN " ++ t ++ " ELSE " ++ concatenation ++ "END"

## PRIVATE
   It will return `Nothing` if the type does not require custom logic.
make_custom_cast column target_value_type type_mapping =
    result = Ref.new Nothing
    column_type =
        type_mapping.sql_type_to_value_type column.sql_type_reference.get
    if target_value_type.is_text && (column_type == Value_Type.Boolean) then
        expr = SQL_Expression.Operation "IIF" [column.expression, SQL_Expression.Literal "'true'", SQL_Expression.Literal "'false'"]
        result.put expr

    if (target_value_type == Value_Type.Boolean) && column_type.is_text then
        lower = SQL_Expression.Operation "FOLD_CASE" [column.expression]
        is_true = SQL_Expression.Operation "==" [lower, SQL_Expression.Literal "'true'"]
        is_false = SQL_Expression.Operation "==" [lower, SQL_Expression.Literal "'false'"]
        expr = SQL_Expression.Operation "CASE" [is_true, SQL_Expression.Literal "TRUE", is_false, SQL_Expression.Literal "FALSE", SQL_Expression.Literal "NULL"]
        result.put expr

    result.get

## PRIVATE
   The RUNTIME_ERROR operation should allow the query to compile fine and it
   will not prevent it from running if the branch including this operation is
   not taken. But if the branch is computed, it should ensure the query fails.

   This query never returns a value, so its type should be polymorphic. However,
   that is not possible - so currently the SQLite dialect just does not handle
   inferring a type for it. Thus, it should only be used in places that will not
   need client-side type inference (e.g. WHERE clause is ok).
   This can be changed in the future, if needed.
make_runtime_error_op arguments =
    if arguments.length != 2 then
        Panic.throw (Illegal_Argument.Error "RUNTIME_ERROR takes exactly 2 arguments (error message and a variable to ensure deferred execution).")
    error_message = arguments.at 0
    variable_to_defer = arguments.at 1
    # We have to ensure that the implementation of SQLite that we use does not have a MATCH function defined which would make the code below succeed.
    SQL_Builder.code "match('[ENSO INVARIANT VIOLATED: '||" ++ error_message ++ "||'] ', " ++ variable_to_defer ++ ")"
