from Standard.Base import all
import Standard.Base.Data.Array_Proxy.Array_Proxy
import Standard.Base.Data.Filter_Condition as Filter_Condition_Module
import Standard.Base.Data.Index_Sub_Range as Index_Sub_Range_Module
import Standard.Base.Data.Time.Errors.Date_Time_Format_Parse_Error
import Standard.Base.Data.Vector.No_Wrap
import Standard.Base.Errors.Common.Additional_Warnings
import Standard.Base.Errors.Common.Incomparable_Values
import Standard.Base.Errors.Common.Index_Out_Of_Bounds
import Standard.Base.Errors.Common.No_Such_Method
import Standard.Base.Errors.Common.Out_Of_Memory
import Standard.Base.Errors.Common.Type_Error
import Standard.Base.Errors.Deprecated.Deprecated
import Standard.Base.Errors.File_Error.File_Error
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument
import Standard.Base.Errors.Unimplemented.Unimplemented
import Standard.Base.Runtime.Context
import Standard.Base.System.File.Generic.Writable_File.Writable_File
from Standard.Base.Metadata import Display, make_single_choice, Widget
from Standard.Base.Widget_Helpers import make_delimiter_selector, make_format_chooser

import project.Aggregate_Column.Aggregate_Column
import project.Blank_Selector.Blank_Selector
import project.Column.Column
import project.Column_Ref.Column_Ref
import project.Constants.Previous_Value
import project.Constants.Report_Unmatched
import project.Data_Formatter.Data_Formatter
import project.Delimited.Delimited_Format.Delimited_Format
import project.Expression.Expression
import project.Expression.Expression_Error
import project.Extensions.Table_Conversions
import project.Internal.Add_Row_Number
import project.Internal.Aggregate_Column_Helper
import project.Internal.Column_Naming_Helper.Column_Naming_Helper
import project.Internal.Constant_Column.Constant_Column
import project.Internal.Delimited_Reader
import project.Internal.Delimited_Writer
import project.Internal.Expand_Objects_Helpers
import project.Internal.Java_Problems
import project.Internal.Join_Helpers
import project.Internal.Lookup_Helpers
import project.Internal.Lookup_Helpers.Lookup_Column
import project.Internal.Parse_Values_Helper
import project.Internal.Problem_Builder.Problem_Builder
import project.Internal.Replace_Helpers
import project.Internal.Split_Tokenize
import project.Internal.Table_Helpers
import project.Internal.Table_Helpers.Table_Column_Helper
import project.Internal.Table_Ref.Table_Ref
import project.Internal.Widget_Helpers
import project.Join_Condition.Join_Condition
import project.Join_Kind.Join_Kind
import project.Match_Columns as Match_Columns_Helpers
import project.Match_Columns.Match_Columns
import project.Position.Position
import project.Prefix_Name.Prefix_Name
import project.Row.Row
import project.Set_Mode.Set_Mode
import project.Simple_Expression.Simple_Expression
import project.Sort_Column.Sort_Column
import project.Value_Type.Auto
import project.Value_Type.Value_Type
from project.Column import get_item_string, make_storage_builder_for_type, normalize_string_for_display
from project.Errors import all
from project.Internal.Filter_Condition_Helpers import make_filter_column
from project.Internal.Lookup_Helpers import make_java_lookup_column_description
from project.Internal.Rows_View import Rows_View

polyglot java import java.util.UUID
polyglot java import org.enso.base.ObjectComparator
polyglot java import org.enso.table.data.index.MultiValueIndex
polyglot java import org.enso.table.data.mask.OrderMask
polyglot java import org.enso.table.data.table.Column as Java_Column
polyglot java import org.enso.table.data.table.join.conditions.Between as Java_Join_Between
polyglot java import org.enso.table.data.table.join.conditions.Equals as Java_Join_Equals
polyglot java import org.enso.table.data.table.join.conditions.EqualsIgnoreCase as Java_Join_Equals_Ignore_Case
polyglot java import org.enso.table.data.table.join.lookup.LookupJoin
polyglot java import org.enso.table.data.table.Table as Java_Table
polyglot java import org.enso.table.data.table.TableToXml as Java_TableToXml
polyglot java import org.enso.table.error.NonUniqueLookupKey
polyglot java import org.enso.table.error.NullValuesInKeyColumns
polyglot java import org.enso.table.error.TooManyColumnsException
polyglot java import org.enso.table.error.UnmatchedRow
polyglot java import org.enso.table.parsing.problems.ParseProblemAggregator

## Represents a column-oriented table data structure.
type Table
    ## GROUP Standard.Base.Constants
       ICON data_output
       Creates a new table from a vector of `[name, items]` pairs.

       Arguments:
       - columns: The `[name, items]` pairs to construct a new table from.

       > Example
         Create a new table with the given columns.

             from Standard.Table import Table

             example_new =
                 first_column = ["count", [1, 2, 3]]
                 second_column = ["is_valid", [True, False, True]]
                 Table.new [first_column, second_column]
    new : Vector (Vector | Column) -> Table
    new columns =
        invalid_input_shape =
            Error.throw (Illegal_Argument.Error "Each column must be represented by a pair whose first element is the column name and the second element is a vector of elements that will constitute that column, or an existing column.")
        cols = columns.map on_problems=No_Wrap c->
            case c of
                v : Vector ->
                    if v.length != 2 then invalid_input_shape else
                        Column.from_vector (v.at 0) (v.at 1) . java_column
                Column.Value java_col -> java_col
                _ -> invalid_input_shape
        Panic.recover Illegal_Argument <|
            if cols.is_empty then
                Panic.throw (Illegal_Argument.Error "Cannot create a table with no columns.")

            if cols.distinct .getName . length != cols.length then
                Panic.throw (Illegal_Argument.Error "Column names must be distinct.")

            mismatched_size_column = cols.find if_missing=Nothing c->
                c.getSize != cols.first.getSize
            if mismatched_size_column.is_nothing.not then
                msg = "All columns must have the same row count, but the column [" + mismatched_size_column.getName + "] has " + mismatched_size_column.getSize.to_text + " rows, while the column [" + cols.first.getName + "] has " + cols.first.getSize.to_text + " rows."
                Panic.throw (Illegal_Argument.Error msg)

            Table.Value (Java_Table.new cols)

    ## GROUP Standard.Base.Constants
       ICON data_input
       Creates a new table from a vector of column names and a vector of vectors
       specifying row contents.

       Arguments:
       - header: A list of texts specifying the column names
       - rows: A vector of vectors, specifying the contents of each table row. The
         length of each element of `rows` must be equal in length to `header`.

       > Example
         Create a table with 3 columns, named `foo`, `bar`, and `baz`, containing
         `[1, 2, 3]`, `[True, False, True]`, and `['a', 'b', 'c']`, respectively.

             from Standard.Table import Table

             example_from_rows =
                 header = [ 'foo' , 'bar' , 'baz' ]
                 row_1 =  [ 1     , True  , 'a'   ]
                 row_2 =  [ 2     , False , 'b'   ]
                 row_3 =  [ 3     , True  , 'c'   ]
                 Table.from_rows header [row_1, row_2, row_3]
    @header (Widget.Vector_Editor item_editor=Widget.Text_Input item_default='"Column"')
    from_rows : Vector -> Vector -> Table
    from_rows header rows =
        columns = header.map_with_index i-> name-> [name, rows.map (_.at i)]
        Table.new columns

    ## PRIVATE

       A table.

       Arguments:
       - java_table: The internal java representation of the table.
    Value java_table

    ## PRIVATE
       ADVANCED
       Returns a text containing an ASCII-art table displaying this data.

       Arguments:
       - show_rows: the number of initial rows that should be displayed.
       - format_terminal: whether ANSI-terminal formatting should be used

       > Example
         Convert the table to a pretty-printed representation.

             import Standard.Examples

             example_display = Examples.inventory_table.display
    display : Integer -> Boolean -> Text
    display self show_rows=10 format_terminal=False =
        cols = Vector.from_polyglot_array self.java_table.getColumns
        col_names = ([""] + cols.map .getName) . map normalize_string_for_display
        col_vals = cols.map .getStorage
        num_rows = self.row_count
        display_rows = num_rows.min show_rows
        rows = Vector.new display_rows row_num->
            cols = col_vals.map col->
                if col.isNothing row_num then "Nothing" else get_item_string col row_num
            [row_num.to_text] + cols
        table = print_table col_names rows 1 format_terminal
        if num_rows - display_rows <= 0 then table else
            missing = '\n\u2026 and ' + (num_rows - display_rows).to_text + ' hidden rows.'
            table + missing

    ## PRIVATE
       ADVANCED
       Prints an ASCII-art table with this data to the standard output.

       Arguments:
       - show_rows: the number of initial rows that should be displayed.

       > Example
         Convert the table to a pretty-printed representation and print it to
         the console.

             import Standard.Examples

             example_print = Examples.inventory_table.print
    print self show_rows=10 =
        IO.println (self.display show_rows format_terminal=True)
        IO.println ''

    ## PRIVATE
       Converts this table into a JS_Object.

       > Example
         Convert a table to a corresponding JavaScript JS_Object representation.

             import Standard.Examples

             example_to_json = Examples.inventory_table.to_js_object
    to_js_object : JS_Object
    to_js_object self =
        cols = self.columns
        rows = 0.up_to self.row_count . map row->
            vals_kv = cols.map col-> [col.name, col.at row]
            JS_Object.from_pairs vals_kv
        rows

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns the column with the given name.

       Arguments:
       - selector: The name or index of the column being looked up.

       > Example
         Get the names of all of the items from the shop inventory.

             import Standard.Examples

             example_at = Examples.inventory_table.at "item_name"

       > Example
         Get the last column.

             import Standard.Examples

             example_at = Examples.inventory_table.at -1
    @selector Widget_Helpers.make_column_name_selector
    at : Text | Integer -> Column ! No_Such_Column | Index_Out_Of_Bounds
    at self selector=0 = case selector of
        _ : Integer ->
            java_columns = Vector.from_polyglot_array self.java_table.getColumns
            Column.Value (java_columns.at selector)
        _ -> self.get selector (Error.throw (No_Such_Column.Error selector))

    ## ICON select_column
       Returns the column with the given name or index.

       Arguments:
       - selector: The name or index of the column being looked up.
       - if_missing: The value to use if the selector isn't present.

       > Example
         Get the names of all of the items from the shop inventory.

             import Standard.Examples

             example_at = Examples.inventory_table.get "item_name"

       > Example
         Get the last column.

             import Standard.Examples

             example_at = Examples.inventory_table.get -1
    @selector Widget_Helpers.make_column_name_selector
    get : Text | Integer -> Any -> Column | Any
    get self selector=0 ~if_missing=Nothing =
        java_column = case selector of
            _ : Integer -> Vector.from_polyglot_array self.java_table.getColumns . get selector
            _ : Text -> self.java_table.getColumnByName selector
            _ -> Error.throw (Illegal_Argument.Error "expected 'selector' to be either a Text or an Integer, but got "+(Meta.get_simple_type_name selector)+".")
        if java_column.is_nothing then if_missing else Column.Value java_column

    ## ALIAS cell value, get cell
       GROUP Standard.Base.Selections
       ICON local_scope4
       Gets a value from the table.

       Arguments:
       - selector: The name or index of the column.
       - index: The index of the value to get within the column.
       - if_missing: The value to use if the selector isn't present.

       > Example
         Get the names of all of the items from the shop inventory.

             import Standard.Examples

             example_at = Examples.inventory_table.get_value "item_name" 4
    @selector Widget_Helpers.make_column_name_selector
    @index (t-> Widget.Numeric_Input minimum=0 maximum=t.row_count-1)
    get_value : Text | Integer -> Integer -> Any -> Any
    get_value self selector=0 index=0 ~if_missing=Nothing =
        col = self.get selector if_missing=Nothing
        if Nothing == col then if_missing else col.get index if_missing

    ## GROUP Standard.Base.Selections
       ICON select_column
       Gets the first column.
    first_column : Column ! Index_Out_Of_Bounds
    first_column self = self.at 0

    ## GROUP Standard.Base.Selections
       ICON select_column
       Gets the second column
    second_column : Column ! Index_Out_Of_Bounds
    second_column self = self.at 1

    ## GROUP Standard.Base.Selections
       ICON select_column
       Gets the last column
    last_column : Column ! Index_Out_Of_Bounds
    last_column self = self.at -1

    ## GROUP Standard.Base.Metadata
       ICON metadata
       Returns the number of columns in the table.
    column_count : Integer
    column_count self = self.java_table.getColumns.length

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with a chosen subset of columns, as specified by the
       `columns`, from the input table. Any unmatched input columns will be
       dropped from the output.

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - case_sensitivity: Controls whether to be case sensitive when matching
         column names.
       - reorder: By default, or if set to `False`, columns in the output will
         be in the same order as in the input table. If `True`, the order in the
         output table will match the order in the columns list. If a column is
         matched by multiple selectors in reorder mode, it will be placed at
         the position of the first one matched.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.

       > Example
         Select columns by name.

             table.select_columns ["bar", "foo"]

       > Example
         Select columns using names passed as a Vector.

             table.select_columns ["bar", "foo"]

       > Example
         Select columns matching a regular expression.

             table.select_columns "foo.+".to_regex case_sensitivity=Case_Sensitivity.Insensitive

       > Example
         Select the first two columns and the last column, moving the last one to front.

             table.select_columns [-1, 0, 1] reorder=True
    @columns Widget_Helpers.make_column_name_multi_selector
    select_columns :  Vector (Integer | Text | Regex) | Text | Integer | Regex -> Boolean -> Case_Sensitivity -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns
    select_columns self (columns : (Vector | Text | Integer | Regex) = [self.columns.first.name]) (reorder:Boolean=False) (case_sensitivity=Case_Sensitivity.Default) (error_on_missing_columns:Boolean=True) (on_problems:Problem_Behavior=Report_Warning) =
        new_columns = self.columns_helper.select_columns columns case_sensitivity reorder error_on_missing_columns on_problems
        Table.new new_columns

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the chosen set of columns filtered by the type
       of the column.

       Arguments:
       - types: The types of columns to select.
       - strict: If `True`, only columns with exactly the specified types will
         be selected. If `False`, columns with related types will also be
         selected (i.e. ignore size, precision).
    @types Widget_Helpers.make_value_type_vector_selector
    select_by_type : Vector Value_Type -> Boolean -> Table
    select_by_type self types:Vector strict:Boolean=False =
        new_columns = self.columns_helper.select_by_type types strict
        Table.new new_columns

    ## ALIAS drop_columns
       GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the chosen set of columns, as specified by the
       `columns`, removed from the input table. Any unmatched input columns will
       be kept in the output. Columns are returned in the same order as in the
       input.

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - case_sensitivity: Controls whether to be case sensitive when matching
         column names.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `False`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is reported according to the `on_problems`
           setting, unless `error_on_missing_columns` is set to `True`, in which
           case it is raised as an error.

       > Example
         Remove columns with given names.

             table.remove_columns ["bar", "foo"]

       > Example
         Remove columns using names passed as a Vector.

             table.remove_columns ["bar", "foo"]

       > Example
         Remove columns matching a regular expression.

             table.remove_columns "foo.+".to_regex case_sensitivity=Case_Sensitivity.Insensitive

       > Example
         Remove the first two columns and the last column.

             table.remove_columns [-1, 0, 1]
    @columns Widget_Helpers.make_column_name_vector_selector
    remove_columns :  Vector (Integer | Text | Regex) | Text | Integer | Regex -> Case_Sensitivity -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns
    remove_columns self (columns : (Vector | Text | Integer | Regex) = [self.columns.first.name]) (case_sensitivity=Case_Sensitivity.Default) (error_on_missing_columns:Boolean=False) (on_problems:Problem_Behavior=Report_Warning) =
        new_columns = self.columns_helper.remove_columns columns case_sensitivity error_on_missing_columns=error_on_missing_columns on_problems=on_problems
        Table.new new_columns

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the chosen set of columns filtering out based
       on the type of the column.

       Arguments:
       - types: The types of columns to remove.
       - strict: If `True`, only columns with exactly the specified types will
         be removed. If `False`, columns with related types will also be
         removed (i.e. ignore size, precision).
    @types Widget_Helpers.make_value_type_vector_selector
    remove_by_type : Vector Value_Type -> Boolean -> Table
    remove_by_type self types:Vector strict:Boolean=False =
        new_columns = self.columns_helper.remove_by_type types strict
        Table.new new_columns

    ## ALIAS select_missing_columns, select_na
       GROUP Standard.Base.Selections
       ICON select_column

       Select columns which are either all blank or contain blank values. If no
       rows are present, all columns are considered blank.

       Arguments:
       - when: By default, only columns consisting of all blank cells are
         selected. If set to Blank_Selector.Any_Cell, columns with one or
         more blank values are selected.
       - treat_nans_as_blank: specifies whether `Number.nan` is considered as
         blank. By default, it is not.

       ? Blank values
         Blank values are `Nothing`, `""` and depending on setting `Number.nan`.

       > Example
         Select completely blank columns from a table.

             table.select_blank_columns
    select_blank_columns : Blank_Selector -> Boolean -> Table ! No_Output_Columns
    select_blank_columns self (when:Blank_Selector = Blank_Selector.All_Cells) (treat_nans_as_blank : Boolean = False) =
        new_columns = self.columns_helper.select_blank_columns_helper when treat_nans_as_blank
        Table.new new_columns

    ## ALIAS drop_missing_columns, drop_na
       GROUP Standard.Base.Selections
       ICON select_column

       Remove columns which are either all blank or contain blank values. If no
       rows are present, all columns are considered blank.

       Arguments:
       - when By default, only columns consisting of all blank cells are
         selected. If set to Blank_Selector.Any_Cell, columns with one or more blank values are
         selected.
       - treat_nans_as_blank: specified whether `Number.nan` is considered as
         blank. By default, it is not.

       ? Blank values
         Blank values are `Nothing`, `""` and depending on setting `Number.nan`.

       > Example
         Remove completely blank columns from a table.

             table.remove_blank_columns
    remove_blank_columns : Blank_Selector -> Boolean -> Table ! No_Output_Columns
    remove_blank_columns self (when:Blank_Selector = Blank_Selector.All_Cells) (treat_nans_as_blank : Boolean = False) =
        new_columns = self.columns_helper.select_blank_columns_helper when treat_nans_as_blank invert_selection=True
        Table.new new_columns

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the specified selection of columns moved to
       either the start or the end in the specified order.

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - position: Specifies how to place the selected columns in relation to
         the remaining columns which were not matched by `columns` (if any).
       - case_sensitivity: Controls whether to be case sensitive when matching
         column names.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `False`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is reported according to the `on_problems`
           setting, unless `error_on_missing_columns` is set to `True`, in which
           case it is raised as an error.

       > Example
         Move a column with a specified name to back.

             table.reorder_columns ["foo"] position=Position.After_Other_Columns

       > Example
         Move columns using names passed as a Vector.

             table.reorder_columns ["bar", "foo"] position=Position.After_Other_Columns

       > Example
         Move columns matching a regular expression to front, keeping columns matching "foo.+" before columns matching "b.*".

             table.reorder_columns "foo.+".to_regex case_sensitivity=Case_Sensitivity.Insensitive

       > Example
         Swap the first two columns.

             table.reorder_columns [1, 0] position=Position.Before_Other_Columns

       > Example
         Move the first column to back.

             table.reorder_columns [0] position=Position.After_Other_Columns
    @columns Widget_Helpers.make_column_name_vector_selector
    reorder_columns : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Position -> Case_Sensitivity -> Boolean -> Problem_Behavior -> Table ! Missing_Input_Columns
    reorder_columns self (columns : (Vector | Text | Integer | Regex) = [self.columns.first.name]) (position:Position=Position.Before_Other_Columns) (case_sensitivity=Case_Sensitivity.Default) (error_on_missing_columns:Boolean=False) (on_problems:Problem_Behavior=Report_Warning) =
        new_columns = self.columns_helper.reorder_columns columns position case_sensitivity error_on_missing_columns on_problems
        Table.new new_columns

    ## GROUP Standard.Base.Selections
       ICON select_column
       Returns a new table with the columns sorted by name according to the
       specified sort method. By default, sorting will be according to
       case-sensitive ascending order based on the normalized Unicode ordering.

       Arguments:
       - order: Whether sorting should be in ascending or descending order.
       - text_ordering: The sort methodology to use.

       > Example
         Sort columns according to the default ordering.

             table.sort_columns

       > Example
         Sort columns according to the natural case-insensitive ordering.

             table.sort_columns text_ordering=(Text_Ordering.Case_Insensitive sort_digits_as_numbers=True)

       > Example
         Sort columns in descending order.

             table.reorder_columns Sort_Direction.Descending
    sort_columns : Sort_Direction -> Text_Ordering -> Table
    sort_columns self order=Sort_Direction.Ascending text_ordering=Text_Ordering.Default =
        new_columns = Table_Helpers.sort_columns self.columns order text_ordering
        Table.new new_columns

    ## GROUP Standard.Base.Metadata
       ICON table_edit
       Returns a new table with the columns renamed based on either a mapping
       from the old name to the new or a positional list of new names.

       Arguments:
       - column_map: Mapping from old column names to new or a vector of new
         column names to apply by position. `Regex` objects can be used
         within the mapping to do pattern based renaming.
       - case_sensitivity: Controls whether to be case sensitive when matching
         column names.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If any of the new names are invalid, an `Invalid_Column_Names`
           error is raised.
         - Other problems are reported according to the `on_problems` setting:
             - If a column is matched by two selectors resulting in a different
               name mapping, a `Ambiguous_Column_Rename`.
             - If in `By_Position` mode and more names than columns are
               provided, a `Too_Many_Column_Names_Provided`.
             - If any of the new names clash either with existing names or each
               other, a `Duplicate_Output_Column_Names`.

       > Example
         Rename the "Alpha" column to "Beta"

              table.rename_columns (Map.from_vector [["Alpha", "Beta"]])

       > Example
         Rename the last column to "LastColumn"

              table.rename_columns (Map.from_vector [[-1, "LastColumn"]])

       > Example
         Rename the "Alpha" column to "Beta" and last column to "LastColumn"

              table.rename_columns (Map.from_vector [["Alpha", "Beta"], [-1, "LastColumn"]])

       > Example
         Rename the first column to "FirstColumn"

              table.rename_columns ["FirstColumn"]

       > Example
         Add a prefix to all column names.

              table.rename_columns (table.columns.map c-> "prefix_" + c.name)

       > Example
         For all columns starting with the prefix `name=`, replace it with `key:`.

              table.rename_columns (Map.from_vector [["name=(.*)".to_regex, "key:$1"]])
    @column_map Widget_Helpers.make_rename_name_vector_selector
    rename_columns : Map (Text | Integer | Regex) Text | Vector Text | Vector Vector -> Case_Sensitivity -> Boolean -> Problem_Behavior -> Table ! Missing_Input_Columns | Ambiguous_Column_Rename | Too_Many_Column_Names_Provided | Invalid_Column_Names | Duplicate_Output_Column_Names
    rename_columns self (column_map:(Map | Vector)=["Column"]) (case_sensitivity:Case_Sensitivity=Case_Sensitivity.Default) (error_on_missing_columns:Boolean=True) (on_problems:Problem_Behavior=Report_Warning) =
        new_names = Table_Helpers.rename_columns self.column_naming_helper self.columns column_map case_sensitivity error_on_missing_columns on_problems
        Warning.with_suspended new_names names->
            Table.new (self.columns.map c-> c.rename (names.at c.name))

    ## GROUP Standard.Base.Metadata
       ICON table_edit
       Returns a new table with the columns renamed based on entries in the
       first row.

       Arguments:
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         The following problems can occur:
         - If any of the new names are invalid, an
           `Invalid_Column_Names`.
         - If any of the new names clash either with existing names or each
           other, a Duplicate_Output_Column_Names.

       > Example
         Rename the column based on the first row

              table.use_first_row_as_names
    use_first_row_as_names : Problem_Behavior -> Table
    use_first_row_as_names self (on_problems=Report_Warning) =
        new_names = self.first_row.to_vector.map c->
            if c.is_nothing then Nothing else c.to_text
        unique = self.column_naming_helper.create_unique_name_strategy
        new_names_cleaned = unique.make_all_unique new_names
        problem_builder = Problem_Builder.new
        problem_builder.report_unique_name_strategy unique
        problem_builder.attach_problems_before on_problems <|
            self.drop (First 1) . rename_columns new_names_cleaned on_problems=on_problems

    ## ALIAS group by, summarize
       GROUP Standard.Base.Calculations
       ICON sigma

       Aggregates the rows in a table using `group_by` columns.
       The columns argument specifies which additional aggregations to perform
       and to return.

       Arguments:
       - group_by: Vector of column identifiers to group by. These will be
         included at the start of the resulting table. If no columns are
         specified a single row will be returned with the aggregate columns.
       - columns: Vector of `Aggregate_Column` specifying the aggregated table.
         Expressions can be used within the aggregate column to perform more
         complicated calculations.
       - error_on_missing_columns: Specifies if a missing columns in aggregates
         should result in an error regardless of the `on_problems` settings.
         Defaults to `False`, meaning that problematic aggregate will not be
         included in the result and the problem reported according to the
         `on_problems` setting.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column index is out of range, a `Missing_Input_Columns` is
           reported according to the `on_problems` setting, unless
           `error_on_missing_columns` is set to `True`, in which case it is
           raised as an error. Problems resolving `group_by` columns are
           reported as dataflow errors regardless of these settings, as a
           missing grouping will completely change semantics of the query.
         - If a column selector is given as a `Text` and it does not match any
           columns in the input table nor is it a valid expression, an
           `Invalid_Aggregate_Column` problem is raised according to the
           `on_problems` settings (unless `error_on_missing_columns` is set to
           `True` in which case it will always be an error). Problems resolving
           `group_by` columns are reported as dataflow errors regardless of
           these settings, as a missing grouping will completely change
           semantics of the query.
         - If an aggregation fails, an `Invalid_Aggregation` dataflow error is
           raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If there are invalid column names in the output table,
             a `Invalid_Column_Names`.
           - If there are duplicate column names in the output table,
             a `Duplicate_Output_Column_Names`.
           - If grouping on or computing the `Mode` on a floating point number,
             a `Floating_Point_Equality`.
           - If when concatenating values there is an quoted delimited,
             an `Unquoted_Delimiter`
           - If there are more than 10 issues with a single column,
             an `Additional_Warnings`.

       > Example
         Count all the rows

              table.aggregate columns=[Aggregate_Column.Count]

       > Example
         Group by the Key column, count the rows

              table.aggregate ["Key"] [Aggregate_Column.Count]
    @group_by Widget_Helpers.make_column_name_vector_selector
    @columns Widget_Helpers.make_aggregate_column_vector_selector
    aggregate : Vector (Integer | Text | Regex | Aggregate_Column) | Text | Integer | Regex -> Vector Aggregate_Column -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Invalid_Aggregate_Column | Invalid_Column_Names | Duplicate_Output_Column_Names | Floating_Point_Equality | Invalid_Aggregation | Unquoted_Delimiter | Additional_Warnings
    aggregate self group_by=[] columns=[] (error_on_missing_columns=False) (on_problems=Report_Warning) =
        normalized_group_by = Vector.unify_vector_or_element group_by
        if normalized_group_by.is_empty && columns.is_empty then Error.throw (No_Output_Columns.Error "At least one column must be specified.") else
            validated = Aggregate_Column_Helper.prepare_aggregate_columns self.column_naming_helper normalized_group_by columns self error_on_missing_columns=error_on_missing_columns

            on_problems.attach_problems_before validated.problems <| Illegal_Argument.handle_java_exception <|
                java_key_columns = validated.key_columns.map .java_column
                Java_Problems.with_problem_aggregator on_problems java_problem_aggregator->
                    index = self.java_table.indexFromColumns java_key_columns java_problem_aggregator
                    new_columns = validated.valid_columns.map c->(Aggregate_Column_Helper.java_aggregator c.first c.second)
                    java_table = index.makeTable new_columns
                    if validated.old_style.not then Table.Value java_table else
                        Warning.attach (Deprecated.Warning "Standard.Table.Aggregate_Column.Aggregate_Column" "Group_By" "Deprecated: `Group_By` constructor has been deprecated, use the `group_by` argument instead.") (Table.Value java_table)

    ## ALIAS sort
       GROUP Standard.Base.Selections
       ICON order
       Sorts the rows of the table according to the specified columns and order.

       Arguments:
       - columns: The columns and order to sort the table.
       - text_ordering: The ordering method to use on text values.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If no columns have been selected for ordering,
           a `No_Input_Columns_Selected` is raised as dataflow error regardless
           of any settings.
         - If a column used for ordering contains values that cannot be
           compared, an `Incomparable_Values` error is raised.

       ? Missing Values

         Missing (`Nothing`) values are sorted as less than any other object.

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`.

             table.order_by ['Quantity']

       > Example
         Sorting `table` in descending order by the value in column `'Quantity'`.

             table.order_by [Sort_Column.Name 'Quantity' Sort_Direction.Descending]

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` for breaking ties.

             table.order_by ['Quantity', 'Rating']

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` in descending order for breaking
         ties.

             table.order_by [Sort_Column.Name 'Quantity', Sort_Column.Name 'Rating' Sort_Direction.Descending]

       > Example
         Order the table by the second column in ascending order. In case of any
         ties, break them based on the 7th column from the end of the table in
         descending order.

             table.order_by [1, Sort_Column.Index -7 Sort_Direction.Descending]

       > Example
         Sort the table by columns whose names start with letter `a`.

              table.order_by [(Sort_Column.Select_By_Name "a.*".to_regex case_sensitivity=Case_Sensitivity.Insensitive)]
    @columns Widget_Helpers.make_order_by_selector
    order_by : Vector (Text | Sort_Column) | Text -> Text_Ordering -> Boolean -> Problem_Behavior -> Table ! Incomparable_Values | No_Input_Columns_Selected | Missing_Input_Columns
    order_by self (columns = [self.columns.first.name]) text_ordering=Text_Ordering.Default error_on_missing_columns=True on_problems=Problem_Behavior.Report_Warning =
        problem_builder = Problem_Builder.new error_on_missing_columns=error_on_missing_columns types_to_always_throw=[No_Input_Columns_Selected]
        columns_for_ordering = Table_Helpers.prepare_order_by self.columns columns problem_builder
        problem_builder.attach_problems_before on_problems <|
            java_columns = columns_for_ordering.map c->c.column.java_column
            directions = columns_for_ordering.map c->c.associated_selector.direction.to_sign

            comparator = case text_ordering.sort_digits_as_numbers of
                True ->
                    txt_cmp a b = Natural_Order.compare a b text_ordering.case_sensitivity . to_sign
                    ObjectComparator.new txt_cmp
                False -> case text_ordering.case_sensitivity of
                    Case_Sensitivity.Default -> ObjectComparator.DEFAULT
                    Case_Sensitivity.Sensitive -> ObjectComparator.DEFAULT
                    Case_Sensitivity.Insensitive locale -> ObjectComparator.new False locale.java_locale

            java_table = Illegal_Argument.handle_java_exception <| Incomparable_Values.handle_errors <|
                self.java_table.orderBy java_columns directions comparator
            Table.Value java_table

    ## ALIAS deduplicate, unique
       GROUP Standard.Base.Selections
       ICON preparation
       Returns the distinct set of rows within the specified columns from the
       input table.

       When multiple rows have the same values within the specified columns, the
       first row of each such set is returned if possible, but in database
       backends any row from each set may be returned (for example if the row
       ordering is unspecified).

       For the in-memory table, the unique rows will be in the order they
       occurred in the input (this is not guaranteed for database operations).

       Arguments:
       - columns: The columns of the table to use for distinguishing the rows.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If no valid columns are selected, a `No_Input_Columns_Selected`, is
           reported as a dataflow error regardless of setting.
         - If floating points values are present in the distinct columns, a
           `Floating_Point_Equality` is reported according to the `on_problems`
           setting.
    @columns Widget_Helpers.make_column_name_vector_selector
    distinct : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Case_Sensitivity -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns | No_Input_Columns_Selected | Floating_Point_Equality
    distinct self (columns = self.column_names) case_sensitivity=Case_Sensitivity.Default error_on_missing_columns=True on_problems=Report_Warning =
        key_columns = self.columns_helper.select_columns columns Case_Sensitivity.Default reorder=True error_on_missing_columns=error_on_missing_columns on_problems=on_problems . catch No_Output_Columns _->
            Error.throw No_Input_Columns_Selected
        java_columns = key_columns.map .java_column
        text_folding_strategy = Case_Sensitivity.folding_strategy case_sensitivity
        java_table = Illegal_Argument.handle_java_exception <|
            Java_Problems.with_problem_aggregator on_problems java_aggregator->
                self.java_table.distinct java_columns text_folding_strategy java_aggregator
        Table.Value java_table

    ## GROUP Standard.Base.Conversions
       ICON convert
       Parses columns within a `Table` to a specific value type.
       By default, it looks at all `Text` columns and attempts to deduce the
       type (columns with other types are not affected).

       In the Database backends, the default formatting settings of the
       particular database are used.

       In the in-memory backend, the default parser options only parse values
       where the process is reversible (e.g., 0123 would not be converted to an
       integer as there is a leading 0). However, settings in the
       `Data_Formatter` can control this.

       Arguments:
       - columns: The columns to parse. If not specified, all text columns
         will be parsed.
       - type: The type to parse the columns to. Defaults to `Auto` meaning that
         the type will be inferred from the data. In the Database backends,
         `Auto` is not supported, so a specific type must be selected.
       - format: The formatting settings to use when parsing the columns.
         For `Date`, `Time_Of_Day` and `Date_Time`, a Java date time style
         can be used. For `Boolean`, it should be two values that represent true
         and false, separated by a `|`. Alternatively, a `Data_Formatter` can be
         passed to provide complete customisation of the formatting. If
         `Nothing` is provided, the default formatting settings of the backend
         will be used. `Nothing` is currently the only setting accepted by the
         Database backends.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a column selected for parsing is not a text column, an
           `Invalid_Value_Type` error is raised.
         - If no columns have been selected for parsing,
           a `No_Input_Columns_Selected` error is raised.
         - If some values in a column did not match the expected datatype
           format, an `Invalid_Format` problem is reported. The problematic
           cells are replaced with `Nothing`.

       ? Number Formats

         If parsing a column to a number, by default, the parser will attempt
         to find the most appropriate format for the column. This is done by
         finding the format that parses the longest set without an issue from
         the first record.

         It will try the following separators in British, German, French and
         Swiss order.

         - Thousand separators must be followed by groups of 3 numbers.
         - Scientific notation is only allowed on decimals and must be on a
           value between -10 and 10. The notation is an `E` followed by an
           integer and must be enabled on the `Data_Formatter`,

         The following formats are supported:
         - Sign (+/-) followed by Number (e.g. +1,234.56)
         - Using brackets to indicate a negative number (e.g. (1,234.56))
         - Currency symbols (if not in Auto mode) can be placed before or after
           the sign and number.
         - If using brackets, the currency symbol must be placed after the
           opening bracket.

       > Example
         Parse the first and last columns containing Yes/No values as booleans.

             table.parse columns=[0, -1] type=Value_Type.Boolean format="Yes|No"

       > Example
         Parse dates in a column in the format `yyyy-MM-dd` (the default format).

             table.parse "birthday" Value_Type.Date

       > Example
         Parse dates in a column in the format `dd/MM/yyyy`.

             table.parse "birthday" Value_Type.Date 'dd/MM/yyyy'

       > Example
         Parse all columns inferring their types, using `,` as the decimal point for numbers.

             table.parse format=(Data_Formatter.Value.with_number_formatting decimal_point=',')
    @columns Widget_Helpers.make_column_name_vector_selector
    @type Widget_Helpers.parse_type_selector
    @format (make_format_chooser include_number=False)
    parse : Vector (Text | Integer | Regex) | Text | Integer | Regex -> Value_Type | Auto -> Text | Data_Formatter -> Boolean -> Problem_Behavior -> Table
    parse self columns=(self.columns . filter (c-> c.value_type.is_text) . map .name) type=Auto format:(Text | Data_Formatter)='' error_on_missing_columns=True on_problems=Report_Warning =
        formatter = case format of
            _ : Text -> if format.is_empty then Data_Formatter.Value else Data_Formatter.Value.with_format type format
            _ : Data_Formatter -> format

        parser = formatter.make_value_type_parser type

        select_problem_builder = Problem_Builder.new error_on_missing_columns=error_on_missing_columns
        selected_columns = self.columns_helper.select_columns_helper columns Case_Sensitivity.Default True select_problem_builder
        select_problem_builder.attach_problems_before on_problems <|
            selected_column_names = case selected_columns.is_empty of
                True ->
                    no_columns_problem_behavior = case error_on_missing_columns of
                        True -> Problem_Behavior.Report_Error
                        False -> on_problems
                    no_columns_problem_behavior.attach_problem_before No_Input_Columns_Selected Map.empty
                False ->
                    Map.from_vector <| selected_columns.map c-> [c.name, True]

            new_columns = self.columns.map on_problems=No_Wrap column-> if selected_column_names.contains_key column.name . not then column else
                Value_Type.expect_text column <|
                    storage = column.java_column.getStorage
                    new_storage = Java_Problems.with_problem_aggregator on_problems java_problem_aggregator->
                        parse_problem_aggregator = ParseProblemAggregator.make java_problem_aggregator column.name type
                        parser.parseColumn storage parse_problem_aggregator
                    Column.Value (Java_Column.new column.name new_storage)
            Table.new new_columns

    ## GROUP Standard.Base.Conversions
       ICON convert
       Formats `Column`s within a `Table` using a format string,
       `Date_Time_Formatter`, or `Column` of format strings.

       Arguments:
       - columns: The columns to format. The columns can have different types,
         but all columns must be compatible with any provided `format` value.
       - format: The type-dependent format string to use to format the values.
         If `format` is `""` or `Nothing`, .to_text is used to format the value.
         In case of date/time columns, the format can also be a
         `Date_Time_Formatter`. If `format` is a `Column`, it must be a text
         column.
       - locale: The locale in which the format should be interpreted.
         If a `Date_Time_Formatter` is provided for `format` and the `locale` is
         set to anything else than `Locale.default`, then that locale will
         override the formatters locale.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default.

       ! Error Conditions

         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If a provided `format` value is not compatible with all selected
           columns, an Illegal_Argument error will be thrown, or a
           Date_Time_Format_Parse_Error in the case of a badly-formed date/time
           format.
         - If no columns have been selected for formatting, a
           `No_Input_Columns_Selected` error is raised.

       ? Supported Types
         - `Value_Type.Date`
         - `Value_Type.Date_Time`
         - `Value_Type.Time`
         - `Value_Type.Integer`
         - `Value_Type.Float`
         - `Value_Type.Boolean`

       ? `Value_Type.Date`, `Value_Type.Date_Time`, `Value_Type.Time` format strings

          See `Date_Time_Formatter` for more details.

       ? `Value_Type.Integer`, `Value_Type.Float` format strings

         Numeric format strings are specified by the Java DecimalFormat class.
         See https://docs.oracle.com/javase/8/docs/api/java/text/DecimalFormat.html
         for a complete format specification.

       ? `Value_Type.Boolean` format strings

         Format strings for `Boolean` consist of two values that represent true
         and false, separated by a `|`.

       > Example
         Format the first and last boolean columns as 'Yes'/'No'.

             table.format columns=[0, -1] format="Yes|No"

       > Example
         Format dates in a column using the format `yyyyMMdd`.

             table.format "birthday" "yyyyMMdd"

       > Example
         Format all columns in the table using the default formatter.

             table.format
    @columns Widget_Helpers.make_column_name_vector_selector
    @locale Locale.default_widget
    @format (make_format_chooser include_number=False)
    format : Vector (Text | Integer | Regex) | Text | Integer | Regex -> Text | Date_Time_Formatter | Column -> Locale -> Boolean -> Problem_Behavior -> Table ! Date_Time_Format_Parse_Error | Illegal_Argument
    format self columns format:(Text | Date_Time_Formatter | Column)="" locale=Locale.default error_on_missing_columns=True on_problems=Report_Warning =
        select_problem_builder = Problem_Builder.new error_on_missing_columns=error_on_missing_columns
        selected_columns = self.columns_helper.select_columns_helper columns Case_Sensitivity.Default True select_problem_builder
        select_problem_builder.attach_problems_before on_problems <|
            selected_column_names = case selected_columns.is_empty of
                True ->
                    no_columns_problem_behavior = case error_on_missing_columns of
                        True -> Problem_Behavior.Report_Error
                        False -> on_problems
                    no_columns_problem_behavior.attach_problem_before No_Input_Columns_Selected Map.empty
                False ->
                    Map.from_vector <| selected_columns.map c-> [c.name, True]

            new_columns = self.columns.map column-> if selected_column_names.contains_key column.name . not then column else
                column.format format locale
            Table.new new_columns

    ## GROUP Standard.Base.Conversions
       ICON convert
       Cast the selected columns to a specific type.

       Returns a new table in which the selected columns are replaced with
       columns having the new types.

       Arguments:
       - columns: The selection of columns to cast.
       - value_type: The `Value_Type` to cast the column to.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       In the Database backend, this will boil down to a CAST operation.
       In the in-memory backend, a conversion will be performed according to
       the following rules:
       - Anything can be cast into the `Mixed` type.
       - Converting to a `Char` type, the elements of the column will be
         converted to text. If it is fixed length, the texts will be trimmed or
         padded on the right with the space character to match the desired
         length.
       - Conversion between numeric types will replace values exceeding the
         range of the target type with `Nothing`.
       - Converting decimal numbers into integers will truncate or round them,
         depending on the backend. If more control is needed, use the various
         rounding functions (such as `round` or `floor`).
       - Booleans may also be converted to numbers, with `True` being converted
         to `1` and `False` to `0`. The reverse is not supported - use `iif`
         instead.
       - A `Date_Time` may be converted into a `Date` or `Time` type - the
         resulting value will be truncated to the desired type.
       - If a `Date` is to be converted to `Date_Time`, it will be set at
         midnight of the default system timezone.
       - For a `Mixed` column being converted into a specific type, each row is
         converted individually.

        If the target type cannot fit some of the values (for example due to too
        small range), a `Conversion_Failure` may be reported according to the
        `on_problems` rules. The Database backends may fail with `SQL_Error`
        instead.

       ? Inexact Target Type

         If the backend does not support the requested target type, the closest
         supported type is chosen and a `Inexact_Type_Coercion` problem is
         reported.

       ! Casting Text values

         The `parse` method should be used to convert text values into other
         types. Due to this, a Mixed column containing values `[2, "3"]` will
         actually be converted into `[2, Nothing]` when casting to Integer type.
    @columns Widget_Helpers.make_column_name_vector_selector
    cast : Vector (Text | Integer | Regex) | Text | Integer | Regex -> Value_Type -> Boolean -> Problem_Behavior -> Table ! Illegal_Argument | Inexact_Type_Coercion | Conversion_Failure
    cast self columns=[0] value_type error_on_missing_columns=True on_problems=Problem_Behavior.Report_Warning =
        selected = self.columns_helper.select_columns columns Case_Sensitivity.Default reorder=False error_on_missing_columns=error_on_missing_columns on_problems=on_problems error_on_empty=False
        selected.fold self table-> column_to_cast->
            new_column = column_to_cast.cast value_type on_problems
            table.set new_column as=column_to_cast.name set_mode=Set_Mode.Update

    ## GROUP Standard.Base.Conversions
       ICON convert
       Change the value type of table columns to a more specific one, based on
       their contents.

       This is most useful for `Mixed` type columns and will allow to narrow
       down the type if all values in the column fit a more specific type.

       Arguments:
       - columns: The selection of columns to convert.
       - shrink_types: If set `True`, smaller types will be chosen if possible,
         according to the rules below. Defaults to `False`.
       - error_on_missing_columns: Specifies if a missing input column should
         result in an error regardless of the `on_problems` settings. Defaults
         to `True`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ? Auto Type Selection Rules

         - If a `Mixed` column can be assigned a single type, like `Char` or
           `Integer`, that will be used.
         - Text columns are not parsed. To do that, use the `parse` method.
         - If a `Float` column contains only integers, it will be converted to
           an Integer column.
         - If a `Decimal` column contains only integers that could fit in a
           64-bit integer storage, it will be converted to an Integer column.
         - If `shrink_types` is `False` (default), no other transformations are
           applied.
         - However, if `shrink_types` is set to `True`, then:
           - Integer columns will be assigned the smallest size that can fit all
             values (down to 16-bit integers; converting to the `Byte` type has
             to be done manually through `cast`).
           - If all elements in a text column have the same length, the type
             will become fixed length.
           - Otherwise, if a text column is variable length, but all text
             elements are no longer than 255 characters, the column will get a
             max length of 255. Otherwise, the column size limit will stay
             unchanged.
    auto_value_types : Vector (Text | Integer | Regex) | Text | Integer | Regex -> Boolean -> Boolean -> Problem_Behavior -> Table
    auto_value_types self columns=self.column_names shrink_types=False error_on_missing_columns=True on_problems=Problem_Behavior.Report_Warning =
        selected = self.columns_helper.select_columns columns Case_Sensitivity.Default reorder=False error_on_missing_columns=error_on_missing_columns on_problems=on_problems error_on_empty=False
        selected.fold self table-> column_to_cast->
            new_column = column_to_cast.auto_value_type shrink_types
            table.set new_column as=column_to_cast.name set_mode=Set_Mode.Update

    ## GROUP Standard.Base.Conversions
       ICON split_text
       Splits a column of text into a set of new columns.
       The original column will be removed from the table.
       The new columns will be named with the name of the input column with a
       incrementing number after.

       Arguments:
       - column: The name or index of the column to split the text of.
       - delimiter: The term or terms used to split the text.
       - column_count: The number of columns to split to.
         If `Nothing` then columns will be added to fit all data.
       - on_problems: Specifies the behavior when a problem occurs.

       ! Error Conditions
         If the data exceeds the `column_count`, a `Column_Count_Exceeded` will
         be reported according to the `on_problems` behavior.
    @column Widget_Helpers.make_column_name_selector
    @delimiter make_delimiter_selector
    split_to_columns : Text | Integer -> Text -> Integer | Nothing -> Problem_Behavior -> Table
    split_to_columns self column delimiter="," column_count=Nothing on_problems=Report_Error =
        Split_Tokenize.split_to_columns self column delimiter column_count on_problems

    ## GROUP Standard.Base.Conversions
       ICON split_text
       Splits a column of text into a set of new rows.
       The values of other columns are repeated for the new rows.

       Arguments:
       - column: The name or index of the column to split the text of.
       - delimiter: The term or terms used to split the text.
    @column Widget_Helpers.make_column_name_selector
    @delimiter make_delimiter_selector
    split_to_rows : Text | Integer -> Text -> Table
    split_to_rows self column delimiter="," =
        Split_Tokenize.split_to_rows self column delimiter

    ## GROUP Standard.Base.Conversions
       ICON split_text
       Tokenizes a column of text into a set of new columns using a regular
       expression.
       If the pattern contains marked groups, the values are concatenated
       together; otherwise the whole match is returned.
       The original column will be removed from the table.
       The new columns will be named with the name of the input column with a
       incrementing number after.

       Arguments:
       - column: The name or index of the column to tokenize the text of.
       - pattern: The pattern used to find within the text.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - column_count: The number of columns to split to.
         If `Nothing` then columns will be added to fit all data.
       - on_problems: Specifies the behavior when a problem occurs.

       ! Error Conditions
         If the data exceeds the `column_count`, a `Column_Count_Exceeded` will
         be reported according to the `on_problems` behavior.
    @column Widget_Helpers.make_column_name_selector
    tokenize_to_columns : Text | Integer -> Text -> Case_Sensitivity -> Integer | Nothing -> Problem_Behavior -> Table
    tokenize_to_columns self column pattern="." case_sensitivity=Case_Sensitivity.Sensitive column_count=Nothing on_problems=Report_Error =
        Split_Tokenize.tokenize_to_columns self column pattern case_sensitivity column_count on_problems

    ## GROUP Standard.Base.Conversions
       ICON split_text
       Tokenizes a column of text into a set of new rows using a regular
       expression.
       If the pattern contains marked groups, the values are concatenated
       together; otherwise the whole match is returned.
       The values of other columns are repeated for the new rows.

       Arguments:
       - column: The name or index of the column to tokenize the text of.
       - pattern: The pattern used to find within the text.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - at_least_one_row: If True, a tokenization that returns no values will still
         produce at least one row, with `Nothing` for the output column values.
         Equivalent to converting a tokenization output of [] to [Nothing].
    @column Widget_Helpers.make_column_name_selector
    tokenize_to_rows : Text | Integer -> Text -> Case_Sensitivity -> Boolean -> Table
    tokenize_to_rows self column pattern="." case_sensitivity=Case_Sensitivity.Sensitive at_least_one_row=False =
        Split_Tokenize.tokenize_to_rows self column pattern case_sensitivity at_least_one_row

    ## GROUP Standard.Base.Conversions
       ICON split_text
       Converts a Text column into new columns using a regular expression
       pattern.

       Each match becomes a row in the table.
       The values of other columns are repeated for the new rows.

       If there are no marked groups, a single column with whole content of
       match is added. Otherwise, each group becomes a column (with group name
       if named in Regex).

       Arguments:
       - column: The column to split the text of.
       - pattern: The pattern used to search within the text.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - parse_values: Parse any values using the default value parser.

       ? Column Names

       If no marked group, the new column will have the same name as the input.
       If the marked groups are named, the names will be used otherwise the column
       will be named `<Input Column> <N>` where `N` is the number of the marked group.
       If the new name is already in use it will be renamed following the normal
       suffixing strategy.
    @column Widget_Helpers.make_column_name_selector
    parse_to_columns : Text | Integer -> Text | Regex -> Case_Sensitivity -> Boolean -> Problem_Behavior -> Table
    parse_to_columns self column pattern="." case_sensitivity=Case_Sensitivity.Sensitive parse_values=True on_problems=Report_Error =
        Split_Tokenize.parse_to_columns self column pattern case_sensitivity parse_values on_problems

    ## GROUP Standard.Base.Calculations
       ICON split_text
       Expand a column of objects to a new set of columns.

        Arguments:
        - column: The column to expand.
        - fields: The set fields to expand. If `Nothing` then all fields are added.
        - prefix: Prefix to add to the column names. If `Nothing` then the column
          name is used.
    @column Widget_Helpers.make_column_name_selector
    expand_column : Text | Integer -> (Vector Text) | Nothing -> Prefix_Name -> Table ! Type_Error | No_Such_Column | Index_Out_Of_Bounds
    expand_column self (column : Text | Integer) (fields : (Vector Text) | Nothing = Nothing) (prefix : Prefix_Name = Prefix_Name.Column_Name) =
        Expand_Objects_Helpers.expand_column self column fields prefix

    ## GROUP Standard.Base.Calculations
       ICON split_text
       Expand aggregate values in a column to separate rows.

       For each value in the specified column, if it is an aggregate (`Vector`,
       `Range`, etc.), expand it to multiple rows, duplicating the values in the
       other columns.

       Arguments:
       - column: The column to expand.
       - at_least_one_row: for an empty aggregate value, if `at_least_one_row` is
         true, a single row is output with `Nothing` for the aggregates column; if
         false, no row is output at all.

       The following aggregate values are supported:
       - `Array`
       - `Vector`
       - `List`
       - `Range`
       - `Date_Range`
       - `Pair`
       - `Table`
       - `Column`

       Any other values are treated as non-aggregate values, and their rows are kept
       unchanged.

       In in-memory tables, it is permitted to mix values of different types.

       > Example
         Expand a column of integer `Vectors` to a column of `Integer`

         table = Table.new [["aaa", [1, 2]], ["bbb", [[30, 31], [40, 41]]]]
         # => Table.new [["aaa", [1, 1, 2, 2]], ["bbb", [30, 31, 40, 41]]]
    @column Widget_Helpers.make_column_name_selector
    expand_to_rows : Text | Integer -> Boolean -> Table ! Type_Error | No_Such_Column | Index_Out_Of_Bounds
    expand_to_rows self column at_least_one_row=False =
        Expand_Objects_Helpers.expand_to_rows self column at_least_one_row

    ## ALIAS filter rows, where
       GROUP Standard.Base.Selections
       ICON preparation

       Selects only the rows of this table that correspond to `True` values of
       `filter`.

       Arguments:
       - column: The column to use for filtering. Can be a column name, index or
         the `Column` object itself.
       - filter: The filter to apply to the column. It can either be an instance
         of `Filter_Condition` or a predicate taking a cell value and returning
         a boolean value indicating whether the corresponding row should be kept
         or not.
       - on_problems: Specifies how to handle if a non-fatal problem occurs,
         attaching a warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If a column index is invalid, an `Index_Out_Of_Bounds` dataflow error
           is raised.
         - If the column is an invalid type for the filter, an
           `Invalid_Value_Type` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If filtering by equality on a floating-point column,
             a `Floating_Point_Equality`.

       > Example
         Get people older than 30.

             people.filter "Age" (Greater 30)

       > Example
         Filter people between 30 and 40.

             people.filter "Age" (Between 30 40)

       > Example
         Select rows where more than 50% of the stock is sold.

             table.filter "sold_stock" (Greater (table.at "total_stock" / 2))

       > Example
         Select people celebrating a jubilee.

             people.filter "age" (age -> (age%10 == 0))
    @column (Widget_Helpers.make_column_name_selector add_expression=True)
    @filter Widget_Helpers.make_filter_condition_selector
    filter : (Column | Expression | Text | Integer) -> (Filter_Condition | (Any -> Boolean)) -> Problem_Behavior -> Table ! No_Such_Column | Index_Out_Of_Bounds | Invalid_Value_Type
    filter self column (filter : Filter_Condition | (Any -> Boolean) = Filter_Condition.Equal True) on_problems=Report_Warning = case column of
        _ : Column ->
            mask filter_column = Table.Value (self.java_table.filter filter_column.java_column)
            case filter of
                _ : Filter_Condition ->
                    resolved = (self:Table_Ref).resolve_condition filter
                    mask (make_filter_column column resolved on_problems)
                _ : Function -> Filter_Condition_Module.handle_constructor_missing_arguments filter <|
                    mask (column.map filter)
        _ : Expression -> self.filter (self.evaluate_expression column on_problems) filter on_problems
        _ ->
            table_at = self.at column
            self.filter table_at filter on_problems

    ## ALIAS filter rows
       GROUP Standard.Base.Selections
       ICON preparation

       Selects only the rows of this table that correspond to `True` values of
       `filter`.

       Arguments:
       - expression: The expression to evaluate to filter the rows.
       - on_problems: Specifies how to handle non-fatal problems, attaching a
         warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - If the expression returns a column that does not have a boolean type,
           an `Invalid_Value_Type` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.

       > Example
         Select people celebrating a jubilee.

             people.filter_by_expression "[age] % 10 == 0"
    filter_by_expression : Text -> Problem_Behavior -> Table ! No_Such_Column | Invalid_Value_Type | Expression_Error
    filter_by_expression self expression on_problems=Report_Warning =
        column = self.evaluate_expression (Expression.Value expression) on_problems
        result = self.filter column Filter_Condition.Is_True
        Warning.attach (Deprecated.Warning "Standard.Table.Table.Table" "filter_by_expression" "Deprecated: use `filter` with an `Expression` instead.") result

    ## ALIAS first, head, last, limit, sample, slice, tail, top
       GROUP Standard.Base.Selections
       ICON select_row
       Creates a new Table with the specified range of rows from the input
       Table.

       Arguments:
       - range: The selection of rows from the table to return.

       For the purposes of the `Index_Sub_Range.While` predicate a single
       "element" of the table is represented by the `Row` type.

       ? Supported Range Types

         Database backends support all range types except `While` and `Sample`

         In-memory tables support all range types.

       > Example
         Take first 10 rows of the table.

             table.take (First 10)

       > Example
         Take rows from the top of the table as long as their values sum to 10.

             table.take (While row-> row.to_vector.compute Statistic.Sum == 10)
    @range Index_Sub_Range.default_widget
    take : (Index_Sub_Range | Range | Integer) -> Table
    take self range=(First 1) =
        Index_Sub_Range_Module.take_helper self.row_count self.rows.at self.slice (slice_ranges self) range

    ## ALIAS skip
       GROUP Standard.Base.Selections
       ICON select_row
       Creates a new Table from the input with the specified range of rows
       removed.

       Arguments:
       - range: The selection of rows from the table to remove.

       For the purposes of the `Index_Sub_Range.While` predicate a single
       "element" of the table is represented by the `Row` type.

       ? Supported Range Types

         Database backends support all range types except `While` and `Sample`

         In-memory tables support all range types.

       > Example
         Drop first 10 rows of the table.

             table.drop (First 10)

       > Example
         Drop rows from the top of the table as long as their values sum to 10.

             table.drop (While row-> row.to_vector.compute Statistic.Sum == 10)
    @range Index_Sub_Range.default_widget
    drop : (Index_Sub_Range | Range | Integer) -> Table
    drop self range=(First 1) =
        Index_Sub_Range_Module.drop_helper self.row_count self.rows.at self.slice (slice_ranges self) range

    ## PRIVATE
       Filter out all rows.
    remove_all_rows : Table
    remove_all_rows self = self.take 0

    ## ALIAS add index column, rank, record id
       GROUP Standard.Base.Values
       ICON dataframe_map_column
       Adds a new column to the table enumerating the rows.

       Arguments:
       - name: The name of the new column. Defaults to "Row".
       - from: The starting value for the enumeration. Defaults to 1.
       - step: The amount to increment the enumeration by. Defaults to 1.
       - group_by: Specifies the columns to group by. The row numbers are
         counted separately for each group. By default, all rows are treated as
         a single group.
       - order_by: Specifies the columns to order by. Defaults to the order of
         the rows in the table. The row numbers are assigned according to the
         specified ordering.

       ? Ordering of rows

         Note that the ordering of rows from the original table is preserved in
         all cases. The grouping and ordering settings affect how the row
         numbers are assigned to each row, but the order of the rows itself is
         not changed by this operation.

       ! Error Conditions

         - If the columns specified in `group_by` or `order_by` are not present
           in the table, a `Missing_Input_Columns` error is raised.
         - If the column with the same name as provided `name` already exists,
           a `Duplicate_Output_Column_Names` problem is reported and the
           existing column is renamed to avoid the clash.
         - If grouping on floating point numbers, a `Floating_Point_Equality`
           problem is reported.
    @group_by Widget_Helpers.make_column_name_vector_selector
    @order_by Widget_Helpers.make_order_by_selector
    add_row_number : Text -> Integer -> Integer -> Vector (Text | Integer | Regex) | Text | Integer | Regex -> Vector (Text | Sort_Column) | Text -> Problem_Behavior -> Table
    add_row_number self (name:Text="Row") (from:Integer=1) (step:Integer=1) (group_by:(Vector | Text | Integer | Regex)=[]) (order_by:(Vector | Text)=[]) (on_problems:Problem_Behavior=Problem_Behavior.Report_Warning) =
        Add_Row_Number.add_row_number self name from step group_by order_by on_problems

    ## ALIAS add column, formula, new column, update column
       GROUP Standard.Base.Values
       ICON dataframe_map_column
       Sets the column value at the given name.

       Arguments:
       - value: The value, expression or column to create column.
       - as: Optional new name for the column.
       - set_mode: Specifies the expected behaviour in regards to existing
         column with the same name.
       - on_problems: Specifies how to handle problems with expression
         evaluation.

       ! Error Conditions

         - If the column name is already present and `set_mode` is `Add`, a
           `Existing_Column` dataflow error is raised.
         - If the column name is not present and `set_mode` is `Update`, a
           `Missing_Column` dataflow error is raised.
         - If a column name referenced from within an expression cannot be
           found, a `No_Such_Column` dataflow error is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - The following problems with expression evaluation may be reported
           according to the `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.

       > Example
         Create a table where the values of the total stock in the inventory is
         doubled.

             import Standard.Examples

             example_set =
                 table = Examples.inventory_table
                 double_inventory = table.at "total_stock" * 2
                 table.set double_inventory as="total_stock"
                 table.set (expr "2 * [total_stock]") as="total_stock_expr"
    @value Simple_Expression.default_widget
    set : Text | Expression | Column | Constant_Column | Simple_Expression -> Text -> Set_Mode -> Problem_Behavior -> Table ! Existing_Column | Missing_Column | No_Such_Column | Expression_Error
    set self value:(Text | Expression | Column | Constant_Column | Simple_Expression) (as : Text = "") (set_mode : Set_Mode = Set_Mode.Add_Or_Update) (on_problems : Problem_Behavior = Report_Warning) =
        problem_builder = Problem_Builder.new
        unique = self.column_naming_helper.create_unique_name_strategy
        unique.mark_used self.column_names

        resolved = case value of
            _ : Text -> self.make_constant_column value
            _ : Expression -> self.evaluate_expression value on_problems
            _ : Column -> value
            _ : Constant_Column -> self.make_constant_column value.value
            _ : Simple_Expression -> value.evaluate self (set_mode==Set_Mode.Update && as=="") on_problems
            _ -> Error.throw (Illegal_Argument.Error "Unsupported type for `Table.set`.")

        ## If `as` was specified, use that. Otherwise, if `value` is a
           `Column`, use its name. In these two cases, do not make it unique.
           Otherwise, make it unique. If set_mode is Update, however, do not
           make it unique.
        new_column_name = if as != "" then as else
            if value.is_a Column || set_mode==Set_Mode.Update || set_mode==Set_Mode.Add_Or_Update then resolved.name else unique.make_unique resolved.name
        renamed = resolved.rename new_column_name
        renamed.if_not_error <| self.column_naming_helper.check_ambiguity self.column_names renamed.name <|
            check_add_mode = case set_mode of
                Set_Mode.Add_Or_Update -> True
                Set_Mode.Add -> if self.java_table.getColumnByName renamed.name . is_nothing then True else
                    Error.throw (Existing_Column.Error renamed.name)
                Set_Mode.Update -> if self.java_table.getColumnByName renamed.name . is_nothing . not then True else
                    Error.throw (Missing_Column.Error renamed.name)

            new_table = check_add_mode.if_not_error <|
                if resolved.length != self.row_count then Error.throw (Row_Count_Mismatch.Error self.row_count resolved.length) else
                    Table.Value (self.java_table.addOrReplaceColumn renamed.java_column)

            problem_builder.report_unique_name_strategy unique
            problem_builder.attach_problems_after on_problems new_table

    ## Given an expression, create a derived column where each value is the
       result of evaluating the expression for the row.

       Arguments:
       - expression: The expression to evaluate.
       - on_problems: Specifies how to handle non-fatal problems, attaching a
         warning by default.

       ! Error Conditions

         - If a column name cannot be found, a `No_Such_Column` dataflow error
           is raised.
         - If the provided expression is invalid, a corresponding
           `Expression_Error` dataflow error is raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If the expression checks equality on a floating-point column,
             a `Floating_Point_Equality`.
           - If an arithmetic error occurs when computing the expression,
             an `Arithmetic_Error`.
           - If more than 10 rows encounter computation issues,
             an `Additional_Warnings`.
    evaluate_expression : Text | Expression -> Problem_Behavior -> Column ! No_Such_Column | Invalid_Value_Type | Expression_Error
    evaluate_expression self expression:(Text | Expression) on_problems:Problem_Behavior=Report_Warning = if expression.is_a Text then self.evaluate_expression (Expression.Value expression) on_problems else
        get_column name = self.at name
        new_column = Expression.evaluate expression get_column self.make_constant_column "Standard.Table.Column" "Column" Column.var_args_functions
        problems = Warning.get_all new_column . map .value
        result = new_column.rename (self.column_naming_helper.sanitize_name expression.expression)
        on_problems.attach_problems_before problems <|
            Warning.set result []

    ## PRIVATE
       A helper that creates a two-column table from a Map.

       The keys of the `Map` become the first column, with name
       `key_column_name`, and the values of the `Map` become the second column,
       with name `value_column_name`.

       For the in-memory database, the `Map` can be empty. For the database
       backends, it must not be empty.

       Arguments:
       - map: The `Map` to create the table from.
       - key_column_name: The name to use for the first column.
       - value_column_name: The name to use for the second column.
    make_table_from_map  : Map Any Any -> Text -> Text -> Table
    make_table_from_map self map key_column_name value_column_name =
        keys_and_values = map.to_vector
        self.make_table_from_vectors [keys_and_values.map .first, keys_and_values.map .second] [key_column_name, value_column_name]

    ## PRIVATE
       A helper that creates a literal table from `Vector`s.

       For the in-memory database, the columns can be empty. For the database
       backends, they must not be empty.

       Arguments:
       - column_vectors: A `Vector` of `Vector`s; each inner `Vector` becomes a
         column of the table.
       - column_names: The names of the columns of the new table.
    make_table_from_vectors : Vector (Vector Any) -> Vector Text -> Table
    make_table_from_vectors self column_vectors column_names =
        # Assume the columns are all the same length; if not, it will be an error anyway.
        if column_vectors.is_empty then Error.throw (Illegal_Argument.Error "Vectors cannot be empty") else
            Runtime.assert (column_vectors.length == column_names.length) "column_vectors and column_names must have the same length"
            Table.new (column_vectors.zip column_names (v-> n-> Column.from_vector n v))

    ## PRIVATE

       Create a constant column from a value.
    make_constant_column : Any -> Column
    make_constant_column self value =
        if Table_Helpers.is_column value then Error.throw (Illegal_Argument.Error "A constant value may only be created from a scalar, not a Column") else
            Column.from_repeated_item value.pretty value self.row_count

    ## PRIVATE
       Create a unique temporary column name.
    make_temp_column_name : Text
    make_temp_column_name self = self.column_naming_helper.make_temp_column_name self.column_names

    ## Returns the vector of columns contained in this table.

       > Examples
         Get a vector containing the columns in the table.

             import Standard.Examples

             example_columns = Examples.inventory_table.columns
    columns : Vector
    columns self = Vector.from_polyglot_array <|
        Array_Proxy.new self.java_table.getColumns.length i->
            Column.Value (self.java_table.getColumns.at i)

    ## GROUP Standard.Base.Metadata
       ICON metadata
       Returns the vector of column names contained in this table.
    column_names : Vector Text
    column_names self = Vector.from_polyglot_array <|
        Array_Proxy.new self.java_table.getColumns.length i->
            self.java_table.getColumns.at i . getName

    ## ICON select_row
       Returns a vector of rows contained in this table.

       In the database backend, it first materializes the table to in-memory.

       Arguments:
       - max_rows: specifies the maximum number of rows to read.
         If `Nothing`, all available rows are returned.
       - warn_if_more_rows: if set to `True`, a warning is attached to the
         result if the number of rows returned by the query exceeds `max_rows`.
    rows : Integer | Nothing -> Boolean -> Vector Row
    rows self (max_rows : Integer | Nothing = Nothing) (warn_if_more_rows : Boolean = True) =
        proxy = Rows_View.Value (self.read max_rows warn_if_more_rows)
        Vector.from_polyglot_array (Array_Proxy.from_proxy_object proxy)

    ## GROUP Standard.Base.Selections
       ICON select_row
       Returns the first row of the table.

       In the database backend, it first materializes the table to in-memory.
    first_row : Row ! Index_Out_Of_Bounds
    first_row self =
        if self.row_count == 0 then Error.throw (Index_Out_Of_Bounds.Error 0 0) else
            Row.Value self 0

    ## GROUP Standard.Base.Selections
       ICON select_row
       Returns the second row of the table.

       In the database backend, it first materializes the table to in-memory.
    second_row : Row ! Index_Out_Of_Bounds
    second_row self =
        if self.row_count < 2 then Error.throw (Index_Out_Of_Bounds.Error 1 self.row_count) else
            Row.Value self 1

    ## GROUP Standard.Base.Selections
       ICON select_row
       Returns the last row of the table.

       In the database backend, it first materializes the table to in-memory.
    last_row : Row ! Index_Out_Of_Bounds
    last_row self =
        if self.row_count == 0 then Error.throw (Index_Out_Of_Bounds.Error 0 0) else
            Row.Value self (self.row_count-1)

    ## GROUP Standard.Base.Calculations
       ICON join
       Joins two tables according to the specified join conditions.

       Arguments:
       - right: The table to join with.
       - join_kind: The `Join_Kind` for the joining the two tables. It defaults
         to `Left_Outer`.
       - on: A single condition or a common column name, or a list thereof, on
         which to correlate rows from the two tables. If multiple conditions
         are supplied, rows are correlated only if all are true.
         If common column names are provided, these columns should be present
         in both tables and an equality condition is added for each of them.
         By default, the join is performed on the first column of the left table
         correlated with a column in the right table with the same name.
       - right_prefix: The prefix added to right table column names in case of
         name conflict.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If a column name cannot be found, a `No_Such_Column` is reported
           and an empty result is reported.
         - If a column index is invalid, an `Index_Out_Of_Bounds` is
           reported and an empty result is reported.
         - If there are column names that are clashing between the two tables, a
           `Duplicate_Output_Column_Names` is reported and the columns from the
           table are renamed as described below.
         - If a join condition correlates columns whose types are not compatible
           (for example comparing numeric types with text), an
           `Invalid_Value_Type` is reported.
         - If decimal columns are joined on equality, a
           `Floating_Point_Equality` is reported.

         In any of the above cases, if a problem occurs, the resulting table
         will have the desired structure, but it will be empty to indicate that
         the join has failed due to an erroneous join condition.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Result Ordering

         The ordering of rows in the resulting table is not specified.

       ? Joining on equality of columns with the same name

         When performing an Inner join on two columns with the same name and an
         equality condition, only one copy of column will be included in the
         output (as these two columns would have the exact same content, so they
         would be redundant).

       ? Same-name column join shorthand

         As a shorthand, providing a column name or a list of column names
         allows to join the two tables on equality of corresponding columns with
         the same name. So `table.join other on=["A", "B"]` is a shorthand for:
             table.join other on=[Join_Condition.Equals "A" "A", Join_Condition.Equals "B" "B"]
    @join_kind Widget_Helpers.make_join_kind_selector
    @on Widget_Helpers.make_join_condition_selector
    join : Table -> Join_Kind -> Vector (Join_Condition | Text) | Text -> Text -> Problem_Behavior -> Table
    join self right:Table (join_kind : Join_Kind = Join_Kind.Left_Outer) on=[Join_Condition.Equals self.column_names.first] right_prefix="Right " on_problems=Report_Warning = Out_Of_Memory.handle_java_exception "join" <|
        columns_to_keep = case join_kind of
            Join_Kind.Left_Exclusive  -> [True, False]
            Join_Kind.Right_Exclusive -> [False, True]
            _                         -> [True, True]

        join_resolution = make_join_helpers self right . resolve on on_problems
        right_columns_to_drop = if join_kind == Join_Kind.Inner then join_resolution.redundant_column_names else []

        java_conditions = join_resolution.conditions
        new_java_table = Java_Problems.with_problem_aggregator on_problems java_aggregator->
            self.java_table.join right.java_table java_conditions join_kind.to_java (columns_to_keep.at 0) (columns_to_keep.at 1) right_columns_to_drop right_prefix java_aggregator
        Table.Value new_java_table

    ## ALIAS append, cartesian join
       GROUP Standard.Base.Calculations
       ICON join
       Joins tables by pairing every row of the left table with every row of the
       right table.

       Arguments:
       - right: The table to join with.
       - right_row_limit: If the number of rows in the right table exceeds this,
         then a `Cross_Join_Row_Limit_Exceeded` problem is raised. The check
         exists to avoid exploding the size of the table by accident. This check
         can be disabled by setting this parameter to `Nothing`.
       - right_prefix: The prefix added to right table column names in case of
         name conflict. See "Column Renaming" below for more information.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If the `right` table has more rows than the `right_row_limit` allows,
           a `Cross_Join_Row_Limit_Exceeded` is reported. In warning/ignore
           mode, the join is still executed.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Result Ordering

         Rows in the result are first ordered by the order of the corresponding
         rows from the left table and then the order of rows from the right
         table. This applies only if the order of the rows was specified (for
         example, by sorting the table; in-memory tables will keep the memory
         layout order while for database tables the order may be unspecified).
    cross_join : Table -> Integer | Nothing -> Text -> Problem_Behavior -> Table
    cross_join self right:Table right_row_limit=100 right_prefix="Right " on_problems=Report_Warning = Out_Of_Memory.handle_java_exception "cross_join" <|
        limit_problems = case right_row_limit.is_nothing.not && (right.row_count > right_row_limit) of
            True ->
                [Cross_Join_Row_Limit_Exceeded.Error right_row_limit right.row_count]
            False -> []
        on_problems.attach_problems_before limit_problems <|
            new_java_table = Java_Problems.with_problem_aggregator on_problems java_aggregator->
                self.java_table.crossJoin right.java_table right_prefix java_aggregator
            Table.Value new_java_table

    ## ALIAS lookup
       GROUP Standard.Base.Calculations
       ICON join
       Merges this table with a lookup table
       New values are looked up in the lookup table based on the `key_columns`.
       Columns that exist in the lookup table where a match was found are
       replaced by values from the lookup table. Columns not found are left
       unchanged.
       This operation is similar to `Table.update_rows`, but just returns a new
       `Table` instance, instead of updating the table in-place (which is only
       possible for Database tables).

       Arguments:
       - lookup_table: The table to use for looking up values.
       - key_columns: Specifies the columns to use for correlating rows between
         the two tables. Must identify values uniquely within `lookup_table`.
       - add_new_columns: Specifies if new columns from the lookup table should
         be added to the result. If `False`, an `Unexpected_Extra_Columns`
         problem is reported.
       - allow_unmatched_rows: Specifies how to handle missing rows in the lookup.
         If `False` (the default), an `Unmatched_Rows_In_Lookup` error is raised.
         If `True`, the unmatched rows are left unchanged. Any new columns will
         be filled with `Nothing`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ? Result Ordering

         When operating in-memory, this operation preserves the order of rows
         from this table (unlike `join`).
         In the Database backend, there are no guarantees related to ordering of
         results.

       ! Error Conditions

         - If this table or the lookup table is lacking any of the columns
           specified in `key_columns`, a `Missing_Input_Columns` error is raised.
         - If an empty vector is provided for `key_columns`, a
           `No_Input_Columns_Selected` error is raised.
         - If a single row is matched by multiple entries in the lookup table,
           a `Non_Unique_Key` error is raised.
         - If a column that is being updated from the lookup table has a type
           that is not compatible with the type of the corresponding column in
           this table, a `No_Common_Type` error is raised.
         - If a key column contains `Nothing` values in the lookup table,
           a `Null_Values_In_Key_Columns` error is raised.
         - If `allow_unmatched_rows` is `False` and there are rows in this table
           that do not have a matching row in the lookup table, an
           `Unmatched_Rows_In_Lookup` error is raised.
         - The following problems may be reported according to the `on_problems`
           setting:
           - If any of the `key_columns` is a floating-point type,
             a `Floating_Point_Equality`.
           - If `add_new_columns` is `False` and the lookup table has columns
             that are not present in this table, an `Unexpected_Extra_Columns`.
    @key_columns Widget_Helpers.make_column_name_vector_selector
    merge : Table -> (Vector (Integer | Text | Regex) | Text | Integer | Regex) -> Boolean -> Boolean -> Problem_Behavior -> Table ! Missing_Input_Columns | Non_Unique_Key | Unmatched_Rows_In_Lookup
    merge self lookup_table:Table key_columns:(Vector (Integer | Text | Regex) | Text | Integer | Regex) add_new_columns:Boolean=False allow_unmatched_rows:Boolean=True on_problems:Problem_Behavior=Problem_Behavior.Report_Warning =
        lookup_columns = Lookup_Helpers.prepare_columns_for_lookup self lookup_table key_columns add_new_columns allow_unmatched_rows on_problems

        java_descriptions = lookup_columns.map make_java_lookup_column_description on_problems=No_Wrap

        keys = lookup_columns.filter .is_key
        java_keys = keys.map on_problems=No_Wrap key_column->
            Java_Join_Equals.new key_column.base_column.java_column key_column.lookup_column.java_column

        handle_java_errors ~action =
            translate_null_values_exception caught_panic =
                exception = caught_panic.payload
                example_values = Vector.from_polyglot_array exception.exampleValues
                Error.throw (Null_Values_In_Key_Columns.Error example_values)
            translate_unmatched_row_exception caught_panic =
                exception = caught_panic.payload
                example_key_values = Vector.from_polyglot_array exception.exampleKeyValues
                Error.throw (Unmatched_Rows_In_Lookup.Error example_key_values)
            translate_non_unique_lookup_key_exception caught_panic =
                exception = caught_panic.payload
                key_column_names = Vector.from_polyglot_array exception.keyColumns
                example_values = Vector.from_polyglot_array exception.exampleValues
                example_count = exception.exampleCount
                Error.throw (Non_Unique_Key.Error key_column_names example_values example_count)
            Panic.catch NonUniqueLookupKey handler=translate_non_unique_lookup_key_exception <|
                Panic.catch UnmatchedRow handler=translate_unmatched_row_exception <|
                    Panic.catch NullValuesInKeyColumns handler=translate_null_values_exception <|
                        action
        handle_java_errors <|
            Java_Problems.with_problem_aggregator on_problems java_problem_aggregator->
                java_table = LookupJoin.lookupAndReplace java_keys java_descriptions allow_unmatched_rows java_problem_aggregator
                Table.Value java_table

    ## ALIAS find replace
       GROUP Standard.Base.Text
       ICON dataframe_map_column
       Replaces values in the columns using `lookup_table` to specify a mapping
       from old to new values.

       Arguments:
       - lookup_table: the table to use as a mapping from old to new values. A
         `Map` can also be used here (in which case passing `from_column` or
         `to_column` is disallowed and will throw an `Illegal_Argument` error.
       - columns: the column or columns within `self` to perform the replace on.
       - from_column: the column within `lookup_table` to match against
         `columns` in `self`.
       - to_column: the column within `lookup_table` to get new values from.
       - allow_unmatched_rows: Specifies how to handle missing rows in the lookup.
         If `False` (the default), an `Unmatched_Rows_In_Lookup` error is raised.
         If `True`, the unmatched rows are left unchanged. Any new columns will
         be filled with `Nothing`.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ? Result Ordering

         When operating in-memory, this operation preserves the order of rows
         from this table (unlike `join`).

         In the Database backend, there are no guarantees related to ordering of
         results.

       ! Error Conditions

         - If this table or the lookup table is lacking any of the columns
           specified by `from_column`, `to_column`, or `columns`, a
           `Missing_Input_Columns` error is raised.
         - If a single row is matched by multiple entries in the lookup table,
           a `Non_Unique_Key` error is raised.
         - If a column that is being updated from the lookup table has a type
           that is not compatible with the type of the corresponding column in
           this table, a `No_Common_Type` error is raised.
         - If a key column contains `Nothing` values in the lookup table,
           a `Null_Values_In_Key_Columns` error is raised.
         - If `allow_unmatched_rows` is `False` and there are rows in this table
           that do not have a matching row in the lookup table, an
           `Unmatched_Rows_In_Lookup` error is raised.
         - The following problems may be reported according to the `on_problems`
           setting:
           - If any of the `columns` is a floating-point type,
             a `Floating_Point_Equality` problem is reported.

       > Example
         Replace values in column 'x' using a lookup table.

             table = Table.new [['x', [1, 2, 3, 4]], ['y', ['a', 'b', 'c', 'd']], ['z', ['e', 'f', 'g', 'h']]]
             #      | x | y | z
             #   ---+---+---+---
             #    0 | 1 | a | e
             #    1 | 2 | b | f
             #    2 | 3 | c | g
             #    3 | 4 | d | h

             lookup_table = Table.new [['x', [1, 2, 3, 4]], ['new_x', [10, 20, 30, 40]]]
             #      | old_x | new_x
             #   ---+-------+-------
             #    0 | 1     | 10
             #    1 | 2     | 20
             #    2 | 3     | 30
             #    3 | 4     | 40

             result = table.replace lookup_table 'x'
             #      | x  | y | z
             #   ---+----+---+---
             #    0 | 10 | a | e
             #    1 | 20 | b | f
             #    2 | 30 | c | g
             #    3 | 40 | d | h
    @columns Widget_Helpers.make_column_name_vector_selector
    @from_column Widget.Text_Input
    @to_column Widget.Text_Input
    replace : (Table | Map) -> (Text | Integer | Vector (Text | Integer)) -> (Text | Integer | Nothing) -> (Text | Integer | Nothing) -> Boolean -> Problem_Behavior -> Table ! Missing_Input_Columns | Non_Unique_Key | Unmatched_Rows_In_Lookup
    replace self lookup_table:(Table | Map) columns:(Text | Integer | Vector (Text | Integer)) from_column:(Text | Integer | Nothing)=Nothing to_column:(Text | Integer | Nothing)=Nothing allow_unmatched_rows:Boolean=True on_problems:Problem_Behavior=Problem_Behavior.Report_Warning =
        Replace_Helpers.replace self lookup_table columns from_column to_column allow_unmatched_rows on_problems

    ## ALIAS join by row position
       GROUP Standard.Base.Calculations
       ICON dataframes_join
       Joins two tables by zipping rows from both tables table together - the
       first row of the left table is correlated with the first one of the right
       one etc.

       Arguments:
       - right: The table to join with.
       - keep_unmatched: If set to `True`, the result will include as many rows
         as the larger of the two tables - the last rows of the larger table
         will have nulls for columns of the smaller one. If set to `False`, the
         result will have as many rows as the smaller of the two tables - the
         additional rows of the larger table will be discarded. The default
         value is `Report_Unmatched` which means that the user expects that two
         tables should have the same amount of rows; if they do not, the
         behaviour is the same as if it was set to `True` - i.e. the unmatched
         rows are kept with `Nothing` values for the other table, but a
         `Row_Count_Mismatch` problem is also reported.
       - right_prefix: The prefix added to right table column names in case of
         name conflict. See "Column Renaming" below for more information.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If the tables have different number of rows and `keep_unmatched` is
           set to `Report_Unmatched`, the join will report `Row_Count_Mismatch`.

       ? Column Renaming

         If columns from the two tables have colliding names, a prefix (by
         default `Right_`) is added to the name of the column from the right
         table. The left column remains unchanged. It is possible that the new
         name will be in use, in this case it will be resolved using the normal
         renaming strategy - adding subsequent `_1`, `_2` etc.

       ? Row Ordering For In-Memory Tables

         This operation requires a well-defined order of rows in the input
         tables. In-memory tables rely on the ordering stemming directly from
         their layout in memory. Database tables may not impose a deterministic
         ordering. If the table defines a primary key, it is used to by default
         to ensure deterministic ordering. That can be overridden by specifying
         a different ordering using `Table.order_by`. If no primary key was
         defined nor any ordering was specified explicitly by the user, the
         order of columns is undefined and the operation will fail, reporting a
         `Undefined_Column_Order` problem and returning an empty table.

       ? Row Ordering For Database Tables

         The ordering of rows in the resulting table is not specified.
    @keep_unmatched (make_single_choice [["True", "Boolean.True"], ["False", "Boolean.False"], ["Report", Meta.get_qualified_type_name Report_Unmatched]])
    zip : Table -> Boolean | Report_Unmatched -> Text -> Problem_Behavior -> Table
    zip self right:Table keep_unmatched=Report_Unmatched right_prefix="Right " on_problems=Report_Warning =
        keep_unmatched_bool = case keep_unmatched of
            Report_Unmatched -> True
            b : Boolean -> b
        report_mismatch = keep_unmatched == Report_Unmatched

        left_row_count = self.row_count
        right_row_count = right.row_count
        problems = if (left_row_count == right_row_count) || report_mismatch.not then [] else
            [Row_Count_Mismatch.Error left_row_count right_row_count]
        on_problems.attach_problems_before problems <|
            new_java_table = Java_Problems.with_problem_aggregator on_problems java_aggregator->
                self.java_table.zip right.java_table keep_unmatched_bool right_prefix java_aggregator
            Table.Value new_java_table

    ## ALIAS append, concat
       GROUP Standard.Base.Calculations
       ICON dataframes_union
       Appends records from other table(s) to this table.

       Arguments:
       - tables: A single table or a vector of tables to append to this one. The
         tables are concatenated in the order they are specified, with `self`
         being the first one.
       - match_columns: Specifies how to match the columns.
         - If `Match_Columns.By_Name` - the columns are matched by name across
           all provided tables.
           If unmatched columns are to be dropped, the resulting table will keep
           only the set of columns that appear in all provided tables, in the
           relative order that they appeared in the `self` table.
           If unmatched columns are kept, they are added in the order of
           appearance - i.e. first all columns from `self` will be added in the
           original order, then any columns from the second table that were not
           matched will be added at the end (preserving their relative order),
           and so on for all the remaining tables.
         - If `Match_Columns.By_Position` - the columns are mapped by position.
           If unmatched columns are to be dropped, the resulting table will have
           as many columns as the table that had the least columns and the
           column names of the first table (self) will be used.
           If unmatched columns are kept, the resulting table will have as many
           columns as the table with the most columns. Since the first table may
           not have all the necessary columns to provide column names for the
           result, the result will have column names taken from the first table
           that has the biggest number of columns.
       - keep_unmatched_columns: If set to `True`, unmatched columns are kept
         and are padded with `Nothing` for tables that did not have them.
         If set to `False`, only the common subset of columns is kept - any
         column that is not present in all tables is dropped. Defaults to
         `Report_Unmatched`, which behaves like `True` - unmatched columns are
         kept and padded with `Nothing`, but a problem is reported.
       - allow_type_widening: Specifies if the resulting column type should be
         adjusted to fit columns from all arguments. If `True`, a common type
         will be chosen for each column (see "Unifying Column Types" below).
         If `False`, the resulting column type will be the same as in the first
         table containing the column. In this case, all columns that are
         concatenated must have the same type as the first one (unless this
         had a `Mixed` type - in which case it will accept any other types).
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If `keep_unmatched_columns` is set to `Report_Unmatched` (the
           default):
           - If matching by name and there are columns that are not present in
             all tables, `Unmatched_Columns` is reported.
           - If matching by position and column counts of the merged tables
             differ, then a `Column_Count_Mismatch` is reported. The error will
             contain the greatest column count as its `expected` value and the
             smallest one as its `actual` value.
         - If `keep_unmatched_columns` is set to `False` and matching by name,
           it is possible that there are no columns that are common to all
           provided tables, in that case `No_Output_Columns` is thrown as a
           dataflow error regardless of the `on_problems` setting, because there
           are no columns to include in the resulting table.
         - If type widening is disabled and one of corresponding columns has a
           type that is incompatible with the type coming from the first table,
           a `Column_Type_Mismatch` is reported. The problematic column will be
           dropped from the resulting table. With type widening disabled, the
           subsequent tables must have the same types as the first one, unless
           the type of the first one was `Mixed` which will accept any other
           type.
         - If a common type coercion for a set of matched columns from
           concatenated tables cannot be found, a `No_Common_Type` is reported.
           In warning or ignore mode, the problematic column will be dropped
           from the resulting table.

       ? Unifying Column Types

         If `allow_type_widening` is set to `True`, then the following rules are
         used to find a common type that will fit values from all merged tables.

         Numeric columns are unified by finding the most general type that can
         fit all of the columns. The biggest integer type will be chosen and if
         integers and decimals are mixed, the decimal type will be chosen.
         If boolean columns are mixed with numeric columns, they will be coerced
         to the numeric type (and converted to 0 and 1).

         Text types will also be coerced according to the common rules - if
         constant-length texts of different lengths are mixed, they will be
         coerced to a varying-length type.

         If one of the matched columns has `Mixed` type, that type will be used
         regardless of types of other columns. Mixing any other types will
         result in a `No_Common_Type` problem. If columns of incompatible types
         are meant to be mixed, at least one of them should be explicitly
         retyped to the `Mixed` type to indicate that intention. Note that the
         `Mixed` type may not be supported by most Database backends.
    union : (Table | Vector Table) -> Match_Columns -> Boolean | Report_Unmatched -> Boolean -> Problem_Behavior -> Table
    union self tables:(Table | Vector)=[] match_columns=Match_Columns.By_Name keep_unmatched_columns=Report_Unmatched allow_type_widening=True on_problems=Report_Warning =
        Table.from_union ([self] + Vector.unify_vector_or_element tables) match_columns keep_unmatched_columns allow_type_widening on_problems

    ## ALIAS drop_missing_rows, dropna
       GROUP Standard.Base.Selections
       ICON preparation
       Remove rows which are all blank or containing blank values.

       Arguments:
       - when: If Blank_Selector.Any_Cell, then remove any row containing
        any blank values.
         If Blank_Selector.All_Cells, then only remove rows with all blank values.
       - treat_nans_as_blank: If `True`, then `Number.nan` is considered as blank.

       ? Blank values
         Blank values are `Nothing`, `""` and depending on setting `Number.nan`.
    filter_blank_rows : Blank_Selector -> Boolean -> Table
    filter_blank_rows self when=Blank_Selector.Any_Cell treat_nans_as_blank=False =
        Table_Helpers.filter_blank_rows self when treat_nans_as_blank

    ## ALIAS count
       GROUP Standard.Base.Metadata
       ICON metadata
       Returns the number of rows in this table.

       > Example
         Count the number of rows in the table.

             import Standard.Examples

             example_row_count = Examples.inventory_table.row_count
    row_count : Integer
    row_count self = self.java_table.rowCount

    ## ICON data_input
       Returns a materialized dataframe containing rows of this table.

       In the in-memory backend, this returns the same table, truncated to
       `max_rows`. This is only kept for API compatibility between database and
       in-memory tables. The `read` operation can be used to ensure that the
       table is now in-memory, regardless of its origin.

       Arguments:
       - max_rows: specifies the maximum number of rows to read.
         If `Nothing`, all available rows are returned.
       - warn_if_more_rows: if set to `True`, a warning is attached to the
         result if the number of rows returned by the query exceeds `max_rows`.
    read : (Integer | Nothing) -> Boolean -> Table
    read self (max_rows : Integer | Nothing = Nothing) (warn_if_more_rows:Boolean = True) = case max_rows of
        Nothing -> self
        _ : Integer ->
            truncated = self.take (First max_rows)
            needs_warning = warn_if_more_rows && self.row_count > max_rows
            if needs_warning.not then truncated else
                Problem_Behavior.Report_Warning.attach_problem_after truncated <|
                    Not_All_Rows_Downloaded.Warning max_rows

    ## ALIAS metadata
       GROUP Standard.Base.Metadata
       ICON metadata
       Returns a Table describing this table's contents.

       The table lists all columns, counts of non-null items and value types of
       each column.

       > Example
         Get information about a table.

             import Standard.Examples

             example_info = Examples.inventory_table.info
    info : Table
    info self =
        cols = self.columns
        Table.new [["Column", cols.map .name], ["Items Count", cols.map .count], ["Value Type", cols.map .value_type]]

    ## GROUP Standard.Base.Calculations
       ICON dataframe_map_row
       Returns a new table with a chosen subset of columns left unchanged and
       the other columns pivoted to rows with a single name field and a single
       value field.

       Arguments:
       - key_columns: Set of fields to remain as columns. These values will be
         repeated for each data field that is pivoted.
       - attribute_column_name: The name of the field that will contain the
         names of the pivoted fields. If this name is already in use, it will be
         renamed with a numeric suffix.
       - value_column_name: The name of the field that will contain the values
         of the pivoted fields. If this name is already in use, it will be
         renamed with a numeric suffix.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If there are no columns in the output table, a `No_Output_Columns` is
           raised as an error regardless of the problem behavior, because it is
           not possible to create a table without any columns.
         - If a column in `columns` is not in the input table, a
           `Missing_Input_Columns` is raised as an error, unless
           `error_on_missing_columns` is set to `False`, in which case the
           problem is reported according to the `on_problems` setting.
         - If any column names in the new table are clashing, a
           `Duplicate_Output_Column_Names` is reported according to the
           `on_problems` setting.

       ? Example Transpose Operation

         Input Table `table`:

            Id | Name    | Country
           ----|---------|---------
            A  | Example | France
            B  | Another | Germany

         Result `table.transpose ['Id'] 'Attribute' 'Value'`:

            Id | Attribute | Value
           ----|-----------|---------
            A  | Name      | Example
            A  | Country   | France
            B  | Name      | Another
            B  | Country   | Germany
    @key_columns Widget_Helpers.make_column_name_vector_selector
    transpose : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Text -> Text -> Boolean -> Problem_Behavior -> Table ! No_Output_Columns | Missing_Input_Columns | Duplicate_Output_Column_Names
    transpose self (key_columns = []) (attribute_column_name="Name") (value_column_name="Value") (error_on_missing_columns=True) (on_problems = Report_Warning) =
        columns_helper = self.columns_helper
        unique = self.column_naming_helper.create_unique_name_strategy
        problem_builder = Problem_Builder.new error_on_missing_columns=error_on_missing_columns

        id_columns = columns_helper.select_columns_helper key_columns Case_Sensitivity.Default False problem_builder

        selected_names = Map.from_vector (id_columns.map column-> [column.name, True])

        data = columns_helper.internal_columns.filter column->(selected_names.get column.name False . not)
        java_data = data.map .java_column

        java_id = id_columns.map .java_column

        unique.mark_used (id_columns.map .name)
        java_table = Java_Problems.with_problem_aggregator on_problems java_problem_aggregator->
            Java_Table.transpose java_id java_data (unique.make_unique attribute_column_name) (unique.make_unique value_column_name) java_problem_aggregator
        result = Table.Value java_table
        problem_builder.report_unique_name_strategy unique

        problem_builder.attach_problems_after on_problems result

    ## GROUP Standard.Base.Calculations
       ICON dataframe_map_column
       Returns a new table using a chosen field as the column header and then
       aggregating the rows within each value as specified. Optionally, a set of
       fields can be used to group the rows.

       Arguments:
       - group_by: Set of fields to group by. If not provided, a single row will
         be produced.
       - name_column: The field to use as the column header. If this field is
         not found, then each value will be a single column.
       - values: The aggregation to perform on each set of rows. Can be a single
         aggregation or a vector of aggregations. Expressions can be used within
         the aggregation to perform more complicated calculations.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

       ! Error Conditions

         - If a column in `group_by` or `name_column` is not in the input table,
           a `Missing_Input_Columns` is raised as a dataflow error.
         - If a column selector in `values` given as a `Text` and it does not
           match any columns in the input table nor is it a valid expression, an
           `Invalid_Aggregate_Column` dataflow error is raised.
         - If a column name generated from the input data is invalid,
           `Invalid_Column_Names` error is raised.
         - If an aggregation fails, an `Invalid_Aggregation` dataflow error is
           raised.
         - Additionally, the following problems may be reported according to the
           `on_problems` setting:
           - If grouping on, using as the column name, or computing the `Mode` on
             a floating point number, a `Floating_Point_Equality`.
           - If when concatenating values there is an quoted delimited,
             an `Unquoted_Delimiter`
           - If there are more than 10 issues with a single column,
             an `Additional_Warnings`.

       ? Example Cross Tab Operation

         Input Table `table`:

            Id | B       | C
           ----|---------|---------
            A  | Name    | Example
            A  | Country | France

         Result `table.cross_tab ['Id'] 'B' (Aggregate_Column.First 'C')`:

            Id | Name    | Country
           ----|---------|---------
            A  | Example | France
    @group_by Widget_Helpers.make_column_name_vector_selector
    @names Widget_Helpers.make_column_name_selector
    @values Widget_Helpers.make_aggregate_column_selector
    cross_tab : Vector (Integer | Text | Regex | Aggregate_Column) | Text | Integer | Regex -> (Text | Integer) -> Aggregate_Column | Vector Aggregate_Column -> Problem_Behavior -> Table ! Missing_Input_Columns | Invalid_Aggregate_Column | Floating_Point_Equality | Invalid_Aggregation | Unquoted_Delimiter | Additional_Warnings | Invalid_Column_Names
    cross_tab self group_by=[] names=self.column_names.first values=Aggregate_Column.Count (on_problems=Report_Warning) = Out_Of_Memory.handle_java_exception "cross_tab" <|
        columns_helper = self.columns_helper
        problem_builder = Problem_Builder.new error_on_missing_columns=True

        ## Normalize the group_by parameter to select columns
        normalize_group_by input = case input of
            Aggregate_Column.Group_By c _ -> c
            _ : Aggregate_Column -> Error.throw (Illegal_Argument.Error "Only Aggregate_Column.Group_By can be used for cross_tab group_by clause.")
            _ : Vector -> input.map on_problems=No_Wrap normalize_group_by
            _ -> input

        ## validate the name and group_by columns
        name_column_selector = case names of
            ix : Integer -> [ix]
            name : Text -> [name]
            _ -> Error.throw (Illegal_Argument.Error "name_column must be a column index or name.")
        matched_name = columns_helper.select_columns_helper name_column_selector Case_Sensitivity.Default True problem_builder
        grouping = columns_helper.select_columns_helper (normalize_group_by group_by) Case_Sensitivity.Default True problem_builder

        ## Validate the values
        values_vector = case values of
            _ : Vector -> values
            _ -> [values]
        resolved_values = values_vector.map on_problems=No_Wrap (Aggregate_Column_Helper.resolve_aggregate self problem_builder)
        is_group_by c = case c of
            Aggregate_Column.Group_By _ _ -> True
            _ -> False
        validated_values = if resolved_values.any is_group_by then Error.throw (Illegal_Argument.Error "Cannot use group_by for a cross_tab value.") else
            resolved_values.filter c->(c!=Nothing)

        problem_builder.attach_problems_before on_problems <| Illegal_Argument.handle_java_exception <|
            java_key_columns = grouping.map .java_column

            name_mapper = if matched_name.is_empty then Aggregate_Column_Helper.default_aggregate_column_name else
                if validated_values.length == 1 then (_ -> "") else
                    all_same = Aggregate_Column_Helper.all_same_column validated_values
                    include_column_name = all_same.not
                    c -> Aggregate_Column_Helper.default_aggregate_column_name c include_column_name

            data_columns = validated_values.map c->
                col_name = if c.as != "" then c.as else
                    Aggregate_Column_Helper.default_aggregate_column_name c
                Aggregate_Column_Helper.java_aggregator col_name c

            Java_Problems.with_problem_aggregator on_problems java_problem_aggregator->
                case matched_name.is_empty of
                    True ->
                        group_by = grouping.map g->(Aggregate_Column_Helper.java_aggregator g.name (Aggregate_Column.Group_By g))
                        index = self.java_table.indexFromColumns java_key_columns java_problem_aggregator
                        new_java_table = index.makeTable (group_by + data_columns)
                        Table.Value new_java_table
                    False ->
                        aggregate_names = validated_values.map c->
                            if c.as != "" then c.as else (name_mapper c)

                        too_many_columns caught_panic =
                            inner_panic = caught_panic.payload
                            Error.throw (Column_Count_Exceeded.Error inner_panic.getMaximumColumnCount inner_panic.getColumnCount)
                        Panic.catch TooManyColumnsException handler=too_many_columns <|
                            Invalid_Column_Names.handle_java_exception <|
                                new_java_table = self.java_table.makeCrossTabTable java_key_columns matched_name.first.java_column data_columns aggregate_names java_problem_aggregator
                                Table.Value new_java_table

    ## PRIVATE
       Returns a table with a continuous sub-range of rows taken.
    slice : Integer -> Integer -> Table
    slice self start end =
        length = self.row_count
        offset = (start.min length).max 0
        limit = ((end - offset).min (length - offset)).max 0
        Table.Value (self.java_table.slice offset limit)

    ## GROUP Standard.Base.Selections
       ICON order
       Returns a table containing the rows of `self` table with their order
       reversed.

       > Example
         Reverse the rows in a table.

             import Standard.Examples

             example_reverse = Examples.inventory_table.reverse
    reverse : Table
    reverse self =
        mask = OrderMask.reverse self.row_count
        Table.Value <| self.java_table.applyMask mask

    ## GROUP Standard.Base.Output
       ICON data_output
       This function writes a table from memory into a file.

       The specific behavior of the various `File_Format`s is specified below.

       Arguments:
       - path: The path to the output file.
       - format: The format of the file.
         If `Auto_Detect` is specified; the provided file determines the
         specific type and configures it appropriately. Details of this type are
         below.
       - on_existing_file: Specified how to handle if the file already exists.
       - match_columns: Specifies how to match columns against an existing file.
         If `Match_Columns.By_Name` - the columns are mapped by name against an
         existing file. If there is a mismatch, then a `Column_Name_Mismatch`
         error is raised.
         If `Match_Columns.By_Position` - the columns are mapped by position
         against an existing file. If there is a mismatch, then a
         `Column_Count_Mismatch` error is raised.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default. The specific issues depend on the `File_Format`
         argument.

       Returns:
       - If an unsupported `File_Format` is specified, an
         `Illegal_Argument` is raised.
       - If the path to the parent location cannot be found or the filename is
         invalid, a `File_Error.Not_Found` is raised.
       - If another IO error occurs, such as access denied, an
         `File_Error.IO_Error` is raised.
       - If appending and the columns do not match, a `Column_Mismatch` is
         raised.
       - Other specific errors or warnings that can be raised depend on the
         format argument.
       - On success, a `File` object for the written file is returned.

       ? `File_Format` write behaviors

         - `Auto_Detect`: The file format is determined by the provided file.
         - `Bytes` and `Plain_Text`: The Table does not support these types in
           the `write` function. If passed as format, an
           `Illegal_Argument` is raised. To write out the table as plain
           text, the user needs to call the `Text.from Table` method and then
           use the `Text.write` function.

       > Example
         Write a table to a CSV file, without writing the header.

             import Standard.Examples
             from Standard.Table import Delimited

             example_to_csv = Examples.inventory_table.write (Enso_Project.data / "example_csv_output.csv") (Delimited_Format.Delimited delimiter="," headers=False)

       > Example
         Write a table to an XLSX file.

             import Standard.Examples
             from Standard.Table import all

             example_to_xlsx = Examples.inventory_table.write (enso_project.data / "example_xlsx_output.xlsx") (Excel_Format.Sheet "MySheetName")
    @path (Widget.Text_Input display=Display.Always)
    @format Widget_Helpers.write_table_selector
    write : Writable_File -> File_Format -> Existing_File_Behavior -> Match_Columns -> Problem_Behavior -> File ! Column_Count_Mismatch | Illegal_Argument | File_Error
    write self path:Writable_File format=Auto_Detect on_existing_file=Existing_File_Behavior.Backup match_columns=Match_Columns.By_Name on_problems=Report_Warning =
        File_Format.handle_format_missing_arguments format <| case format of
            _ : Auto_Detect ->
                base_format = format.get_writing_format path
                if base_format == Nothing then Error.throw (File_Error.Unsupported_Output_Type path.file Table) else
                    self.write path format=base_format on_existing_file match_columns on_problems
            _ ->
                handle_no_write_method caught_panic =
                    is_write = caught_panic.payload.method_name == "write_table"
                    if is_write.not then Panic.throw caught_panic else
                        Error.throw (File_Error.Unsupported_Output_Type format Table)
                Panic.catch No_Such_Method handler=handle_no_write_method <|
                    to_write = if Context.Output.is_enabled then self else self.take 1000
                    format.write_table path to_write on_existing_file match_columns on_problems

    ## ICON convert
       Creates a text representation of the table using the CSV format.
    to_csv : Text
    to_csv self = Text.from self (Delimited_Format.Delimited delimiter=",")

    ## GROUP Standard.Base.Conversions
       ICON convert
       Returns an `XML_Document` representation of the table.
       Arguments:
       - element_columns: Columns to be used as elements in the XML.
       - attribute_columns: Columns to be used as attributes in the XML.
       - value_column: Column to be used as the value for the row tag in the XML.
       - root_name: The name of the root tag in the XML.
       - row_name: The name of the row tag in the XML.
       - on_problems: Specifies how to handle warnings if they occur, reporting
         them as warnings by default.     

       ! Error Conditions

         - If a column in `element_columns`, `attribute_columns` or `value_column` is not in 
           the input table, a `Missing_Input_Columns` is raised as an error.
         - If any incomming columns aree not specified in one of `element_columns`, 
           `attribute_columns` or `value_column`, a `Unexpected_Extra_Columns`
           is reported according to the `on_problems` setting.

       ? Example to_xml Operation

         Input Table `table`:

            Title                  | Author              | Price | Year 
           ------------------------+---------------------+-------+------
            A Tale Of Two Cities   | Charles Dickens     | 9.99  | 1859 
            The Great Gatsby       | F. Scott Fitzgerald | 5.99  | 1925 

         Result `r = t.to_xml ["Year"] ["Author", "Price"] "Title" "Books" "Book"`:

            <Books>
              <Book Author="Charles Dickens" Price="9.99">
                A Tale Of Two Cities
                <Year>1859</Year>
              </Book>
              <Book Author="F. Scott Fitzgerald" Price="5.99">
                The Great Gatsby
                <Year>1925</Year>
              </Book>
            </Books>
    @element_columns Widget_Helpers.make_column_name_vector_selector
    @attribute_columns Widget_Helpers.make_column_name_vector_selector
    @value_column Widget_Helpers.make_column_name_selector
    to_xml self (element_columns : (Vector (Integer | Text | Regex) | Text | Integer | Regex) = self.column_names) (attribute_columns : (Vector (Integer | Text | Regex) | Text | Integer | Regex) = []) (value_column : Text | Integer | Nothing = Nothing) (root_name : Text = "Table") (row_name : Text = "Row") (on_problems : Problem_Behavior = Report_Warning) -> XML_Document =
        columns_helper = self.columns_helper
        problem_builder = Problem_Builder.new error_on_missing_columns=True
        resolved_element_columns = columns_helper.select_columns_helper element_columns Case_Sensitivity.Default False problem_builder
        java_element_columns = resolved_element_columns.map .java_column

        resolved_attribute_columns = columns_helper.select_columns_helper attribute_columns Case_Sensitivity.Default False problem_builder
        java_attribute_column = resolved_attribute_columns.map .java_column

        resolved_value_column = if value_column.is_nothing then Nothing else (self.at value_column)
        java_value_column = if value_column.is_nothing then Nothing else resolved_value_column.java_column

        unused_columns = columns_helper.internal_columns.filter (Filter_Condition.Is_In resolved_element_columns+resolved_attribute_columns+[resolved_value_column] Filter_Action.Remove) . map .name
        if unused_columns.length > 0 then problem_builder.report_other_warning (Unexpected_Extra_Columns.Warning unused_columns)
        
        problem_builder.attach_problems_before on_problems <|
            XML_Document.Value (Java_TableToXml.to_xml self.row_count java_element_columns java_attribute_column java_value_column root_name row_name)

    ## PRIVATE
    columns_helper : Table_Column_Helper
    columns_helper self =
        Table_Helpers.Table_Column_Helper.Value self.columns (x->x) self (x->x)

    ## ALIAS fill missing, if_nothing
       GROUP Standard.Base.Values
       ICON dataframe_clean

       Returns a new table where missing values in the specified columns have
       been replaced with the provided default(s).

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - default: The value to replace missing values with. If this argument
         is a column, the value from `default` at the corresponding position
         will be used. If this argument is `Previous_Value`, the missing values
         will be replaced with the previous value in the column. Note that the
         first rows may stay `Nothing` if they do not have a previous value to
         use.

       > Example
         Fill missing values in two columns with the value 20.5.

             fill_nothing = table.fill_nothing ["col0", "col1"] 20.5
    @columns Widget_Helpers.make_column_name_vector_selector
    @default (self -> Widget_Helpers.make_fill_default_value_selector column_source=self add_text=True add_number=True add_boolean=True)
    fill_nothing : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Column | Column_Ref | Expression | Previous_Value | Any -> Table
    fill_nothing self (columns : Vector | Text | Integer | Regex) default =
        resolved_default = (self:Table_Ref).resolve default
        transformer col = col.fill_nothing resolved_default
        Table_Helpers.replace_columns_with_transformed_columns self columns transformer

    ## ALIAS fill empty, if_empty
       GROUP Standard.Base.Values
       ICON dataframe_clean

       Returns a new column where empty Text values have been replaced with the
       provided default(s).

       Arguments:
       - columns: Specifies columns by a name, index or regular expression to
         match names, or a Vector of these.
       - default: The value to replace empty values with. If this argument
         is a column, the value from `default` at the corresponding position
         will be used. If this argument is `Previous_Value`, the empty values
         will be replaced with the previous value in the column. Note that the
         first rows may stay empty if they do not have a previous value to use.

       > Example
         Fill empty values in two columns with the value "hello".

             fill_empty = table.fill_empty ["col0", "col1"] "hello"
    @columns Widget_Helpers.make_column_name_vector_selector
    @default (self -> Widget_Helpers.make_fill_default_value_selector column_source=self add_text=True)
    fill_empty : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Column | Column_Ref | Expression | Previous_Value | Any -> Table
    fill_empty self (columns : Vector | Text | Integer | Regex) default =
        resolved_default = (self:Table_Ref).resolve default
        transformer col = col.fill_empty resolved_default
        Table_Helpers.replace_columns_with_transformed_columns self columns transformer

    ## GROUP Standard.Base.Text
       ICON dataframe_map_column
       Replaces the first, or all occurrences of `term` with `new_text` in each
       row of the specified column. If `term` is empty, the function returns the
       table unchanged.

       This method follows the exact replacement semantics of the
       `Text.replace` method.

       Arguments:
       - columns: The column(s) to replace values on.
       - term: The term to find. Can be `Text`, `Regex`, or a `Column` of
         strings.
       - replacement: The text to replace matches with.
       - case_sensitivity: Specifies if the text values should be compared case
         sensitively.
       - only_first: If True, only replace the first match.

       > Example
         Replace dashes with underscores.

             table.text_replace ["Input"] "-" "_"

       > Example
         Remove leading and trailing spaces from cells.

             table.text_replace ["Input"] "^\s*(.*?)\s*$".to_regex "$1"

       > Example
         Replace texts in quotes with parentheses.

             table.text_replace ["Input"] '"(.*?)"'.to_regex '($1)'
    @columns Widget_Helpers.make_column_name_vector_selector
    @term (Widget_Helpers.make_column_ref_by_name_selector add_regex=True add_text=True)
    @new_text (Widget_Helpers.make_column_ref_by_name_selector add_text=True)
    text_replace : Vector (Integer | Text | Regex) | Text | Integer | Regex -> Text | Column | Column_Ref | Expression | Regex -> Text | Column | Column_Ref | Expression -> Case_Sensitivity -> Boolean -> Column
    text_replace self columns (term : Text | Column | Column_Ref | Expression | Regex = "") (new_text : Text | Column | Column_Ref | Expression = "") case_sensitivity=Case_Sensitivity.Sensitive only_first=False =
        table_ref = Table_Ref.from self
        resolved_term = table_ref.resolve term
        resolved_new_text = table_ref.resolve new_text
        transformer col = col.text_replace resolved_term resolved_new_text case_sensitivity only_first
        Table_Helpers.replace_columns_with_transformed_columns self columns transformer

    ## PRIVATE
       ALIAS cumulative
       GROUP Standard.Base.Values
       ICON dataframe_map_column
       Adds a new column to the table with a running calculation.

       Arguments:
       - statistic: The running statistic to calculate.
       - of: The existing column to run the statistic over.
       - as: The name of the new column.
       - group_by: Specifies the columns to group by. The running statistic is
         calculated separately for each group. By default, all rows are treated as
         a single group.
       - order_by: Specifies the columns to order by. Defaults to the order of
         the rows in the table. The running statistic is calculated according to the
         specified ordering.

       ? Ordering of rows

         Note that the ordering of rows from the original table is preserved in
         all cases. The grouping and ordering settings affect how the running statistic is
         calculated for each row, but the order of the rows itself is
         not changed by this operation.

       ! Error Conditions

         - If the columns specified in `group_by` or `order_by` are not present
           in the table, a `Missing_Input_Columns` error is raised.
         - If the column with the same name as provided by `as` already exists,
           a `Duplicate_Output_Column_Names` problem is reported and the
           existing column is renamed to avoid the clash.
         - If grouping on floating point numbers, a `Floating_Point_Equality`
           problem is reported.
    @group_by Widget_Helpers.make_column_name_vector_selector
    @order_by Widget_Helpers.make_order_by_selector
    @of Widget_Helpers.make_column_name_selector
    running : Statistic -> (Text | Integer) -> Text -> Vector (Text | Integer | Regex) | Text | Integer | Regex -> Vector (Text | Sort_Column) | Text -> Problem_Behavior -> Table
    running self (statistic:Statistic=Statistic.Count) (of:(Text | Integer)=0) (as:Text='') (group_by:(Vector | Text | Integer | Regex)=[]) (order_by:(Vector | Text)=[]) (on_problems:Problem_Behavior=Problem_Behavior.Report_Warning) =
        if statistic != Statistic.Count then Error.throw (Illegal_Argument.Error ("Currently only Statistic.Count is supported in Table.running.")) else
          of_col = self.at of
          new_name = if as == '' then 'Running ' + statistic.to_text + ' of ' + of_col.name else as
          Add_Row_Number.add_row_number self new_name 1 1 group_by order_by on_problems

    ## PRIVATE
    column_naming_helper : Column_Naming_Helper
    column_naming_helper self = Column_Naming_Helper.in_memory

    ## ALIAS from
       GROUP Standard.Base.Calculations
       ICON select_column
       Appends records from the vector of tables into a single table.

       Arguments:
       - tables: A vector of tables to union  together. The
         tables are concatenated in the order they are specified.
       - match_columns: Specifies how to match the columns.
         - If `Match_Columns.By_Name` - the columns are matched by name across
           all provided tables.
           If unmatched columns are to be dropped, the resulting table will keep
           only the set of columns that appear in all provided tables, in the
           relative order that they appeared in the `self` table.
           If unmatched columns are kept, they are added in the order of
           appearance - i.e. first all columns from `self` will be added in the
           original order, then any columns from the second table that were not
           matched will be added at the end (preserving their relative order),
           and so on for all the remaining tables.
         - If `Match_Columns.By_Position` - the columns are mapped by position.
           If unmatched columns are to be dropped, the resulting table will have
           as many columns as the table that had the least columns and the
           column names of the first table (self) will be used.
           If unmatched columns are kept, the resulting table will have as many
           columns as the table with the most columns. Since the first table may
           not have all the necessary columns to provide column names for the
           result, the result will have column names taken from the first table
           that has the biggest number of columns.
       - keep_unmatched_columns: If set to `True`, unmatched columns are kept
         and are padded with `Nothing` for tables that did not have them.
         If set to `False`, only the common subset of columns is kept - any
         column that is not present in all tables is dropped. Defaults to
         `Report_Unmatched`, which behaves like `True` - unmatched columns are
         kept and padded with `Nothing`, but a problem is reported.
       - allow_type_widening: Specifies if the resulting column type should be
         adjusted to fit columns from all arguments. If `True`, a common type
         will be chosen for each column (see "Unifying Column Types" below).
         If `False`, the resulting column type will be the same as in the first
         table containing the column. In this case, all columns that are
         concatenated must have the same type as the first one (unless this
         had a `Mixed` type - in which case it will accept any other types).
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         - If `keep_unmatched_columns` is set to `Report_Unmatched` (the
           default):
           - If matching by name and there are columns that are not present in
             all tables, `Unmatched_Columns` is reported.
           - If matching by position and column counts of the merged tables
             differ, then a `Column_Count_Mismatch` is reported. The error will
             contain the greatest column count as its `expected` value and the
             smallest one as its `actual` value.
         - If `keep_unmatched_columns` is set to `False` and matching by name,
           it is possible that there are no columns that are common to all
           provided tables, in that case `No_Output_Columns` is thrown as a
           dataflow error regardless of the `on_problems` setting, because there
           are no columns to include in the resulting table.
         - If type widening is disabled and one of corresponding columns has a
           type that is incompatible with the type coming from the first table,
           a `Column_Type_Mismatch` is reported. The problematic column will be
           dropped from the resulting table. With type widening disabled, the
           subsequent tables must have the same types as the first one, unless
           the type of the first one was `Mixed` which will accept any other
           type.
         - If a common type coercion for a set of matched columns from
           concatenated tables cannot be found, a `No_Common_Type` is reported.
           In warning or ignore mode, the problematic column will be dropped
           from the resulting table.

       ? Unifying Column Types

         If `allow_type_widening` is set to `True`, then the following rules are
         used to find a common type that will fit values from all merged tables.

         Numeric columns are unified by finding the most general type that can
         fit all of the columns. The biggest integer type will be chosen and if
         integers and decimals are mixed, the decimal type will be chosen.
         If boolean columns are mixed with numeric columns, they will be coerced
         to the numeric type (and converted to 0 and 1).

         Text types will also be coerced according to the common rules - if
         constant-length texts of different lengths are mixed, they will be
         coerced to a varying-length type.

         If one of the matched columns has `Mixed` type, that type will be used
         regardless of types of other columns. Mixing any other types will
         result in a `No_Common_Type` problem. If columns of incompatible types
         are meant to be mixed, at least one of them should be explicitly
         retyped to the `Mixed` type to indicate that intention. Note that the
         `Mixed` type may not be supported by most Database backends.
    from_union : (Vector Table) -> Match_Columns -> Boolean | Report_Unmatched -> Boolean -> Problem_Behavior -> Table
    from_union tables:Vector=[] match_columns=Match_Columns.By_Name keep_unmatched_columns=Report_Unmatched allow_type_widening=True on_problems=Report_Warning =
        all_tables = (tables.map t-> Table.from t)
        all_tables.if_not_error <|
            ## We keep separate problem builders, because if we are reporting `No_Output_Columns`,
               we only want to add a cause coming from unification; matching reports problems that would not fit this error.
            problem_builder_for_matching = Problem_Builder.new
            problem_builder_for_unification = Problem_Builder.new
            matched_column_sets = Match_Columns_Helpers.match_columns all_tables match_columns keep_unmatched_columns problem_builder_for_matching
            result_row_count = all_tables.fold 0 c-> t-> c + t.row_count
            merged_columns = matched_column_sets.map column_set->
                case Table_Helpers.unify_result_type_for_union column_set all_tables allow_type_widening problem_builder_for_unification of
                    Nothing -> Nothing
                    result_type : Value_Type ->
                        concat_columns column_set all_tables result_type result_row_count on_problems
            good_columns = merged_columns.filter Filter_Condition.Not_Nothing
            problem_builder_for_matching.attach_problems_before on_problems <|
                problem_builder_for_unification.attach_problems_before on_problems <|
                    if good_columns.is_empty then problem_builder_for_unification.raise_no_output_columns_with_cause else
                        Table.new good_columns
## PRIVATE

   Ensures that the `txt` has at least `len` characters by appending spaces at
   the end.

   Arguments:
   - txt: The text to pad.
   - len: The minimum length of the text.
pad : Text -> Integer -> Text
pad txt len =
    true_len = txt.characters.length
    txt + (" ".repeat (len - true_len))

## PRIVATE

   Adds ANSI bold escape sequences to text if the feature is enabled.

   Arguments:
   - enabled: will insert ANSI sequences only if this flag is true and we are not on Windows.
   - txt: The text to possibly bold.
ansi_bold : Boolean -> Text -> Text
ansi_bold enabled txt =
    case Platform.os of
        ## Output formatting for Windows is not currently supported.
        Platform.OS.Windows -> txt
        _ -> if enabled then '\e[1m' + txt + '\e[m' else txt

## PRIVATE

   A helper function for creating an ASCII-art representation of tabular data.

   Arguments:
   - header: vector of names of columns in the table.
   - rows: a vector of rows, where each row is a vector that contains a text
     representation of each cell
   - indices_count: the number specifying how many columns should be treated as
     indices; this will make them in bold font if `format_term` is enabled.
   - format_term: a boolean flag, specifying whether to use ANSI escape codes
     for rich formatting in the terminal.
print_table : Vector Text -> (Vector (Vector Text)) -> Integer -> Boolean -> Text
print_table header rows indices_count format_term =
    content_lengths = Vector.new header.length i->
        max_row = 0.up_to rows.length . fold 0 a-> j-> a.max (rows.at j . at i . characters . length)
        max_row.max (header.at i . characters . length)
    header_line = header.zip content_lengths pad . map (ansi_bold format_term) . join ' | '
    divider = content_lengths . map (l -> "-".repeat l+2) . join '+'
    row_lines = rows.map r->
        x = r.zip content_lengths pad
        ixes = x.take (First indices_count) . map (ansi_bold format_term)
        with_bold_ix = ixes + x.drop (First indices_count)
        y = with_bold_ix . join ' | '
        " " + y
    ([" " + header_line, divider] + row_lines).join '\n'

## PRIVATE
   A helper to create a new table consisting of slices of the original table.
slice_ranges table ranges =
    normalized = Index_Sub_Range_Module.normalize_ranges ranges
    Table.Value (table.java_table.slice normalized)

## PRIVATE
make_join_helpers left_table right_table =
    make_equals _ left right = Java_Join_Equals.new left.java_column right.java_column
    make_equals_ignore_case _ left right locale =
        Java_Join_Equals_Ignore_Case.new left.java_column right.java_column locale.java_locale
    make_between _ left right_lower right_upper =
        Java_Join_Between.new left.java_column right_lower.java_column right_upper.java_column
    Join_Helpers.Join_Condition_Resolver.Value (left_table.at _) (right_table.at _) make_equals make_equals_ignore_case make_between

## PRIVATE
   A helper that efficiently concatenates storages of in-memory columns.
concat_columns column_set all_tables result_type result_row_count on_problems =
    Java_Problems.with_problem_aggregator on_problems java_problem_aggregator->
        storage_builder = make_storage_builder_for_type result_type on_problems initial_size=result_row_count java_problem_aggregator
        column_set.column_indices.zip all_tables i-> parent_table->
            case i of
                Nothing ->
                    null_row_count = parent_table.row_count
                    storage_builder.appendNulls null_row_count
                _ : Integer ->
                    storage = parent_table.at i . java_column . getStorage
                    storage_builder.appendBulkStorage storage
        sealed_storage = storage_builder.seal
        Column.from_storage column_set.name sealed_storage

## PRIVATE
   A helper that creates a two-column table from a map.
map_to_lookup_table : Map Any Any -> Text -> Text -> Table
map_to_lookup_table map key_column value_column =
    keys_and_values = map.to_vector
    Table.new [[key_column, keys_and_values.map .first], [value_column, keys_and_values.map .second]]

## PRIVATE
   Conversion method to a Table from a Column.
Table.from (that:Column) = that.to_table

## PRIVATE
   Converts a Text value into a Table.

   The format of the text is determined by the `format` argument.

   Arguments:
   - that: The text to convert.
   - format: The format of the text.
   - on_problems: What to do if there are problems reading the text.
Table.from (that : Text) (format:Delimited_Format = Delimited_Format.Delimited '\t') (on_problems:Problem_Behavior=Report_Warning) =
    File_Format.handle_format_missing_arguments format <| case format of
        _ : Delimited_Format -> Delimited_Reader.read_text that format on_problems
        _ -> Unimplemented.throw "Table.from is currently only implemented for Delimited_Format."

## PRIVATE
   Converts a Table into a Text value.

   The format of the text is determined by the `format` argument.

   Arguments:
   - that: The table to convert.
   - format: The format of the text.
Text.from (that : Table) (format:Delimited_Format = Delimited_Format.Delimited '\t') =
    Delimited_Writer.write_text that format

## PRIVATE
   Conversion method to a Table from a Vector.
Table.from (that:Vector) (fields : (Vector | Nothing) = Nothing) = that.to_table fields

## PRIVATE
   Conversion method to a Table from a JS_Object.
Table.from (that:JS_Object) (fields : (Vector | Nothing) = Nothing) =
    Table.from_objects that fields

## PRIVATE
   Conversion method to a Column from a Vector.
Table.from (that:Range) (name:Text="Range") = Table.new [Column.from_vector name that.to_vector]

## PRIVATE
   Conversion method to a Column from a Vector.
Table.from (that:Date_Range) (name:Text=that.default_column_name) = Table.new [Column.from_vector name that.to_vector]

## PRIVATE
   Convert an `XML_Element` into a `Table`

   Generates a single-row table with columns for the tag's contents.

   Arguments:
   - that: The XML_Element to convert

   The columns generated are:
   - Name: the root tag name
   - @[attribute name]: the attribute with that name.
   - Children: the children of the tag, including `XML_Element`s and text
     elements. This is only generated if the tag has `XML_Element` children
   - Value: the text content of the tag. This is only generated if the tag does
     not have `XML_Element` children

   Either `Children` or `Value` will be generated, but not both.
Table.from (that:XML_Element) =
    # Generating a table from an `XML_Element` is the same logic as `expand_column`
    Table.new [["x", [that]]] . expand_column 'x' prefix=Prefix_Name.None

## PRIVATE
   Convert an `XML_Document` into a `Table`

   Generates a single-row table with columns for the root tag's contents.

   Arguments:
   - that: The XML_Document to convert

   The columns generated are:
   - Name: the root tag name
   - @[attribute name]: the attribute with that name
   - Children: the children of the tag, including `XML_Element`s and text
     elements. This is only generated if the tag has `XML_Element` children
   - Value: the text content of the tag. This is only generated if the tag does
     not have `XML_Element` children

   Either `Children` or `Value` will be generated, but not both.
Table.from (that:XML_Document) = Table.from that.root_element
