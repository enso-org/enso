from Standard.Base import all hiding First, Last
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument
import Standard.Base.Errors.Illegal_State.Illegal_State
import Standard.Base.Errors.Unimplemented.Unimplemented

import Standard.Table.Internal.Problem_Builder.Problem_Builder
import Standard.Table.Internal.Vector_Builder.Vector_Builder
from Standard.Table import Aggregate_Column, Column, Value_Type
from Standard.Table.Aggregate_Column.Aggregate_Column import all
from Standard.Table.Errors import Inexact_Type_Coercion
from Standard.Table.Internal.Storage import get_storage_for_column

import Standard.Database.Connection.Connection.Connection
import Standard.Database.DB_Column.DB_Column
import Standard.Database.DB_Table.DB_Table
import Standard.Database.Dialect
import Standard.Database.Internal.Base_Generator
import Standard.Database.Internal.Common.Database_Distinct_Helper
import Standard.Database.Internal.Common.Database_Join_Helper
import Standard.Database.Internal.Error_Mapper.Error_Mapper
import Standard.Database.Internal.Internals_Access
import Standard.Database.Internal.IR.Context.Context
import Standard.Database.Internal.IR.Context.Context_Extension
import Standard.Database.Internal.IR.From_Spec.From_Spec
import Standard.Database.Internal.IR.Internal_Column.Internal_Column
import Standard.Database.Internal.IR.Nulls_Order.Nulls_Order
import Standard.Database.Internal.IR.Order_Descriptor.Order_Descriptor
import Standard.Database.Internal.IR.Query.Query
import Standard.Database.Internal.IR.SQL_Expression.SQL_Expression
import Standard.Database.Internal.IR.SQL_Join_Kind.SQL_Join_Kind
import Standard.Database.Internal.Replace_Params.Replace_Params
import Standard.Database.Internal.SQL_Type_Mapping.SQL_Type_Mapping
import Standard.Database.Internal.SQL_Type_Reference.SQL_Type_Reference
import Standard.Database.Internal.Statement_Setter.Statement_Setter
import Standard.Database.SQL.SQL_Builder
import Standard.Database.SQL.SQL_Fragment
import Standard.Database.SQL_Statement.SQL_Statement
import Standard.Database.SQL_Type.SQL_Type
from Standard.Database.Dialect import Temp_Table_Style
from Standard.Database.Dialect_Flags import all
from Standard.Database.Errors import SQL_Error, Unsupported_Database_Operation
from Standard.Database.Feature import Feature
from Standard.Database.Internal.Base_Generator import lift_binary_op
from Standard.Database.Internal.IR.Operation_Metadata import Date_Period_Metadata
from Standard.Database.Internal.JDBC_Connection import JDBC_Connection
from Standard.Database.Internal.Statement_Setter import fill_hole_default

import project.Internal.SQLServer_Error_Mapper.SQLServer_Error_Mapper
import project.Internal.SQLServer_Type_Mapping.SQLServer_Type_Mapping

polyglot java import java.sql.Types as Java_Types
polyglot java import org.enso.database.JDBCUtils

## PRIVATE
   The dialect of SQL Server databases.
sqlserver : SQLSever_Dialect
sqlserver =
    SQLSever_Dialect.Value make_dialect_operations

## PRIVATE
   The dialect of SQL Server databases.
type SQLSever_Dialect
    ## PRIVATE
       The dialect of SQL Server databases.
    Value dialect_operations

    ## PRIVATE
       Name of the dialect.
    name : Text
    name self = sqlserver_dialect_name

    ## PRIVATE
    to_text : Text
    to_text self = "SQL_Server_Dialect"

    ## PRIVATE
       A function which generates SQL code from the internal representation
       according to the specific dialect.
    generate_sql : Query -> SQL_Statement
    generate_sql self query =
        Base_Generator.generate_query self query . build

    ## PRIVATE
       Generates SQL to truncate a table.
    generate_truncate_table_sql : Text -> SQL_Builder
    generate_truncate_table_sql self table_name =
        Base_Generator.truncate_table_truncate_table_style self table_name

    ## PRIVATE
       Generates SQL modifier for limiting the number of rows and its position in the query
    get_limit_sql_modifier : Integer -> Any
    get_limit_sql_modifier self limit =
        [150, SQL_Builder.code (" TOP " + limit.to_text)]

    ## PRIVATE
       Wraps and possibly escapes the identifier so that it can be used in a
       generated query regardless of what characters it contains.
       The quotes used will depend on the dialect.
    wrap_identifier : Text -> Text
    wrap_identifier self identifier =
        Base_Generator.wrap_in_quotes identifier

    ## PRIVATE
       Prepares an ordering descriptor.

       One of the purposes of this method is to verify if the expected ordering
       settings are supported by the given database backend.

       Arguments:
       - internal_column: the column to order by.
       - sort_direction: the direction of the ordering.
       - text_ordering: If provided, specifies that the column should be treated
         as text values according to the provided ordering. For non-text types,
         it should be set to `Nothing`.
    prepare_order_descriptor : Internal_Column -> Sort_Direction -> Nothing | Text_Ordering -> Order_Descriptor
    prepare_order_descriptor self internal_column sort_direction text_ordering =
        make_order_descriptor internal_column sort_direction text_ordering

    ## PRIVATE
       Prepares a distinct operation.
    prepare_distinct : DB_Table -> Vector -> Case_Sensitivity -> Problem_Builder -> DB_Table
    prepare_distinct self table key_columns case_sensitivity problem_builder =
        table_name_deduplicator = table.connection.base_connection.table_naming_helper.create_unique_name_strategy
        table_name_deduplicator.mark_used table.name
        inner_table_alias = table_name_deduplicator.make_unique table.name+"_inner"
        setup = table.context.as_subquery inner_table_alias [table.internal_columns]
        new_columns = setup.new_columns.first
        column_mapping = Dictionary.from_vector <| new_columns.map c-> [c.name, c]
        new_key_columns = key_columns.map c-> column_mapping.at c.name
        type_mapping = self.get_type_mapping
        distinct_expressions = new_key_columns.map column->
            value_type = type_mapping.sql_type_to_value_type column.sql_type_reference.get
            Database_Distinct_Helper.make_distinct_expression case_sensitivity problem_builder column value_type
        new_context = Context.for_subquery setup.subquery . add_extension (make_distinct_extension distinct_expressions)
        table.updated_context_and_columns new_context new_columns subquery=True

    ## PRIVATE
       Returns the mapping between SQL types of this dialect and Enso
       `Value_Type`.
    get_type_mapping : SQL_Type_Mapping
    get_type_mapping self = SQLServer_Type_Mapping

    ## PRIVATE
    get_statement_setter : Statement_Setter
    get_statement_setter self =
        custom_fill_hole stmt i type_hint value = case value of
            Nothing ->
                java_type = case type_hint of
                    Nothing -> Java_Types.NULL
                    _ ->
                        ## SQLServer needs its NULLS to be typed at least for TIME.
                        type_mapping = self.get_type_mapping
                        sql_type = type_mapping.value_type_to_sql type_hint Problem_Behavior.Ignore
                        sql_type.typeid                            
                stmt.setNull i java_type
            _ : Time_Of_Day -> JDBCUtils.setLocalTimeViaTimeStamp stmt i value
            # Fallback to default logic for everything else
            _ -> fill_hole_default stmt i type_hint value
        Statement_Setter.Value custom_fill_hole
    ## PRIVATE
    make_cast : Internal_Column -> SQL_Type -> (SQL_Expression -> SQL_Type_Reference) -> Internal_Column
    make_cast self column target_type infer_result_type_from_database_callback =
        mapping = self.get_type_mapping
        source_type = mapping.sql_type_to_value_type column.sql_type_reference.get
        target_value_type = mapping.sql_type_to_value_type target_type
        # Boolean to Numeric casts need special handling:
        transformed_expression = case source_type.is_boolean && target_value_type.is_numeric of
            True ->
                SQL_Expression.Operation "IIF" [Internals_Access.column_expression column, SQL_Expression.Literal "1", SQL_Expression.Literal "0"]
            False -> Internals_Access.column_expression column
        target_type_sql_text = mapping.sql_type_to_text target_type
        new_expression = SQL_Expression.Operation "CAST" [transformed_expression, SQL_Expression.Literal target_type_sql_text]
        new_sql_type_reference = infer_result_type_from_database_callback new_expression
        Internal_Column.Value column.name new_sql_type_reference new_expression

    ## PRIVATE
    needs_execute_query_for_type_inference : Text | SQL_Statement -> Boolean
    needs_execute_query_for_type_inference self statement =
        _ = statement
        False

    ## PRIVATE
       Specifies if the Database backend supports WITH clauses in nested queries.
    supports_nested_with_clause : Boolean
    supports_nested_with_clause self = False

    ## PRIVATE
    supports_separate_nan : Boolean
    supports_separate_nan self = True

    ## PRIVAITE
       Specifies implementation details flags.
    dialect_flags : Dialect_Flags
    dialect_flags self -> Dialect_Flags =
        rounding = Rounding_Flags.Value supports_negative_decimal_places=True supports_float_decimal_places=True use_builtin_bankers=False
        primary_key = Primary_Key_Flags.Value allows_nulls=False
        Dialect_Flags.Value rounding=rounding primary_key=primary_key

    ## PRIVATE
       Specifies how the database creates temp tables.
    temp_table_style : Temp_Table_Style
    temp_table_style self = Temp_Table_Style.Hash_Prefix

    ## PRIVATE
    adapt_unified_column : Internal_Column -> Value_Type -> (SQL_Expression -> SQL_Type_Reference) -> Internal_Column
    adapt_unified_column self column approximate_result_type infer_result_type_from_database_callback =
        _ = [approximate_result_type, infer_result_type_from_database_callback]
        column

    ## PRIVATE
       Add an extra cast to adjust the output type of certain operations with
       certain arguments.

       It is used when the normal type inference provided by the database engine
       needs to be adjusted.

       In most cases this method will just return the expression unchanged, it
       is used only to override the type in cases where the default one that the
       database uses is not what we want.
    cast_op_type self (op_kind:Text) (args:(Vector Internal_Column)) (expression:SQL_Expression) =
        _ = [op_kind, args]
        expression

    ## PRIVATE
    prepare_fetch_types_query : SQL_Expression -> Context -> SQL_Statement
    prepare_fetch_types_query self expression context =
        Base_Generator.default_fetch_types_query self expression context where_filter_always_false_literal="1=0"

    ## PRIVATE
    check_aggregate_support : Aggregate_Column -> Boolean ! Unsupported_Database_Operation
    check_aggregate_support self aggregate =
        _ = aggregate
        True

    ## PRIVATE
       Checks if an operation is supported by the dialect.
    is_operation_supported self operation:Text -> Boolean =
        self.dialect_operations.is_operation_supported operation

    ## PRIVATE
       Checks if a feature is supported by the dialect.
    is_feature_supported self feature:Feature -> Boolean =
        case feature of
            Feature.Select_columns -> False
            Feature.Filter -> False
            _ -> True

    ## PRIVATE
       The default table types to use when listing tables.
    default_table_types : Vector Text
    default_table_types self =
        ["TABLE", "VIEW", "TEMPORARY TABLE", "TEMPORARY VIEW", "MATERIALIZED VIEW"]

    ## PRIVATE
    get_error_mapper : Error_Mapper
    get_error_mapper self = SQLServer_Error_Mapper

    ## PRIVATE
       The dialect-dependent strategy to get the Primary Key for a given table.

       Returns `Nothing` if the key is not defined.
    fetch_primary_key : Connection -> Text -> Vector Text ! Nothing
    fetch_primary_key self connection table_name =
        Dialect.default_fetch_primary_key connection table_name

    ## PRIVATE
       Prepares metadata for an operation taking a date/time period and checks
       if the given period is supported.
    prepare_metadata_for_period : Date_Period | Time_Period -> Value_Type -> Any
    prepare_metadata_for_period self period operation_input_type =
        Date_Period_Metadata.Value period operation_input_type

    ## PRIVATE
       Returns true if the `replace` parameters are supported by this backend.
    if_replace_params_supports : Replace_Params -> Any -> Any
    if_replace_params_supports self replace_params ~action =
        if supported_replace_params.contains replace_params then action else replace_params.throw_unsupported sqlserver_dialect_name

    ## PRIVATE
    value_type_for_upload_of_existing_column : DB_Column -> Value_Type
    value_type_for_upload_of_existing_column self column = case column of
        # Return the type as-is for database columns.
        _ : DB_Column -> column.value_type
        _ : Column ->
            base_type = column.value_type
            case base_type of
                Value_Type.Decimal precision scale ->
                    used_scale = scale.if_nothing 12
                    used_precision = Math.min 38 precision.if_nothing 38
                    new_type = Value_Type.Decimal used_precision used_scale
                    if used_scale==scale && used_precision==precision then new_type else
                        Warning.attach (Inexact_Type_Coercion.Warning base_type new_type unavailable=False) new_type
                _ -> base_type

    ## PRIVATE
    needs_literal_table_cast : Value_Type -> Boolean
    needs_literal_table_cast self value_type =
        _ = value_type
        False

    ## PRIVATE
    ensure_query_has_no_holes : JDBC_Connection -> Text -> Nothing ! Illegal_Argument
    ensure_query_has_no_holes self jdbc:JDBC_Connection raw_sql:Text =
        ## The jdbc driver doesn't work for asking about holes for SQLServer temp tables
           We can skip this check and still get a decent error message
        if raw_sql.contains "#" . not then
            jdbc.ensure_query_has_no_holes raw_sql

## PRIVATE
make_dialect_operations =
    cases = [["LOWER", Base_Generator.make_function "LOWER"], ["UPPER", Base_Generator.make_function "UPPER"]]
    text = [starts_with, contains, ends_with, agg_shortest, agg_longest, make_case_sensitive, ["REPLACE", replace], left, right]+concat_ops+cases+trim_ops
    counts = [agg_count_is_null, agg_count_empty, agg_count_not_empty, ["COUNT_DISTINCT", agg_count_distinct], ["COUNT_DISTINCT_INCLUDE_NULL", agg_count_distinct_include_null]]
    arith_extensions = [is_nan, is_inf, is_finite, floating_point_div, mod_op, decimal_div, decimal_mod, ["ROW_MIN", Base_Generator.make_function "LEAST"], ["ROW_MAX", Base_Generator.make_function "GREATEST"]]
    bool = [bool_or]
    eq = lift_binary_op "==" make_equals
    compare = [eq]

    stddev_pop = ["STDDEV_POP", Base_Generator.make_function "stddev_pop"]
    stddev_samp = ["STDDEV_SAMP", Base_Generator.make_function "stddev_samp"]
    stats = [agg_median, agg_mode, agg_percentile, stddev_pop, stddev_samp]
    date_ops = [make_extract_as_int "year", make_extract_as_int "quarter", make_extract_as_int "month", make_extract_as_int "week", make_extract_as_int "day", make_extract_as_int "hour", make_extract_as_int "minute", make_extract_fractional_as_int "second", make_extract_fractional_as_int "millisecond" modulus=1000, make_extract_fractional_as_int "microsecond" modulus=1000, ["date_add", make_date_add], ["date_diff", make_date_diff], ["date_trunc_to_day", make_date_trunc_to_day]]
    special_overrides = [is_null]
    other = [["RUNTIME_ERROR", make_runtime_error_op]]
    my_mappings = text + counts + stats + first_last_aggregators + arith_extensions + bool + compare + date_ops + special_overrides + other
    Base_Generator.base_dialect_operations . extend_with my_mappings

## PRIVATE
is_null = Base_Generator.lift_unary_op "IS_NULL" arg->
    arg.paren ++ " IS NULL"

## PRIVATE
agg_count_is_null = Base_Generator.lift_unary_op "COUNT_IS_NULL" arg->
    SQL_Builder.code "SUM(CASE WHEN " ++ arg.paren ++ " IS NULL THEN 1 ELSE 0 END)"

## PRIVATE
agg_count_empty = Base_Generator.lift_unary_op "COUNT_EMPTY" arg->
    SQL_Builder.code "SUM(CASE WHEN (" ++ arg.paren ++ " IS NULL) OR (" ++ arg.paren ++ " = '') THEN 1 ELSE 0 END)"

## PRIVATE
agg_count_not_empty = Base_Generator.lift_unary_op "COUNT_NOT_EMPTY" arg->
    SQL_Builder.code "SUM(CASE WHEN (" ++ arg.paren ++ " IS NOT NULL) AND (" ++ arg.paren ++ " != '') THEN 1 ELSE 0 END)"


## PRIVATE
agg_median = Base_Generator.lift_unary_op "MEDIAN" arg->
    median = SQL_Builder.code "MEDIAN(" ++ arg ++ ")"
    has_nan = SQL_Builder.code "BOOLOR_AGG(" ++ arg ++ " = 'NaN'::Double)"
    SQL_Builder.code "CASE WHEN " ++ has_nan ++ " THEN 'NaN'::Double ELSE " ++ median ++ " END"

## PRIVATE
agg_mode = Base_Generator.lift_unary_op "MODE" arg->
    SQL_Builder.code "MODE(" ++ arg ++ ")"

## PRIVATE
agg_percentile = Base_Generator.lift_binary_op "PERCENTILE" p-> expr->
    percentile = SQL_Builder.code "percentile_cont(" ++ p ++ ") WITHIN GROUP (ORDER BY " ++ expr ++ ")"
    has_nan = SQL_Builder.code "BOOLOR_AGG(" ++ expr ++ " = 'NaN'::Double)"
    SQL_Builder.code "CASE WHEN " ++ has_nan ++ " THEN 'NaN' ELSE " ++ percentile ++ " END"

## PRIVATE
   These are written in a not most-efficient way, but a way that makes them
   compatible with other group-by aggregations out-of-the-box. In the future, we
   may want to consider some alternative solutions.
first_last_aggregators =
    first = make_first_aggregator reverse=False ignore_null=False
    first_not_null = make_first_aggregator reverse=False ignore_null=True
    last = make_first_aggregator reverse=True ignore_null=False
    last_not_null = make_first_aggregator reverse=True ignore_null=True
    [["FIRST", first], ["FIRST_NOT_NULL", first_not_null], ["LAST", last], ["LAST_NOT_NULL", last_not_null]]

## PRIVATE
make_equals a b =
    case a.build.prepare.second==[True] of
        True -> b.paren
        False -> case b.build.prepare.second==[True] of
            True -> a.paren
            False -> a.paren ++ " = " ++ b.paren

## PRIVATE
make_first_aggregator reverse ignore_null args =
    if args.length < 2 then Error.throw (Illegal_State.Error "Insufficient number of arguments for the operation.") else
        result_expr = args.first
        order_bys = args.drop 1

        method_name = if reverse then "LAST_VALUE" else "FIRST_VALUE"
        filter_clause = if ignore_null then ") IGNORE NULLS OVER" else ") OVER"
        order_clause = SQL_Builder.code " ORDER BY " ++ SQL_Builder.join "," order_bys
        SQL_Builder.code (method_name + "(") ++ result_expr ++ filter_clause ++ order_clause

## PRIVATE
agg_shortest = Base_Generator.lift_unary_op "SHORTEST" arg->
     SQL_Builder.code "FIRST_VALUE(" ++ arg ++ ") IGNORE NULLS OVER (ORDER BY LENGTH(" ++ arg ++ "))"

## PRIVATE
agg_longest = Base_Generator.lift_unary_op "LONGEST" arg->
     SQL_Builder.code "FIRST_VALUE(" ++ arg ++ ") IGNORE NULLS OVER (ORDER BY LENGTH(" ++ arg ++ ") DESC)"

## PRIVATE
concat_ops =
    make_raw_concat_expr expr separator =
        SQL_Builder.code "string_agg(" ++ expr ++ ", " ++ separator ++ ")"
    concat = Base_Generator.make_concat make_raw_concat_expr make_contains_expr
    [["CONCAT", concat (has_quote=False)], ["CONCAT_QUOTE_IF_NEEDED", concat (has_quote=True)]]

## PRIVATE
trim_ops =
    whitespace = "' ' || CHR(9) || CHR(10) || CHR(13)"
    make_fn fn_name = Base_Generator.lift_binary_op fn_name input-> chars-> case chars of
            Nothing -> SQL_Builder.code fn_name+"(" ++ input ++ ", " ++ whitespace ++ ")"
            _ ->
                case chars.is_constant of
                    True ->
                        const = chars.fragments.vec.first.object
                        if const.is_nothing || const.is_empty then SQL_Builder.code fn_name+"(" ++ input ++ ", " ++ whitespace ++ ")" else
                            SQL_Builder.code fn_name+"(" ++ input ++ ", " ++ chars ++ ")"
                    False ->
                        SQL_Builder.code "CASE WHEN " ++ chars ++ " IS NULL OR " ++ chars ++ " = '' THEN " ++ fn_name ++ "(" ++ input ++ ") ELSE " ++ fn_name ++ "(" ++ input ++ ", " ++ chars ++ ") END"
    [make_fn "TRIM", make_fn "LTRIM", make_fn "RTRIM"]

## PRIVATE
agg_count_distinct args = if args.is_empty then (Error.throw (Illegal_Argument.Error "COUNT_DISTINCT requires at least one argument.")) else
    case args.length == 1 of
        True ->
            ## A single null value will be skipped.
            SQL_Builder.code "COUNT(DISTINCT " ++ args.first ++ ")"
        False ->
            ## A tuple of nulls is not a null, so it will not be skipped - but
               we want to ignore all-null columns. So we manually filter them
               out.
            count = SQL_Builder.code "COUNT(DISTINCT (" ++ SQL_Builder.join ", " args ++ "))"
            are_nulls = args.map arg-> arg.paren ++ " IS NULL"
            all_nulls_filter = SQL_Builder.code " FILTER (WHERE NOT (" ++ SQL_Builder.join " AND " are_nulls ++ "))"
            (count ++ all_nulls_filter).paren

## PRIVATE
agg_count_distinct_include_null args = case args.length == 1 of
    True ->
        arg = args.first
        count = SQL_Builder.code "COUNT(DISTINCT " ++ arg ++ ")"
        all_nulls_case = SQL_Builder.code "CASE WHEN COUNT(CASE WHEN " ++ arg ++ "IS NULL THEN 1 END) > 0 THEN 1 ELSE 0 END"
        count ++ " + " ++ all_nulls_case
    False -> Error.throw (Illegal_Argument.Error "COUNT_DISTINCT supports only single arguments in SQLServer.")

## PRIVATE
starts_with = Base_Generator.lift_binary_sql_function "STARTS_WITH" "STARTSWITH"

## PRIVATE
ends_with = Base_Generator.lift_binary_sql_function "ENDS_WITH" "ENDSWITH"

## PRIVATE
contains = Base_Generator.lift_binary_sql_function "CONTAINS" "CONTAINS"

## PRIVATE
make_contains_expr expr substring = contains [expr, substring]

## PRIVATE
make_case_sensitive = Base_Generator.lift_unary_op "MAKE_CASE_SENSITIVE" arg->
    SQL_Builder.code "((" ++ arg ++ ') COLLATE "ucs_basic")'

## PRIVATE
left = Base_Generator.lift_binary_op "LEFT" str-> n->
    SQL_Builder.code "left(" ++ str ++ ", CAST(" ++ n ++ " AS INT))"

## PRIVATE
right = Base_Generator.lift_binary_op "RIGHT" str-> n->
    SQL_Builder.code "right(" ++ str ++ ", CAST(" ++ n ++ " AS INT))"

## PRIVATE
make_order_descriptor internal_column sort_direction text_ordering =
    nulls = Nothing
    case text_ordering of
        Nothing ->
            Order_Descriptor.Value (Internals_Access.column_expression internal_column) sort_direction nulls_order=nulls collation=Nothing
        _ ->
            ## In the future we can modify this error to suggest using a custom defined collation.
            if text_ordering.sort_digits_as_numbers then Error.throw (Unsupported_Database_Operation.Error "Natural ordering") else
                case text_ordering.case_sensitivity of
                    Case_Sensitivity.Default ->
                        Order_Descriptor.Value (Internals_Access.column_expression internal_column) sort_direction nulls_order=nulls collation=Nothing
                    Case_Sensitivity.Sensitive ->
                        Order_Descriptor.Value (Internals_Access.column_expression internal_column) sort_direction nulls_order=nulls collation="ucs_basic"
                    Case_Sensitivity.Insensitive locale -> case locale == Locale.default of
                        False ->
                            Error.throw (Unsupported_Database_Operation.Error "Case insensitive ordering with custom locale")
                        True ->
                            upper = SQL_Expression.Operation "UPPER" [Internals_Access.column_expression internal_column]
                            folded_expression = SQL_Expression.Operation "LOWER" [upper]
                            Order_Descriptor.Value folded_expression sort_direction nulls_order=nulls collation=Nothing

## PRIVATE
is_nan = Base_Generator.lift_unary_op "IS_NAN" arg->
    (arg ++ " in (double precision 'NaN')").paren

## PRIVATE
is_inf = Base_Generator.lift_unary_op "IS_INF" arg->
    (arg ++ " in (double precision 'Infinity', double precision '-Infinity')").paren

## PRIVATE
is_finite = Base_Generator.lift_unary_op "IS_FINITE" arg->
    (arg ++ " not in (double precision 'Infinity', double precision '-Infinity', double precision 'NaN')").paren

## PRIVATE
bool_or = Base_Generator.lift_unary_op "BOOL_OR" arg->
    SQL_Builder.code "bool_or(" ++ arg ++ ")"

## PRIVATE
floating_point_div = Base_Generator.lift_binary_op "/" x-> y->
    SQL_Builder.code "CAST(" ++ x ++ " AS double precision) / CAST(" ++ y ++ " AS double precision)"

## PRIVATE
mod_op = Base_Generator.lift_binary_op "MOD" x-> y->
    x ++ " - FLOOR(CAST(" ++ x ++ " AS double precision) / CAST(" ++ y ++ " AS double precision)) * " ++ y

## PRIVATE
decimal_div = Base_Generator.lift_binary_op "DECIMAL_DIV" x-> y->
    SQL_Builder.code "CAST(" ++ x ++ " AS decimal) / CAST(" ++ y ++ " AS decimal)"

## PRIVATE
decimal_mod = Base_Generator.lift_binary_op "DECIMAL_MOD" x-> y->
    x ++ " - FLOOR(CAST(" ++ x ++ " AS decimal) / CAST(" ++ y ++ " AS decimal)) * " ++ y

## PRIVATE
supported_replace_params : Hashset Replace_Params
supported_replace_params =
    e0 = [Replace_Params.Value Text Case_Sensitivity.Default False, Replace_Params.Value Text Case_Sensitivity.Default True, Replace_Params.Value Text Case_Sensitivity.Sensitive False]
    e1 = [Replace_Params.Value Text Case_Sensitivity.Sensitive True, Replace_Params.Value Text Case_Sensitivity.Insensitive False, Replace_Params.Value Text Case_Sensitivity.Insensitive True]
    e2 = [Replace_Params.Value Regex Case_Sensitivity.Default False, Replace_Params.Value Regex Case_Sensitivity.Default True, Replace_Params.Value Regex Case_Sensitivity.Sensitive False]
    e3 = [Replace_Params.Value Regex Case_Sensitivity.Sensitive True, Replace_Params.Value Regex Case_Sensitivity.Insensitive False, Replace_Params.Value Regex Case_Sensitivity.Insensitive True]
    e4 = [Replace_Params.Value DB_Column Case_Sensitivity.Default False, Replace_Params.Value DB_Column Case_Sensitivity.Sensitive False]
    Hashset.from_vector <| e0 + e1 + e2 + e3 + e4

## PRIVATE
replace : Vector SQL_Builder -> Any -> SQL_Builder
replace args metadata =
    input = args.at 0
    pattern = args.at 1
    replacement = args.at 2

    ## `raw_pattern` is a `Text1 or `Regex`; it's the same value as `input`, but not
       embedded in IR.
    raw_pattern = metadata.at 0
    replace_params = metadata.at 1

    expression = case replace_params.input_type of
        Text ->
            ## To use REGEXP_REPLACE on a non-regex, we have to escape it.
            escaped_pattern = SQL_Builder.interpolation (Regex.escape raw_pattern)
            case replace_params.only_first of
                False -> case replace_params.case_sensitivity of
                    Case_Sensitivity.Insensitive _ ->
                        SQL_Builder.code "REGEXP_REPLACE(" ++ input ++ ", " ++ escaped_pattern ++ ", " ++ replacement ++ ", 'ig')"
                    _ ->
                        SQL_Builder.code "REPLACE(" ++ input ++ ", " ++ pattern ++ ", " ++ replacement ++ ")"
                True -> case replace_params.case_sensitivity of
                    Case_Sensitivity.Insensitive _ ->
                        SQL_Builder.code "REGEXP_REPLACE(" ++ input ++ ", " ++ escaped_pattern ++ ", " ++ replacement ++ ", 'i')"
                    _ ->
                        SQL_Builder.code "REGEXP_REPLACE(" ++ input ++ ", " ++ escaped_pattern ++ ", " ++ replacement ++ ")"
        Regex ->
            pattern_string = SQL_Builder.interpolation raw_pattern.pattern_string
            case replace_params.only_first of
                False -> case replace_params.case_sensitivity of
                    Case_Sensitivity.Insensitive _ ->
                        SQL_Builder.code "REGEXP_REPLACE(" ++ input ++ ", " ++ pattern_string ++ ", " ++ replacement ++ ", 'ig')"
                    _ ->
                        SQL_Builder.code "REGEXP_REPLACE(" ++ input ++ ", " ++ pattern_string ++ ", " ++ replacement ++ ", 'g')"
                True -> case replace_params.case_sensitivity of
                    Case_Sensitivity.Insensitive _ ->
                        SQL_Builder.code "REGEXP_REPLACE(" ++ input ++ ", " ++ pattern_string ++ ", " ++ replacement ++ ", 'i')"
                    _ ->
                        SQL_Builder.code "REGEXP_REPLACE(" ++ input ++ ", " ++ pattern_string ++ ", " ++ replacement ++ ")"
        DB_Column ->
            case replace_params.only_first of
                False -> case replace_params.case_sensitivity of
                    Case_Sensitivity.Insensitive _ ->
                        Nothing
                    _ ->
                        SQL_Builder.code "REPLACE(" ++ input ++ ", " ++ pattern ++ ", " ++ replacement ++ ")"
                True -> Nothing
    expression.if_nothing (replace_params.throw_unsupported sqlserver_dialect_name)

## PRIVATE
make_extract_as_int enso_name sql_name=enso_name =
    Base_Generator.lift_unary_op enso_name arg->
        as_int32 <| SQL_Builder.code "EXTRACT(" ++ sql_name ++ " FROM " ++ arg ++ ")"

## PRIVATE
make_extract_fractional_as_int enso_name sql_name=enso_name modulus=Nothing =
    Base_Generator.lift_unary_op enso_name arg->
        result = as_int32 <| SQL_Builder.code "TRUNC(EXTRACT(" ++ sql_name ++ " FROM " ++ arg ++ "))"
        case modulus of
            Nothing -> result
            _ : Integer ->
                (result ++ (" % "+modulus.to_text)).paren

## PRIVATE
make_date_add arguments (metadata : Date_Period_Metadata) =
    if arguments.length != 2 then Error.throw (Illegal_State.Error "date_add expects exactly 2 sub expressions. This is a bug in Database library.") else
        expr = arguments.at 0
        amount = arguments.at 1
        interval_arg = case metadata.period of
            Date_Period.Year ->
                "years=>1"
            Date_Period.Quarter ->
                "months=>3"
            Date_Period.Month ->
                "months=>1"
            Date_Period.Week _ ->
                "weeks=>1"
            Date_Period.Day ->
                "days=>1"
            Time_Period.Hour ->
                "hours=>1"
            Time_Period.Minute ->
                "mins=>1"
            Time_Period.Second ->
                "secs=>1"
            Time_Period.Millisecond ->
                "secs=>0.001"
            Time_Period.Microsecond ->
                "secs=>0.000001"
        interval_expression = SQL_Builder.code "make_interval(" ++ interval_arg ++ ")"
        shifted = SQL_Builder.code "(" ++ expr ++ " + (" ++ amount ++ " * " ++ interval_expression ++ "))"
        case metadata.input_value_type of
            Value_Type.Date ->
                SQL_Builder.code "(" ++ shifted ++ "::date)"
            _ -> shifted

## PRIVATE
make_date_diff arguments (metadata : Date_Period_Metadata) =
    if arguments.length != 2 then Error.throw (Illegal_State.Error "date_diff expects exactly 2 sub expressions. This is a bug in Database library.") else
        start = arguments.at 0
        end = arguments.at 1

        truncate expr =
            SQL_Builder.code "TRUNC(" ++ expr ++ ")"

        # `age` computes a 'symbolic' difference expressed in years, months and days.
        extract_years =
            as_int32 <| SQL_Builder.code "EXTRACT(YEARS FROM age(" ++ end ++ ", " ++ start ++ "))"
        # To get total months, we need to sum up with whole years.
        extract_months =
            months = as_int32 <|
                SQL_Builder.code "EXTRACT(MONTHS FROM age(" ++ end ++ ", " ++ start ++ "))"
            SQL_Builder.code "(" ++ extract_years ++ " * 12 + " ++ months ++ ")"
        ## To get total days, we cannot use `age`, because we cannot convert an
           amount of months to days (month lengths vary). Instead we rely on `-`
           returning an interval based in 'raw' days.
        extract_days =
            as_int32 <| case metadata.input_value_type of
                ## For pure 'date' datatype, the difference is a simple integer
                   count of days.
                Value_Type.Date -> (end ++ " - " ++ start).paren
                # For others, it is an interval, so we need to extract.
                _ -> SQL_Builder.code "EXTRACT(DAYS FROM (" ++ end ++ " - " ++ start ++ "))"
        ## We round the amount of seconds towards zero, as we only count full
           elapsed seconds in the interval.
           Note that it is important the interval is computed using `-`. The
           symbolic `age` has no clear mapping to the count of days, skewing the
           result.
        extract_seconds =
            seconds_numeric = SQL_Builder.code "EXTRACT(EPOCH FROM (" ++ end ++ " - " ++ start ++ "))"
            as_int64 (truncate seconds_numeric)
        case metadata.period of
            Date_Period.Year    -> extract_years
            Date_Period.Month   -> extract_months
            Date_Period.Quarter -> (extract_months ++ " / 3").paren
            Date_Period.Week _  -> (extract_days ++ " / 7").paren
            Date_Period.Day     -> extract_days
            ## EXTRACT HOURS/MINUTES would yield only a date part, but we need
               the total which is easiest achieved by EPOCH
            Time_Period.Hour    -> (extract_seconds ++ " / 3600").paren
            Time_Period.Minute  -> (extract_seconds ++ " / 60").paren
            Time_Period.Second  -> extract_seconds
            ## The EPOCH gives back just the integer amount of seconds, without
               the fractional part. So we get the fractional part using
               MILLISECONDS - but that does not give the _total_ just the
               'seconds of minute' part, expressed in milliseconds. So we need
               to merge both - but then seconds of minute appear twice, so we %
               the milliseconds to get just the fractional part from it and sum
               both.
            Time_Period.Millisecond ->
                millis = truncate <|
                    SQL_Builder.code "EXTRACT(MILLISECONDS FROM (" ++ end ++ " - " ++ start ++ "))"
                as_int64 <|
                    ((extract_seconds ++ " * 1000").paren ++ " + " ++ (millis ++ " % 1000").paren).paren
            Time_Period.Microsecond ->
                micros = SQL_Builder.code "EXTRACT(MICROSECONDS FROM (" ++ end ++ " - " ++ start ++ "))"
                as_int64 <|
                    ((extract_seconds ++ " * 1000000").paren ++ " + " ++ (micros ++ " % 1000000").paren).paren

## PRIVATE
make_date_trunc_to_day arguments =
    if arguments.length != 1 then Error.throw (Illegal_State.Error "date_trunc_to_day expects exactly one sub expression. This is a bug in Database library.") else
        expr = arguments.at 0
        SQL_Builder.code "(DATE_TRUNC('day'," ++ expr ++ ") :: DATE)"

## PRIVATE
   Alters the expression casting the value to a 64-bit integer.
   TODO probably remove
as_int64 expr =
    SQL_Builder.code "(" ++ expr ++ "::int8)"

## PRIVATE
   Alters the expression casting the value to a 32-bit integer.
   TODO probably remove
as_int32 expr =
    SQL_Builder.code "(" ++ expr ++ "::int4)"

## PRIVATE
   The RUNTIME_ERROR operation should allow the query to compile fine and it
   will not prevent it from running if the branch including this operation is
   not taken. But if the branch is computed, it should ensure the query fails.

   This query never returns a value, so its type should be polymorphic. However,
   that is not possible - so currently it just 'pretends' that it would return a
   Boolean - because that is the type we expect in the use-case. This can be
   altered if needed.

   It takes a variable as the second argument. It can be any value that is not
   statically known - this ensure that the optimizer will not be able to
   pre-compute the expression too early (which could make the query fail
   spuriously). See `make_invariant_check` in `Lookup_Query_Helper` for an
   example.
make_runtime_error_op arguments =
    if arguments.length != 2 then
        Panic.throw (Illegal_Argument.Error "RUNTIME_ERROR takes exactly 2 arguments (error message and a variable to ensure deferred execution).")
    error_message = arguments.at 0
    variable_to_defer = arguments.at 1

    SQL_Builder.code "CAST('[ENSO INVARIANT VIOLATED: '||" ++ error_message ++ "||'] '||COALESCE(" ++ variable_to_defer ++ "::TEXT,'NULL') AS BOOLEAN)"

## PRIVATE
make_distinct_extension expressions =
    run_generator sql_expressions =
        SQL_Builder.code "DISTINCT ON (" ++ (SQL_Builder.join ", " sql_expressions) ++ ") "
    Context_Extension.Value position=120 expressions=expressions run_generator=run_generator

## PRIVATE
sqlserver_dialect_name = "SQL Server"
