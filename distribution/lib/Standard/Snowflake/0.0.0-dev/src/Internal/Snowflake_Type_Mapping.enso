private

from Standard.Base import all
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

import Standard.Table.Data.Type.Value_Type.Bits
import Standard.Table.Data.Type.Value_Type.Value_Type
import Standard.Table.Internal.Java_Exports
from Standard.Table.Errors import Inexact_Type_Coercion

import Standard.Database.Internal.Column_Fetcher as Column_Fetcher_Module
import Standard.Database.Internal.Column_Fetcher.Column_Fetcher
import Standard.Database.Internal.IR.SQL_Expression.SQL_Expression
import Standard.Database.Internal.SQL_Type_Mapping
import Standard.Database.Internal.SQL_Type_Reference.SQL_Type_Reference
import Standard.Database.SQL_Type.SQL_Type
from Standard.Database.Errors import Unsupported_Database_Operation

polyglot java import java.sql.Types

## PRIVATE
type Snowflake_Type_Mapping
    ## PRIVATE
    value_type_to_sql : Value_Type -> Problem_Behavior -> SQL_Type
    value_type_to_sql value_type on_problems =
        result = case value_type of
            Value_Type.Boolean -> SQL_Type.Value Types.BOOLEAN "boolean"
            # All integer types in Snowflake become NUMERIC(38,0).
            Value_Type.Byte -> SQL_Type.Value Types.BIGINT "bigint"
            Value_Type.Integer _ -> SQL_Type.Value Types.BIGINT "bigint"
            # All float types in Snowflake become double
            Value_Type.Float _ -> SQL_Type.Value Types.DOUBLE "float8"
            Value_Type.Decimal precision scale -> case precision of
                # If precision is not set, scale is also lost because SQL is unable to express a scale without a precision.
                Nothing -> SQL_Type.Value Types.DECIMAL "decimal" Nothing Nothing
                # Scale can be set or not, if precision is given, so no check needed.
                _       -> SQL_Type.Value Types.DECIMAL "decimal" precision scale
            Value_Type.Char size _ ->
                # Snowflake does not support fixed length strings, so we use VARCHAR.
                is_unbounded = size.is_nothing || (size >= max_length)
                case is_unbounded of
                    True  -> SQL_Type.Value Types.VARCHAR "varchar"
                    False -> SQL_Type.Value Types.VARCHAR "varchar" size
            Value_Type.Time -> SQL_Type.Value Types.TIME "time"
            Value_Type.Date -> SQL_Type.Value Types.DATE "date"
            Value_Type.Date_Time with_timezone ->
                type_name = if with_timezone then "timestamp_tz" else "timestamp_ntz"
                SQL_Type.Value Types.TIMESTAMP type_name
            Value_Type.Binary size _ ->
                ## Snowflake does not support fixed length binary types, so we use BINARY.
                is_unbounded = size.is_nothing || (size >= max_length)
                case is_unbounded of
                    True  -> SQL_Type.Value Types.BINARY "binary"
                    False -> SQL_Type.Value Types.BINARY "binary" size
            Value_Type.Mixed -> Error.throw (Unsupported_Database_Operation.Error "Snowflake tables do not support Mixed types.")
            Value_Type.Unsupported_Data_Type type_name underlying_type ->
                underlying_type.if_nothing <| Error.throw <| Illegal_Argument.Error <|
                    "An unsupported SQL type ["+type_name.to_text+"] cannot be converted into an SQL type because it did not contain the SQL metadata needed to reconstruct it."

        approximated_value_type = Snowflake_Type_Mapping.sql_type_to_value_type result
        problems = if approximated_value_type == value_type then [] else [Inexact_Type_Coercion.Warning value_type approximated_value_type]
        on_problems.attach_problems_before problems result

    ## PRIVATE
    sql_type_to_value_type : SQL_Type -> Value_Type
    sql_type_to_value_type sql_type =
        simple_type = simple_types_map.get sql_type.typeid Nothing
        simple_type.if_nothing <|
            ## If we didn't match any of the types from the simple mapping, we
               continue with the more complex mappings that take stuff like
               precision into account.
            case complex_types_map.get sql_type.typeid Nothing of
                Nothing -> on_unknown_type sql_type
                builder -> builder sql_type

    ## PRIVATE
    sql_type_to_text : SQL_Type -> Text
    sql_type_to_text sql_type =
        variable_length_types = [Types.VARCHAR, Types.BINARY]
        ## If the type is variable length and the maximum is provided, we treat
           it as unbounded, otherwise too big max length may be not accepted by
           Snowflake.
        skip_precision = (variable_length_types.contains sql_type.typeid) && (sql_type.precision == max_length)
        case skip_precision of
            True -> sql_type.name
            False -> SQL_Type_Mapping.default_sql_type_to_text sql_type

    ## PRIVATE
       The Snowflake_Type_Mapping always relies on the return type determined by
       the database backend.
    infer_return_type : (SQL_Expression -> SQL_Type_Reference) -> Text -> Vector -> SQL_Expression -> SQL_Type_Reference
    infer_return_type infer_from_database_callback op_name arguments expression =
        _ = [op_name, arguments]
        infer_from_database_callback expression

    ## PRIVATE
       We want to respect any overriding references, but references that rely on
       computing the type by the database are resolved to Nothing to just rely
       on the `ResultSet` metadata and decrease overhead.
    prepare_type_overrides : Nothing | Vector SQL_Type_Reference -> Nothing | Vector (Nothing | SQL_Type)
    prepare_type_overrides column_type_suggestions = case column_type_suggestions of
        Nothing -> Nothing
        _ : Vector -> column_type_suggestions.map .to_type_override

    ## PRIVATE
       Creates a `Column_Fetcher` used to fetch data from a result set and build
       an in-memory column from it, based on the given column type.
    make_column_fetcher : SQL_Type -> Column_Fetcher
    make_column_fetcher self sql_type =
        value_type = self.sql_type_to_value_type sql_type
        case value_type of
            Value_Type.Time -> time_fetcher
            Value_Type.Date_Time _ -> date_time_fetcher
            _ -> Column_Fetcher_Module.default_fetcher_for_value_type value_type

## PRIVATE
simple_types_map = Map.from_vector <|
    ints = [[Types.TINYINT, Value_Type.Byte], [Types.SMALLINT, Value_Type.Integer Bits.Bits_16], [Types.BIGINT, Value_Type.Integer Bits.Bits_64], [Types.INTEGER, Value_Type.Integer Bits.Bits_32]]
    floats = [[Types.DOUBLE, Value_Type.Float Bits.Bits_64], [Types.REAL, Value_Type.Float Bits.Bits_32]]
    other = [[Types.DATE, Value_Type.Date], [Types.TIME, Value_Type.Time], [Types.BOOLEAN, Value_Type.Boolean]]
    ints + floats + other

## PRIVATE
complex_types_map = Map.from_vector <|
    make_decimal sql_type =
        Value_Type.Decimal sql_type.precision sql_type.scale
    make_varchar sql_type =
        effective_size = if sql_type.precision==max_length || (sql_type.precision==9 && sql_type.scale==9) then Nothing else sql_type.precision
        Value_Type.Char size=effective_size variable_length=True
    make_char sql_type =
        Value_Type.Char size=sql_type.precision variable_length=False
    make_binary variable sql_type =
        Value_Type.Binary size=sql_type.precision variable_length=variable
    handle_bit sql_type =
        if sql_type.name == "BOOLEAN" then Value_Type.Boolean else
            # We currently do not support bit types.
            on_unknown_type sql_type
    handle_timestamp sql_type = case sql_type.name of
        "TIMESTAMPTZ" -> Value_Type.Date_Time with_timezone=True
        "TIMESTAMP_TZ" -> Value_Type.Date_Time with_timezone=True
        "TIMESTAMPLTZ" -> Value_Type.Date_Time with_timezone=False
        "TIMESTAMP_LTZ" -> Value_Type.Date_Time with_timezone=False
        "TIMESTAMPNTZ"   -> Value_Type.Date_Time with_timezone=False
        "TIMESTAMP_NTZ"   -> Value_Type.Date_Time with_timezone=False
        _             -> on_unknown_type sql_type

    numerics = [[Types.DECIMAL, make_decimal], [Types.NUMERIC, make_decimal]]
    strings = [[Types.VARCHAR, make_varchar], [Types.CHAR, make_char], [Types.CLOB, make_varchar]]
    binaries = [[Types.BINARY, make_binary True], [Types.BIT, handle_bit]]
    others = [[Types.TIMESTAMP, handle_timestamp]]
    numerics + strings + binaries + others

## PRIVATE
on_unknown_type sql_type =
    Value_Type.Unsupported_Data_Type sql_type.name sql_type

## PRIVATE
   This is the maximum size that JDBC driver reports for 'unbounded' types in
   Snowflake.
max_length = 16777216

## PRIVATE
time_fetcher =
    fetch_value rs i =
        ## Read the time as a string to get the nanosecond precision.
        sf_string = rs.getString i
        if sf_string == Nothing then Nothing else Time_Of_Day.parse sf_string
    make_builder initial_size _ =
        java_builder = Java_Exports.make_time_of_day_builder initial_size
        Column_Fetcher_Module.make_builder_from_java_object_builder java_builder
    Column_Fetcher.Value fetch_value make_builder

## PRIVATE
date_time_fetcher =
    fetch_value rs i =
        ## Read the time as a string to get the nanosecond precision.
        sf_string = rs.getString i
        if sf_string == Nothing then Nothing else Date_Time.parse sf_string
    make_builder initial_size _ =
        java_builder = Java_Exports.make_date_time_builder initial_size
        Column_Fetcher_Module.make_builder_from_java_object_builder java_builder
    Column_Fetcher.Value fetch_value make_builder
