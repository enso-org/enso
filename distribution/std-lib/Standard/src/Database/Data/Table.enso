from Standard.Base import all

import Standard.Database.Data.Internal.Helpers
import Standard.Database.Data.Internal.IR
import Standard.Database.Data.Sql
import Standard.Table.Data.Column as Materialized_Column
import Standard.Table.Data.Table as Materialized_Table
import Standard.Table.Internal.Java_Exports

from Standard.Database.Data.Column as Column_Module import all
from Standard.Database.Data.Internal.IR import Internal_Column
from Standard.Table.Data.Order_Rule as Order_Rule_Module import Order_Rule
from Standard.Table.Data.Table import No_Such_Column_Error

polyglot java import java.sql.JDBCType

## Represents a column-oriented table data structure backed by a database.
type Table
    ## PRIVATE

       Represents a column-oriented table data structure backed by a database.
       # type Table (name : Text) (connection : Connection)
       #            (internal_columns : Vector Internal_Column)
       #            (context : IR.Context)
    type Table name connection internal_columns context

    ## UNSTABLE

       Returns a text containing an ASCII-art table displaying this data.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
         - format_terminal: whether ANSI-terminal formatting should be used
    display : Integer -> Boolean -> Text
    display show_rows=10 format_terminal=False =
        df = this.reset_index.to_dataframe max_rows=show_rows
        indices_count = this.context.meta_index.length
        all_rows_count = this.row_count
        here.display_dataframe df indices_count all_rows_count format_terminal

    ## UNSTABLE

       Prints an ASCII-art table with this data to the standard output.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
    print show_rows=10 =
        IO.println (this.display show_rows format_terminal=True)
        IO.println ''

    ## UNSTABLE

       Converts this table to a JSON structure.
    to_json : Json
    to_json = case this.internal_columns.is_empty of
        True ->
            Json.from_pairs [["query", Nothing], ["message", "The table has no columns so a query cannot be generated."]]
        False -> this.to_sql.to_json

    ## UNSTABLE

       Returns the column with the given name.
    at : Text -> Column ! UnknownColumnError
    at name =
        internal = this.internal_columns.find (p -> p.name == name)
        this.make_column internal . map_error (_ -> No_Such_Column_Error name)

    ## PRIVATE
       Resolves the column name to a column within this table. If instead of a
       name, a column is provided, it is returned as-is as long as it comes from
       the same context.
    resolve : Text | Column -> Column
    resolve column = case column of
        Text -> Panic.rethrow (this.at column)
        _ ->
            if Helpers.check_integrity this column then column else
                Panic.throw (Integrity_Error "Column "+column.name)

    ## UNSTABLE

       Selects only the rows of this table that correspond to `True` values in
       `filter`.
       This is useful for filtering the rows by given predicate.
       > Example
         Select only the rows of `my_table` where the `"Status"` column has the
         value `"Valid"`
             my_table.where (my_table.at "Status" == "Valid")
    where : Column -> Table
    where filter =
        case Helpers.check_integrity this filter of
            False ->
                Error.throw (Integrity_Error "Column "+filter.name)
            True ->
                new_filters = this.context.where_filters + [filter.expression]
                new_ctx = this.context.set_where_filters new_filters
                this.updated_context new_ctx

    ## UNSTABLE

       Returns a new Table that will include at most `max_rows` rows from the
       original Table.

       Since this Table is backed by an SQL database, the Table returned by the
       `limit` method is deterministic only if the Table has been ordered (using
       the `sort` method).

       Otherwise, no order is imposed, so the returned Table will include at most
       `max_rows` rows, but there are no guarantees on which rows will be
       selected. Moreover, even if the underlying table in the database did not
       change, different sets of rows may be returned each time the returned
       Table is materialized.

       The limit is applied at the very end, so the new Table behaves exactly as
       the old one, just limitting its results when being materialized.
       Specifically, applying further filters will still apply to the whole
       result set and the limit will be taken after applying these filters.

       > For example:
         In the call below, assuming that the table of `t1` contains rows for
         numbers 1, 2, ..., 10, will return rows starting from 6 and not an empty
         result as one could expect if the limit was applied before the filters.
             t1 = table.sort by='A' . limit 5
             t2 = t1.where (t1.at 'A' > 5)
             t2.to_dataframe
    limit : Integer -> Table
    limit max_rows =
        new_ctx = this.context.set_limit max_rows
        this.updated_context new_ctx

    ## UNSTABLE

       Sets the column value at the given name. If a column with the given name
       already exists, it will be replaced. Otherwise a new column is added.
    set : Text -> Column -> Table
    set name column = case Helpers.ensure_name_is_sane name of
        True ->
            is_used_in_index = this.context.meta_index.exists i-> i.name == name
            case is_used_in_index of
                True -> Error.throw <| Illegal_State_Error "Cannot override column "+name+", because it is used as an index. Remove the index or use a different name."
                False ->
                    new_col = Internal_Column name column.sql_type column.expression
                    replace = this.internal_columns.exists (c -> c.name == name)
                    case replace of
                        True ->
                            new_cols = this.internal_columns.map (c -> if c.name == name then new_col else c)
                            this.updated_columns new_cols
                        False ->
                            this.updated_columns (this.internal_columns + [new_col])

    ## UNSTABLE

       Returns the vector of columns contained in this table.
    columns : Vector Column
    columns = this.internal_columns . map this.make_column

    ## UNSTABLE

       Sets the index of this table, using the column with the provided name.
    set_index : Text | Column | Vector (Text | Column) -> Table
    set_index index = Panic.recover <|
        new_index = (Helpers.unify_vector_singleton index).map (this.resolve >> .as_internal)
        new_ctx = this.context.set_index new_index
        new_cols = this.internal_columns.filter col->
            turned_into_index = new_index.exists i-> i.name == col.name
            turned_into_index.not
        this.updated_context new_ctx . updated_columns new_cols

    ## Returns the index (or indexes) of this table, as a column (indexed by itself).
       Returns `Nothing` if there is no index set.
    index : Column | Vector Column | Nothing
    index =
        ixes = this.context.meta_index.map this.make_column
        len = this.context.meta_index.length
        if len == 0 then Nothing else
            if len == 1 then ixes.at 0 else ixes

    ## UNSTABLE

       Sorts the table according to the specified rules.

       Arguments:
         - by: specifies the columns used for reordering the table. This
           argument may be one of:
             - a text: the text is treated as a column name.
             - a column: any column, which is an expression computed from this
               table.
             - an order rule: specifies both the sorting column and additional
               settings, that will take precedence over the global parameters of
               this sort operation. The `column` field of the rule may be a text
               or a column, with the semantics described above.
             - a vector of any of the above: this will result in a hierarchical
               sorting, such that the first rule is applied first, the second is
               used for breaking ties, etc.
         - order: specifies the default sort order for this operation. All the
           rules specified in the `by` argument will default to this setting,
           unless specified in the rule.
         - missing_last: specifies the default placement of missing values when
           compared to non-missing ones. This setting may be overriden by the
           particular rules of the `by` argument.  Note thet this argument is
           independent from `order`, i.e. missing values will always be sorted
           according to this rule, ignoring the ascending / descending setting.

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`
             table.sort by='Quantity'

       > Example
         Sorting `table` in descending order by the value in column `'Quantity'`,
         placing missing values at the top of the table.
             table.sort by='Quantity' order=Sort_Order.Descending missing_last=False

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` for breaking ties.
             table.sort by=['Quantity', 'Rating']

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` in descending order for breaking
         ties.
             table.sort by=['Quantity', Order_Rule 'Rating' (order=Sort_Order.Descending)]

       > Example
         Sorting `table` in ascending order by the value in an externally
         computed column, using the value in column `'Rating'` for breaking
         ties.
             quality_ratio = table.at 'Rating' / table.at 'Price'
             table.sort by=[quality_ratio, 'Rating']
    sort : Text | Column | Order_Rule | Vector.Vector (Text | Column | Order_Rule) -> Sort_Order -> Boolean -> Table
    sort by order=Sort_Order.Ascending missing_last=True = Panic.recover <|
        order_to_ir = case _ of
            Sort_Order.Ascending -> IR.Ascending
            Sort_Order.Descending -> IR.Descending
        missing_to_ir last = case last of
            True -> IR.Nulls_Last
            False -> IR.Nulls_First
        wrap_elem elem =
            [this.resolve elem . expression, order_to_ir order, missing_to_ir missing_last]
        to_ir elem = case elem of
            Text -> wrap_elem elem
            Column _ _ _ _ _ -> wrap_elem elem
            Order_Rule elem Nothing my_order my_nulls ->
                chosen_order = if my_order.is_nothing then order else my_order
                chosen_nulls = if my_nulls.is_nothing then missing_last else my_nulls
                [this.resolve elem . expression, order_to_ir chosen_order, missing_to_ir chosen_nulls]
            Order_Rule _ _ _ _ ->
                Error.throw <| Illegal_State_Error "Custom comparators are not supported in Database"
        elems = Helpers.unify_vector_singleton by . map to_ir
        new_ctx = this.context.set_orders elems
        this.updated_context new_ctx

    ## UNSTABLE

       Selects a subset of columns from this table by name.
    select : Vector Text -> Table
    select columns =
        find_col = (name -> this.internal_columns.find (p -> p.name == name))
        selected_cols = columns.map (find_col >> .catch) . filter (c -> c.is_nothing.not)
        this.updated_columns selected_cols

    ## UNSTABLE

       Efficiently joins two tables based on either the index or a key column.

       The resulting table contains rows of `this` extended with rows of
       `other` with matching indexes. If the index in `other` is not unique,
       the corresponding rows of `this` will be duplicated in the result.

       Arguments:
         - other: the table being the right operand of this join operation.
         - on: the column(s) or expression(s) of `this` that should be used as
           the join key. If this argument is not provided, the index of `this`
           will be used.
         - drop_unmatched: whether the rows of `this` without corresponding
                           matches in `other` should be dropped from the result.
         - left_suffix: a suffix that should be added to the columns of `this`
                        when there's a name conflict with a column of `other`.
         - right_suffix: a suffix that should be added to the columns of `other`
                         when there's a name conflict with a column of `this`.
    join : Table -> Nothing | Text | Column | Vector (Text | Column) -> Boolean -> Text -> Text -> Table
    join other on=Nothing drop_unmatched=False left_suffix='_left' right_suffix='_right' = Panic.recover <|
        Panic.rethrow (Helpers.ensure_name_is_sane left_suffix && Helpers.ensure_name_is_sane right_suffix)
        if left_suffix == right_suffix then
            Panic.throw <| Illegal_State_Error "left_suffix must be different from right_suffix"
        kind = if drop_unmatched then IR.Join_Inner else IR.Join_Left
        my_index : Vector Internal_Column
        my_index = case on of
            Nothing -> this.context.meta_index
            _ ->
                (Helpers.unify_vector_singleton on).map (this.resolve >> .as_internal)
        other_index = other.context.meta_index
        case my_index.length == other_index.length of
            False -> Panic.throw <| Illegal_State_Error "Cannot join with multi-indexes of different lengths."
            True ->
                # TODO [RW] we may be able to avoid creating subqueries if there are no groups, orders or wheres,
                # so it may be worth optimizing that here (#1515)
                new_table_name = this.name + "_" + other.name
                aliases = case this.name == other.name of
                    True -> [this.name+left_suffix, other.name+right_suffix]
                    False -> [this.name, other.name]
                left_alias = aliases.first
                right_alias = aliases.second

                left_subquery_cols = this.internal_columns_with_index.map c-> [c.name, c.expression]
                right_subquery_cols = other.internal_columns_with_index.map c-> [c.name, c.expression]
                left_query = IR.Sub_Query left_subquery_cols this.context left_alias
                right_query = IR.Sub_Query right_subquery_cols other.context right_alias

                left_renamed_index = my_index.map <|
                    IR.lift_expression_map (IR.substitute_origin this.name left_alias)
                right_renamed_index = other_index.map <|
                    IR.lift_expression_map (IR.substitute_origin other.name right_alias)
                on_exprs = left_renamed_index.zip right_renamed_index l-> r->
                    IR.Operation "=" [l.expression, r.expression]

                new_index = left_renamed_index
                new_from = IR.Join kind left_query right_query on_exprs
                new_limit = Nothing
                new_ctx = IR.Context new_from [] [] [] new_index new_limit

                new_names = here.combine_names (this.internal_columns.map .name) (other.internal_columns.map .name) left_suffix right_suffix
                left_names = new_names.first
                right_names = new_names.second

                new_left_columns = this.internal_columns.zip left_names p-> new_name->
                    Internal_Column new_name p.sql_type (IR.Column left_alias p.name)
                new_right_columns = other.internal_columns.zip right_names p-> new_name->
                    Internal_Column new_name p.sql_type (IR.Column right_alias p.name)

                new_columns = new_left_columns + new_right_columns

                Table new_table_name this.connection new_columns new_ctx

    ## UNSTABLE

       Returns an aggregate table resulting from grouping the elements by the
       value of the specified column.

       If the `by` argument is not set, the index is used for grouping instead.
    group : Vector Text | Text | Nothing -> Aggregate_Table
    group by=Nothing = Panic.recover <|
        cols = case by of
            Nothing ->
                if this.context.meta_index.is_empty then Panic.throw <| Illegal_State_Error "Trying to group by an empty index." else
                    this.context.meta_index
            _ ->

                Helpers.unify_vector_singleton by . map (this.resolve >> .as_internal)
        exprs = cols.map .expression
        new_ctx = this.context.set_groups exprs . set_index cols
        Aggregate_Table this.name this.connection this.internal_columns new_ctx

    ## UNSTABLE

       Returns a new Table without rows that contained missing values in any of
       the columns.
    drop_missing_rows : Table
    drop_missing_rows =
        filters = this.columns.map (c -> c.is_missing.not.expression)
        new_ctx = this.context.set_where_filters (this.context.where_filters + filters)
        this.updated_context new_ctx

    ## Returns a new Table without columns that contained any missing values.

       This operation needs to actually materialize the underlying query in
       order to know which columns to drop.
    drop_missing_columns : Table
    drop_missing_columns =
        rows_expr = IR.Operation "COUNT_ROWS" []
        all_rows_column_name = "row_count"
        make_count_expr expr = IR.Operation "COUNT" [expr]
        cols = this.internal_columns.map (c -> [c.name, make_count_expr c.expression])
        query = IR.Select [[all_rows_column_name, rows_expr]]+cols this.context
        sql = this.connection.dialect.generate_sql query
        table = this.connection.execute_query sql
        all_rows = table.at all_rows_column_name . at 0
        kept_columns = this.internal_columns . filter c->
            all_rows == table.at c.name . at 0
        this.updated_columns kept_columns

    ## Returns the amount of rows in this table.
    row_count : Integer
    row_count =
        expr = IR.Operation "COUNT_ROWS" []
        column_name = "row_count"
        query = IR.Select [[column_name, expr]] this.context
        sql = this.connection.dialect.generate_sql query
        table = this.connection.execute_query sql
        table.at column_name . at 0

    ## UNSTABLE

       Returns a materialized dataframe containing rows of this table.

       Arguments:
       - max_rows: specifies a maximum amount of rows to fetch; if not set, all
         available rows are fetched.
    to_dataframe : (Integer | Nothing) -> Materialized_Table.Table
    to_dataframe max_rows=Nothing =
        case this.context.meta_index.length > 1 of
            True -> Error.throw <| Illegal_State_Error "Multi-indexes are not implemented in the dataframes, if you want to materialize such a Table, remove the index first using `set_index`."
            False ->
                preprocessed = this.reset_index.limit max_rows
                case preprocessed.internal_columns.is_empty of
                    True ->
                        internal_table = Java_Exports.make_table_without_columns this.row_count
                        Materialized_Table.Table internal_table
                    False ->
                        sql = preprocessed.to_sql
                        expected_types = preprocessed.internal_columns.map .sql_type
                        table = this.connection.execute_query sql expected_types
                        case this.context.meta_index.length == 1 of
                            False -> table
                            True ->
                                ix_col_name = table.columns.first.name
                                table.set_index ix_col_name

    ## PRIVATE

       Brings the index back as columns.
    reset_index : Table
    reset_index =
        new_cols = this.internal_columns_with_index
        new_ctx = this.context.set_index []
        this.updated_context new_ctx . updated_columns new_cols

    ## UNSTABLE

       Returns an SQL statement that will be used for materializing this table.
    to_sql : Sql.Statement
    to_sql =
        cols = this.internal_columns.map (c -> [c.name, c.expression])
        case cols.is_empty of
            True -> Error.throw <| Illegal_State_Error "Cannot generate SQL for a table with no columns."
            False ->
                query = IR.Select cols this.context
                this.connection.dialect.generate_sql query

    ## Returns a Table describing this table's contents.

       The table lists all columns, counts of non-null items and storage types
       of each column.
    info : Table
    info =
        cols = this.internal_columns
        count_columns = cols.map c-> IR.Internal_Column c.name Sql.Sql_Type.integer (IR.Operation "COUNT" [c.expression])
        count_table = this.updated_columns count_columns . to_dataframe
        counts = count_table.columns.map c-> c.at 0
        column_type_as_text col =
            id = col.sql_type.typeid
            JDBCType.valueOf id . getName
        types = cols.map column_type_as_text
        Materialized_Table.new [["Column", cols.map .name], ["Items Count", counts], ["SQL Type", types]] . set_index "Column"

    ## PRIVATE

       Helper to create columns from internal columns.
    make_column : Internal_Column -> Column
    make_column internal =
        Column internal.name this.connection internal.sql_type internal.expression this.context

    ## PRIVATE

       Returns a copy of this table with updated internal columns.
    updated_columns columns = Table this.name this.connection columns this.context

    ## PRIVATE

       Returns a copy of this table with updated context.
    updated_context ctx = Table this.name this.connection this.internal_columns ctx

    ## PRIVATE

       Returns a vector that contains first the internal representations of all
       indices and then all columns.
    internal_columns_with_index : Vector Internal_Column
    internal_columns_with_index =
        this.context.meta_index + this.internal_columns

    ## PRIVATE

       Inserts a new row to the table. It actually modifies the underlying table
       in the database.

       It can only be called on the Table if no operations modifying it have
       been performed like modifying, removing or adding columns, filtering,
       grouping etc.
    insert : Vector Any -> Nothing
    insert values =
        table_name = case this.context.from_spec of
            IR.From_Table name _ -> name
            _ -> Error.throw <| Illegal_State_Error "Inserting can only be performed on tables as returned by `access_table`, any further processing is not allowed."
        # TODO [RW] before removing the PRIVATE tag, add a check that no bad stuff was done to the table as described above
        pairs = this.internal_columns.zip values col-> value->
            [col.name, IR.Constant col.sql_type value]
        query = this.connection.dialect.generate_sql <| IR.Insert table_name pairs
        affected_rows = this.connection.execute_update query
        case affected_rows == 1 of
            False -> Error.throw <| Illegal_State_Error "The update unexpectedly affected "+affected_rows.to_text+" rows."
            True -> Nothing


## Represents a table with grouped rows.
type Aggregate_Table

    ## UNSTABLE

       Represents a table with grouped rows.
       # type Aggregate_Table (name : Text) (connection : Connection)
       #                      (internal_columns : Vector [Text, IR.Expression])
       #                      (context : IR.Context)
    type Aggregate_Table name connection internal_columns context

    ## UNSTABLE

       Returns a vector of aggregate columns in this table.
    columns : Vector.Vector
    columns = this.internal_columns . map this.make_column

    ## UNSTABLE

       Returns a column containing the number of elements in each group.
    count : Column
    count =
        expr = IR.Operation "COUNT_ROWS" []
        Column "count" this.connection Sql.Sql_Type.integer expr this.context

    ## UNSTABLE

       Returns an aggregate column with the given name, contained in this table.
    at : Text -> Column ! No_Such_Column_Error
    at name =
        internal = this.internal_columns.find (p -> p.name == name)
        this.make_column internal . map_error (_ -> No_Such_Column_Error name)

    ## PRIVATE

       Helper to create aggregate columns from internal columns.
       # make_column : Internal_Column -> Aggregate_Column
    make_column internal =
        Aggregate_Column internal.name this.connection internal.sql_type internal.expression this.context

type Integrity_Error
    ## UNSTABLE

       Signalizes that an operation tried using objects coming from different
       contexts.

       To use columns from different tables, you must first join them.
    type Integrity_Error object_description

    # Return a readable description of this error.
    to_text : Text
    to_text = this.object_description + " comes from a different context."

## PRIVATE

   Creates a Table out of a connection, name and list of column names.
   # make_table : Connection -> Text -> Vector [Text, Sql.Sql_Type] -> Table
make_table connection table_name columns =
    ctx = IR.make_ctx_from table_name
    cols = columns.map (p -> Internal_Column p.first p.second (IR.Column table_name p.first))
    Table table_name connection cols ctx

## PRIVATE

   Renders an ASCII-art representation for a Table from a dataframe that
   contains a fragment of the underlying data and count of all rows.

   Arguments:
   - df: the materialized dataframe that contains the data to be displayed, it
     should have no indices set.
   - indices_count: indicates how many columns from the materialized dataframe
     should be treated as indices in the display (index columns will be bold if
     `format_terminal` is enabled).
   - all_rows_count: the count of all rows in the underlying Table; if
     `all_rows_count` is bigger than the amount of rows of `df`, an additional
     line will be included that will say how many hidden rows there are.
   - format_term: a boolean flag, specifying whether to use ANSI escape codes
     for rich formatting in the terminal.
display_dataframe : Materialized_Table.Table -> Integer -> Integer -> Boolean -> Text
display_dataframe df indices_count all_rows_count format_terminal =
    cols = Vector.Vector df.java_table.getColumns
    col_names = cols.map .getName
    col_vals = cols.map .getStorage
    display_rows = df.row_count
    rows = Vector.new display_rows row_num->
        col_vals.map col->
            if col.isNa row_num then "Nothing" else Materialized_Column.get_item_string col row_num
    table = Materialized_Table.print_table col_names rows indices_count format_terminal
    if display_rows == all_rows_count then table else
        missing_rows_count = all_rows_count - display_rows
        missing = '\n\u2026 and ' + missing_rows_count.to_text + ' hidden rows.'
        table + missing

## PRIVATE

   Creates a list of non-colliding names by merging the two lists and
   appending suffixes if necessary.

   If even after appending the suffixes it is impossible to have unique names,
   it throws a panic. It returns two vectors, one for each input. It assumes
   that the names within each argument itself are unique.
combine_names left_names right_names left_suffix right_suffix =
    make_count_map names =
        map = names.fold Map.empty acc-> name->
            count = acc.get_or_else name 0 + 1
            acc.insert name count
        name-> map.get_or_else name 0
    original_names_count = make_count_map left_names+right_names
    add_suffix_if_necessary suffix name = case original_names_count name > 1 of
        True -> [name, name+suffix]
        False -> [name, name]
    left_pairs = left_names.map <| add_suffix_if_necessary left_suffix
    right_pairs = right_names.map <| add_suffix_if_necessary right_suffix

    new_names_count = make_count_map (left_pairs+right_pairs . map .second)
    catch_ambiguity pairs = pairs.each pair->
        original_name = pair.first
        new_name = pair.second
        case new_name!=original_name && (new_names_count new_name > 1) of
            True ->
                Panic.throw <| Illegal_State_Error "Duplicate column "+original_name+" was about to be renamed to "+new_name+" to disambiguate column names, but a column with name "+new_name+" already exists too. Please rename the columns before joining to avoid ambiguity."
            False -> Nothing
    catch_ambiguity left_pairs
    catch_ambiguity right_pairs
    new_left_names = left_pairs.map .second
    new_right_names = right_pairs.map .second
    [new_left_names, new_right_names]
